{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# The Stanford Sentiment Treebank \n",
    "The Stanford Sentiment Treebank consists of sentences from movie reviews and human annotations of their sentiment. The task is to predict the sentiment of a given sentence. We use the two-way (positive/negative) class split, and use only sentence-level labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Environment variables that need to be defined:   \n",
       "`export DIR_PROJ=your_path_git_repository`  \n",
       "`export PYTHONPATH=$DIR_PROJ/src`  \n",
       "`export PATH_TENSORBOARD=your_path_tensorboard`  \n",
       "`export PATH_DATASETS=your_path_datasets`  \n",
       "`export PROJECT_ID=your_gcp_project_id`  \n",
       "`export BUCKET_NAME=your_gcp_gs_bucket_name`  \n",
       "`export BUCKET_TRANSLATION_NAME=your_gcp_gs_bucket_translation_name`  \n",
       "`export BUCKET_STAGING_NAME=your_gcp_gs_bucket_staging_name` \n",
       "`export REGION=your_region`  \n",
       "`export PATH_SAVE_MODEL=your_path_to_save_model`  \n",
       "`export CLOUDSDK_PYTHON=your_path/conda-env/env_gcp_sdk/bin/python`  \n",
       "`export CLOUDSDK_GSUTIL_PYTHON=your_path/conda-env/env_gcp_sdk/bin/python`  \n",
       "\n",
       "- Use local Jupyter Lab \n",
       "    - you need to have the `jupyter-notebook` Anaconda python environment created [link](local_jupyter_lab_installation.md) \n",
       "    - you need to have the `jupyter-notebook` Anaconda python environment activated [link](local_jupyter_lab_installation.md) \n",
       "    - then define the environment variables above (copy and paste) \n",
       "    - you need to have the `env_multilingual_class` Anaconda python environment created [link](local_jupyter_lab_installation.md)  \n",
       "    - start Jupyter Lab:  `jupyter lab` \n",
       "    - open a Jupyter Lab notebook from `notebook/` \n",
       "     - clone this repositiory: `git clone https://github.com/tarrade/proj_multilingual_text_classification.git`\n",
       "    - choose the proper Anaconda python environment:  `Python [conda env:env_multilingual_class]` [link](conda_env.md) \n",
       "    - clone this repositiory: `git clone https://github.com/tarrade/proj_multilingual_text_classification.git`\n",
       "\n",
       "\n",
       "- Use GCP Jupyter Lab \n",
       "    - Go on GCP\n",
       "    - open a Cloud Shell\n",
       "    - `ssh-keygen -t rsa -b 4096 -C firstName_lastName`\n",
       "    - `cp .ssh/id_rsa.pub .`\n",
       "    - use Cloud Editor to edit this file `id_rsa.pub` and copy the full content\n",
       "    - Go on Compute Engine -> Metadata\n",
       "    - Click SSH Keys\n",
       "    - Click Edit\n",
       "    - Click + Add item, copy the content of `id_rsa.pub`\n",
       "    - You should see firstName_lastName of the left\n",
       "    - Click Save\n",
       "    - you need to start a AI Platform instance \n",
       "    - open a Jupyter Lab terminal and got to `/home/gcp_user_name/`\n",
       "    - clone this repositiory: `git clone https://github.com/tarrade/proj_multilingual_text_classification.git`\n",
       "    - then `cd proj_multilingual_text_classification/`\n",
       "    - create the Anacond Python environment `conda env create -f env/environment.yml`\n",
       "    - create a file `config.sh` in `/home` with the following information: \n",
       "    ```\n",
       "    #!/bin/bash\n",
       "    \n",
       "    echo \"applying some configuration ...\"\n",
       "    git config --global user.email user_email\n",
       "    git config --global user.name user_name\n",
       "    git config --global credential.helper store\n",
       "        \n",
       "    # Add here the enviroment variables from above below\n",
       "    # [EDIT ME]\n",
       "    export DIR_PROJ=your_path_git_repository\n",
       "    export PYTHONPATH=$DIR_PROJ/src\n",
       "  \n",
       "    cd /home/gcp_user_name/\n",
       "    \n",
       "    conda activate env_multilingual_class\n",
       "\n",
       "    export PS1='\\[\\e[91m\\]\\u@:\\[\\e[32m\\]\\w\\[\\e[0m\\]$'\n",
       "    ```\n",
       "    - Got to AI Platform Notebook, select your instance and click \"Reset\".\n",
       "    - Wait and reshreh you Web browser with the Notebook\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "with open('../../doc/env_variables_setup.md', 'r') as fh:\n",
    "    content = fh.read()\n",
    "display(Markdown(content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from transformers import (\n",
    "    BertConfig,\n",
    "    BertTokenizer,\n",
    "    XLMRobertaTokenizer,\n",
    "    TFBertModel,\n",
    "    TFXLMRobertaModel,\n",
    "    TFBertForSequenceClassification,\n",
    "    glue_convert_examples_to_features,\n",
    "    glue_processors\n",
    ")\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from google.cloud import storage\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import re\n",
    "import codecs\n",
    "import json\n",
    "\n",
    "from google.api_core.client_options import ClientOptions\n",
    "from googleapiclient import discovery\n",
    "from googleapiclient import errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Check configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v2.2.0-rc4-8-g2b96f3662b 2.2.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.version.GIT_VERSION, tf.version.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0-tf\n"
     ]
    }
   ],
   "source": [
    "print(tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available !!!!\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if len(gpus)>0:\n",
    "    for gpu in gpus:\n",
    "        print('Name:', gpu.name, '  Type:', gpu.device_type)\n",
    "else:\n",
    "    print('No GPU available !!!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Define Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    data_dir=os.environ['PATH_DATASETS']\n",
    "except KeyError:\n",
    "    print('missing PATH_DATASETS')\n",
    "try:   \n",
    "    tensorboard_dir=os.environ['PATH_TENSORBOARD']\n",
    "except KeyError:\n",
    "    print('missing PATH_TENSORBOARD')\n",
    "try:   \n",
    "    savemodel_dir=os.environ['PATH_SAVE_MODEL']\n",
    "except KeyError:\n",
    "    print('missing PATH_SAVE_MODEL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Import local packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarrade/anaconda-release/conda-env/env_multilingual_class/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import preprocessing.preprocessing as pp\n",
    "import utils.model_metrics as mm\n",
    "import utils.model_utils as mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(pp);\n",
    "importlib.reload(mm);\n",
    "importlib.reload(mu);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Check the local model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "savemodel_path = os.path.join(savemodel_dir, 'saved_model')\n",
    "os.makedirs(savemodel_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "model=tf.keras.models.load_model(os.path.join(savemodel_path, 'tf_bert_classification'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: tf_bert_classification\n",
      "  projector_config.pbtxt\n",
      "  variables\n",
      "  history\n",
      "  history_per_step\n",
      "  train\n",
      "  saved_model.pb\n",
      "  assets\n",
      "  validation\n"
     ]
    }
   ],
   "source": [
    "# check the saved model\n",
    "print('Model: {}'.format(model.name))\n",
    "for i in os.listdir(os.path.join(savemodel_path,model.name)):\n",
    "        print(' ',i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_classification\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bert (TFBertMainLayer)       multiple                  167356416 \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "classifier (Dense)           multiple                  1538      \n",
      "=================================================================\n",
      "Total params: 167,357,954\n",
      "Trainable params: 167,357,954\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "source_bucket_name = savemodel_path+'/'+model.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".../projector_config.pbtxt\n",
      ".../saved_model.pb\n",
      ".../variables.data-00000-of-00001\n",
      ".../variables.index\n",
      ".../keras_embedding.ckpt-1.index\n",
      ".../checkpoint\n",
      ".../keras_embedding.ckpt-0.index\n",
      ".../events.out.tfevents.1587997306.Fabien-Tarrades-MacBook-Pro.local.20696.11162.v2\n",
      ".../events.out.tfevents.1587997350.Fabien-Tarrades-MacBook-Pro.local.profile-empty\n",
      ".../events.out.tfevents.1587999214.Fabien-Tarrades-MacBook-Pro.local.22120.11162.v2\n",
      ".../keras_embedding.ckpt-1.data-00000-of-00001\n",
      ".../keras_embedding.ckpt-0.data-00000-of-00001\n",
      ".../local.trace\n",
      ".../local.trace\n",
      ".../events.out.tfevents.1587999352.Fabien-Tarrades-MacBook-Pro.local.22120.34079.v2\n",
      ".../events.out.tfevents.1587997456.Fabien-Tarrades-MacBook-Pro.local.20696.34079.v2\n"
     ]
    }
   ],
   "source": [
    "for root, dirs, files in os.walk(source_bucket_name):\n",
    "    for name in files:\n",
    "        if not 'history' in name:\n",
    "            print(os.path.join('.../', name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "The **variables** directory contains a standard training checkpoint (see the guide to training checkpoints).  \n",
    "The **assets** directory contains files used by the TensorFlow graph, for example text files used to initialize vocabulary tables.  \n",
    "The **saved_model.pb** file stores the actual TensorFlow program, or model, and a set of named signatures, each identifying a function that accepts tensor inputs and produces tensor outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "os.environ['MODEL_LOCAL']=savemodel_path+'/'+model.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "SavedModels may contain multiple variants of the model (multiple v1.MetaGraphDefs, identified with the **--tag_set** flag to saved_model_cli), but this is rare. APIs which create multiple variants of a model include "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The given SavedModel MetaGraphDef contains SignatureDefs with the following keys:\n",
      "SignatureDef key: \"__saved_model_init_op\"\n",
      "SignatureDef key: \"serving_default\"\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "saved_model_cli show --dir $MODEL_LOCAL --tag_set serve "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The given SavedModel SignatureDef contains the following input(s):\n",
      "  inputs['attention_mask'] tensor_info:\n",
      "      dtype: DT_INT32\n",
      "      shape: (-1, 128)\n",
      "      name: serving_default_attention_mask:0\n",
      "  inputs['input_ids'] tensor_info:\n",
      "      dtype: DT_INT32\n",
      "      shape: (-1, 128)\n",
      "      name: serving_default_input_ids:0\n",
      "  inputs['token_type_ids'] tensor_info:\n",
      "      dtype: DT_INT32\n",
      "      shape: (-1, 128)\n",
      "      name: serving_default_token_type_ids:0\n",
      "The given SavedModel SignatureDef contains the following output(s):\n",
      "  outputs['output_1'] tensor_info:\n",
      "      dtype: DT_FLOAT\n",
      "      shape: (-1, 2)\n",
      "      name: StatefulPartitionedCall:0\n",
      "Method name is: tensorflow/serving/predict\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "saved_model_cli show --dir $MODEL_LOCAL --tag_set serve --signature_def serving_default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Copy the local model on GCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "destination_bucket_name = 'saved_model/tf_bert_classification'\n",
    "copy_model_gcp=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# will take some time since the size of the model is 2 GB!\n",
    "buket_name = os.environ['BUCKET_NAME']\n",
    "if copy_model_gcp:\n",
    "    mu.copy_local_directory_to_gcs(source_bucket_name, buket_name, destination_bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "os.environ['MODEL_GCP']='gs://'+os.environ['BUCKET_NAME']+'/saved_model/'+model.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Big model BERT for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# use model trainied with TPU\n",
    "os.environ['MODEL_GCP']='gs://'+os.environ['BUCKET_NAME']+'/training_model_gcp/tf_bert_classification_tpu_2020_06_21_211701/saved_model/'+model.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Small model census for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# use model trainied with CPU\n",
    "os.environ['MODEL_GCP']='gs://'+os.environ['BUCKET_NAME']+'/census_20200624_101711/keras-job-dir/4/keras_export'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Test the model with the aoth defined aboved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The given SavedModel SignatureDef contains the following input(s):\n",
      "  inputs['dense_input'] tensor_info:\n",
      "      dtype: DT_FLOAT\n",
      "      shape: (-1, 11)\n",
      "      name: serving_default_dense_input:0\n",
      "The given SavedModel SignatureDef contains the following output(s):\n",
      "  outputs['dense_4'] tensor_info:\n",
      "      dtype: DT_FLOAT\n",
      "      shape: (-1, 1)\n",
      "      name: StatefulPartitionedCall:0\n",
      "Method name is: tensorflow/serving/predict\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "saved_model_cli show --dir $MODEL_GCP --tag_set serve --signature_def serving_default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Model serving setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Normal VM has a model size of 500 MB \n",
    "# For more you need to use a specific n1-standard-2 VM (2 GB) for online prediction. It is only available in us-central1.\n",
    "\n",
    "region_model = 'us-central1'\n",
    "#region_model = 'europe-west4'\n",
    "#region_model = 'europe-west1'\n",
    "#region_model = 'europe-west6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Region: us-central1 is a regional endpoint: True\n"
     ]
    }
   ],
   "source": [
    "regional_endpoint=False\n",
    "if region_model=='europe-west4':\n",
    "    regional_endpoint=True\n",
    "elif region_model=='us-central1':\n",
    "    regional_endpoint=True\n",
    "print(' Region: {} is a regional endpoint: {}'.format(region_model, regional_endpoint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "batch_pred=True\n",
    "if batch_pred:\n",
    "    regional_endpoint=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarrade/anaconda-release/conda-env/env_multilingual_class/lib/python3.7/site-packages/google/auth/_default.py:69: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n",
      "/Users/tarrade/anaconda-release/conda-env/env_multilingual_class/lib/python3.7/site-packages/google/auth/_default.py:69: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "project_name = os.environ['PROJECT_ID']\n",
    "project_id = 'projects/{}'.format(project_name)\n",
    "if not regional_endpoint:\n",
    "    ai_platform_serving = discovery.build('ml', 'v1')\n",
    "else:\n",
    "    endpoint = 'https://'+region_model+'-ml.googleapis.com'\n",
    "    client_options = ClientOptions(api_endpoint=endpoint)\n",
    "    ai_platform_serving = discovery.build('ml', 'v1', client_options=client_options)\n",
    "# to list all model\n",
    "ai_platform_serving_global = discovery.build('ml', 'v1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Check models already deployed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "request = ai_platform_serving_global.projects().models().list(parent=project_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of model:\n",
      "  Model 's name: tf_bert_classification_test_batch_europe_west1:\n",
      "    descrition: this is a model for test\n",
      "    regions: ['europe-west1']\n",
      "  Model 's name: tf_bert_classification_test_batch_us_central1:\n",
      "    descrition: this is a model for test\n",
      "    regions: ['us-central1']\n",
      "  Model 's name: tf_bert_classification_test_europe_west1:\n",
      "    descrition: this is a model for test\n",
      "    regions: ['europe-west1']\n"
     ]
    }
   ],
   "source": [
    "# Make the call.\n",
    "try:\n",
    "    response = request.execute()\n",
    "    print('List of model:')\n",
    "    if 'models' in response.keys():\n",
    "        for i in response['models']:\n",
    "            print('  Model \\'s name: {}:'.format(i['name'].split('/')[-1]))\n",
    "            print('    descrition: {}'.format(i['description']))\n",
    "            print('    regions: {}'.format(i['regions']))\n",
    "\n",
    "except errors.HttpError as err:\n",
    "    # Something went wrong, print out some information.\n",
    "    print('There was an error creating the model. Check the details:')\n",
    "    print(err._get_reason())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Create a new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# defining the name of the model for online prediction\n",
    "if batch_pred:\n",
    "    name_model = model.name+'_test_census_batch_'+region_model.replace('-','_')\n",
    "else:\n",
    "    name_model = model.name+'_test_census_'+region_model.replace('-','_')\n",
    "description_model = 'this is a model for test'\n",
    "\n",
    "# Create a dictionary with the fields from the request body.\n",
    "request_dict = {'name': name_model,\n",
    "                'regions': [region_model],\n",
    "                'description': description_model,\n",
    "                'labels': {'region': region_model} }\n",
    "\n",
    "# Create a request to call projects.models.create.\n",
    "request = ai_platform_serving.projects().models().create(parent=project_id, \n",
    "                                                         body=request_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'tf_bert_classification_test_census_batch_us_central1',\n",
       " 'regions': ['us-central1'],\n",
       " 'description': 'this is a model for test',\n",
       " 'labels': {'region': 'us-central1'}}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "request_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name of the model: tf_bert_classification_test_census_batch_us_central1:\n",
      "  descrition: this is a model for test\n",
      "  regions: ['us-central1']\n"
     ]
    }
   ],
   "source": [
    "# Make the call.\n",
    "try:\n",
    "    response = request.execute()\n",
    "    print('Name of the model: {}:'.format(response['name'].split('/')[-1]))\n",
    "    print('  descrition: {}'.format(response['description']))\n",
    "    print('  regions: {}'.format(response['regions']))\n",
    "\n",
    "except errors.HttpError as err:\n",
    "    # Something went wrong, print out soFinme information.\n",
    "    print('There was an error creating the model. Check the details:')\n",
    "    print(err._get_reason())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Defined all parameters and upload our models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# defining the name of the model for online prediction\n",
    "description_model = ' this is a model for test'\n",
    "parentId = 'projects/{}/models/{}'.format(project_name, name_model)\n",
    "# Normal VM has a model size of 500 MB for more you need to use a specific n1-standard-2 VM (2 GB) for online prediction. It is only available in us-central1.\n",
    "#region_model = 'us-central1'\n",
    "\n",
    "model_binaries = os.environ['MODEL_GCP'] \n",
    "machine_type='mls1-c1-m2'\n",
    "\n",
    "#'gs://'+os.environ['BUCKET_NAME']+'/saved_model/'+model.name\n",
    "# machine_type='n1-standard-2'\n",
    "\n",
    "version = 'V1'\n",
    "\n",
    "# Create a dictionary with the fields from the request body.\n",
    "request_dict = {'machineType': machine_type,\n",
    "                'runtimeVersion': '2.1',\n",
    "                'pythonVersion': '3.7',\n",
    "                'framework': 'TENSORFLOW',\n",
    "                'description': 'This is sentiment classifier using BERT and fine tune on SST-2 for test',\n",
    "                'deploymentUri': model_binaries,\n",
    "                'name': version\n",
    "               }\n",
    "\n",
    "# Create a request to call projects.models.create.\n",
    "request = ai_platform_serving.projects().models().versions().create(parent=parentId, \n",
    "                                                                    body=request_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#request_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name of the model: create_tf_bert_classification_test_census_batch_us_central1_V1-1594186701100:\n",
      "  descrition: This is sentiment classifier using BERT and fine tune on SST-2 for test\n",
      "  runtimeVersion: 2.1\n",
      "  framework: TENSORFLOW\n",
      "  machineType: mls1-c1-m2\n",
      "  pythonVersion: 3.7\n"
     ]
    }
   ],
   "source": [
    "# Make the call.\n",
    "try:\n",
    "    response = request.execute()\n",
    "    print('Name of the model: {}:'.format(response['name'].split('/')[-1]))\n",
    "    print('  descrition: {}'.format(response['metadata']['version']['description']))\n",
    "    print('  runtimeVersion: {}'.format(response['metadata']['version']['runtimeVersion']))\n",
    "    print('  framework: {}'.format(response['metadata']['version']['framework']))\n",
    "    print('  machineType: {}'.format(response['metadata']['version']['machineType']))\n",
    "    print('  pythonVersion: {}'.format(response['metadata']['version']['pythonVersion']))\n",
    "\n",
    "except errors.HttpError as err:\n",
    "    # Something went wrong, print out soFinme information.\n",
    "    print('There was an error creating the model. Check the details:')\n",
    "    print(err._get_reason())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Check that the new modelal was deployed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "request = ai_platform_serving.projects().models().list(parent=project_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of model:\n",
      "  Model 's name: tf_bert_classification_test_batch_europe_west1:\n",
      "    descrition: this is a model for test\n",
      "    regions: ['europe-west1']\n",
      "  Model 's name: tf_bert_classification_test_batch_us_central1:\n",
      "    descrition: this is a model for test\n",
      "    regions: ['us-central1']\n",
      "  Model 's name: tf_bert_classification_test_census_batch_us_central1:\n",
      "    descrition: this is a model for test\n",
      "    regions: ['us-central1']\n",
      "  Model 's name: tf_bert_classification_test_europe_west1:\n",
      "    descrition: this is a model for test\n",
      "    regions: ['europe-west1']\n"
     ]
    }
   ],
   "source": [
    "# Make the call.\n",
    "try:\n",
    "    response = request.execute()\n",
    "    print('List of model:')\n",
    "    for i in response['models']:\n",
    "        print('  Model \\'s name: {}:'.format(i['name'].split('/')[-1]))\n",
    "        print('    descrition: {}'.format(i['description']))\n",
    "        print('    regions: {}'.format(i['regions']))\n",
    "\n",
    "except errors.HttpError as err:\n",
    "    # Something went wrong, print out some information.\n",
    "    print('There was an error creating the model. Check the details:')\n",
    "    print(err._get_reason())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Model serving inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Prepare data for online prediction for BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "example of format:\n",
    "\n",
    "```\n",
    "{'instances': \n",
    "  [\n",
    "    {'input_ids': [101, 143, 18267, 15470, 90395, ...], \n",
    "     'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, .....], \n",
    "     'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, .....]\n",
    "     }, \n",
    "     {'input_ids': [101, 17664, 143, 30728, .........], \n",
    "      'attention_mask': [1, 1, 1, 1, 1, 1, 1, .......], \n",
    "      'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, ....]\n",
    "      }\n",
    "  ]\n",
    "}\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "tfrecord_data_dir=data_dir+'/tfrecord/sst2/tf_bert_classification/valid'\n",
    "os.makedirs(tfrecord_data_dir, exist_ok=True)\n",
    "valid_files = tf.data.TFRecordDataset(tfrecord_data_dir+'/valid_dataset.tfrecord')\n",
    "valid_dataset = valid_files.map(pp.parse_tfrecord_glue_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# format data for online prediction\n",
    "np_array = np.array(list(valid_dataset.as_numpy_iterator()))\n",
    "\n",
    "data_prediction=[]\n",
    "\n",
    "for el in np_array[0:10]:\n",
    "    instance={'input_ids': el[0]['input_ids'].tolist(), 'attention_mask': el[0]['attention_mask'].tolist(), 'token_type_ids': el[0]['token_type_ids'].tolist()}\n",
    "    data_prediction.append(instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(data_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'input_ids': [101, 143, 18267, 15470, 90395, 10453, 10202, 14985, 10114, 11061, 16722, 10533, 20448, 83617, 10151, 10103, 15252, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, {'input_ids': [101, 17664, 143, 30728, 10563, 26936, 78285, 13512, 10195, 10103, 11838, 11967, 39253, 87385, 117, 100, 100, 61334, 112, 112, 25458, 10103, 11714, 13170, 10146, 56281, 112, 161, 100, 100, 10379, 32824, 112, 112, 10171, 10772, 15905, 14214, 12024, 10563, 89441, 28060, 15569, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}]\n"
     ]
    }
   ],
   "source": [
    "print(data_prediction[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Prepare data for online prediction for Census"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# for census\n",
    "data_prediction=[{'dense_input': [25.0, 0, 7, 0, 0, 0, 0, 0, 0, 40, 0]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dense_input': [25.0, 0, 7, 0, 0, 0, 0, 0, 0, 40, 0]}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_prediction[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Make online prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# model\n",
    "version_name='V1'\n",
    "\n",
    "# use the one above or define it below\n",
    "#name_model='tf_bert_classification_test'\n",
    "#name_model='tf_bert_classification_test_europe_west4'\n",
    "\n",
    "# use the one above, be careful with regional endpoint\n",
    "#ai_platform_serving\n",
    "\n",
    "parent = 'projects/{}/models/{}/versions/{}'.format(project_name, name_model, version_name)\n",
    "\n",
    "# data for prediction\n",
    "request_data = {\"instances\": data_prediction}\n",
    "#request_data = {\"instances\": [{\"dense_input\":data_prediction}]}\n",
    "\n",
    "# Create a request to call projects.models.create.\n",
    "request = ai_platform_serving.projects().predict(body=request_data, \n",
    "                                                 name=parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'projects/axarevvicnonprod/models/tf_bert_classification_test_census_batch_us_central1/versions/V1'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instances': [{'dense_input': [25.0, 0, 7, 0, 0, 0, 0, 0, 0, 40, 0]}]}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "request_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions:\n",
      "  {'dense_4': [0.2507100999355316]}\n"
     ]
    }
   ],
   "source": [
    "# Make the call.\n",
    "try:\n",
    "    response = request.execute()\n",
    "    print('predictions:')\n",
    "    for i in response['predictions']:\n",
    "        print('  {}'.format(i))\n",
    "\n",
    "except errors.HttpError as err:\n",
    "    # Something went wrong, print out soFinme information.\n",
    "    print('There was an error making prediction. Check the details:')\n",
    "    print(err._get_reason())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Make prediction using local model to test the input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# not possible ? probably not very useful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Batch predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "tfrecord_data_dir=data_dir+'/tfrecord/sst2/tf_bert_classification/valid'\n",
    "os.makedirs(tfrecord_data_dir, exist_ok=True)\n",
    "valid_files = tf.data.TFRecordDataset(tfrecord_data_dir+'/valid_dataset.tfrecord')\n",
    "valid_dataset = valid_files.map(pp.parse_tfrecord_glue_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# format data for online prediction\n",
    "np_array = np.array(list(valid_dataset.as_numpy_iterator()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# create a json file with the right format for online prediction\n",
    "serving_data_dir=data_dir+'/serving/sst2'\n",
    "os.makedirs(serving_data_dir, exist_ok=True)\n",
    "json_file = serving_data_dir+'/input_predict_gcloud.json' \n",
    "\n",
    "with codecs.open(json_file, 'w', encoding='utf-8') as f:\n",
    "    for el in np_array[0:10]:\n",
    "        instance={'input_ids': el[0]['input_ids'].tolist(), 'attention_mask': el[0]['attention_mask'].tolist(), 'token_type_ids': el[0]['token_type_ids'].tolist()}\n",
    "        json.dump(instance, f , sort_keys=True)\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarrade/anaconda-release/conda-env/env_multilingual_class/lib/python3.7/site-packages/google/auth/_default.py:69: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n",
      "/Users/tarrade/anaconda-release/conda-env/env_multilingual_class/lib/python3.7/site-packages/google/auth/_default.py:69: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "serving/sst2/input_predict_gcloud.json\n",
      "copy of the file(s) on gs:// done !\n"
     ]
    }
   ],
   "source": [
    "destination_bucket_name = 'serving/sst2'\n",
    "buket_name = os.environ['BUCKET_NAME']\n",
    "mu.copy_local_directory_to_gcs(serving_data_dir, buket_name, destination_bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# bert\n",
    "# Regional endpoint only support online prediction and AI explanations\n",
    "name_model='tf_bert_classification_test_batch_us_central1'\n",
    "#version_name='V1'\n",
    "region_model='us-central1'\n",
    "version_name=None\n",
    "input_paths='gs://'+os.environ['BUCKET_NAME']+'/serving/sst2/input_predict_gcloud.json'\n",
    "output_path='gs://'+os.environ['BUCKET_NAME']+'/'\n",
    "data_format='TEXT'\n",
    "max_worker_count=20\n",
    "runtime_version=None\n",
    "\n",
    "not_deployed=False\n",
    "if not_deployed:\n",
    "    runtime_version='2.1'\n",
    "    #uri='gs://'+os.environ['BUCKET_NAME']+'/training_model_gcp/tf_bert_classification_tpu_2020_06_21_211701/saved_model/'+model.name\n",
    "    uri='gs://'+os.environ['BUCKET_NAME']+'/census_20200706_194610/keras-job-dir/4/keras_export'\n",
    "    signatureName='serving_default'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarrade/anaconda-release/conda-env/env_multilingual_class/lib/python3.7/site-packages/google/auth/_default.py:69: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "# census\n",
    "ai_platform_serving = discovery.build('ml', 'v1')\n",
    "name_model='tf_bert_classification_test_batch_us_central1'\n",
    "version_name=None\n",
    "region_model='us-central1'\n",
    "input_paths='gs://'+os.environ['BUCKET_NAME']+'/serving/sst2/input_predict_gcloud_census.json'\n",
    "output_path='gs://'+os.environ['BUCKET_NAME']+'/batch_prediction_census_'+datetime.now().strftime(\"%Y_%m_%d_%H%M%S\")\n",
    "data_format='TEXT'\n",
    "max_worker_count=20\n",
    "runtime_version=None\n",
    "\n",
    "not_deployed=False\n",
    "if not_deployed:\n",
    "    runtime_version='2.1'\n",
    "    uri='gs://'+os.environ['BUCKET_NAME']+'/census_20200706_194610/keras-job-dir/4/keras_export'\n",
    "    signatureName='serving_default'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "model_id = '{}/models/{}'.format(project_id, name_model)\n",
    "if version_name is not None:\n",
    "    version_id = '{}/versions/{}'.format(model_id, version_name)\n",
    "\n",
    "# Make a jobName of the format \"model_name_batch_predict_YYYYMMDD_HHMMSS\"\n",
    "timestamp = time.strftime('%Y%m%d_%H%M%S', time.gmtime())\n",
    "\n",
    "job_id = '{}_{}'.format(name_model,timestamp)\n",
    "# Start building the request dictionary with required information.\n",
    "body = {'jobId': job_id,\n",
    "        'predictionInput': {\n",
    "            'dataFormat': data_format,\n",
    "            'inputPaths': [input_paths],\n",
    "            'outputPath': output_path,\n",
    "            'region': region_model}\n",
    "       }\n",
    "\n",
    "# Use the version if present, the model (its default version) if not.\n",
    "if not_deployed:\n",
    "    body['predictionInput']['uri'] = uri\n",
    "    body['predictionInput']['signatureName'] = signatureName\n",
    "else:\n",
    "    if version_name is not None:\n",
    "        body['predictionInput']['versionName'] = version_id\n",
    "    else:\n",
    "        body['predictionInput']['modelName'] = model_id\n",
    "\n",
    "# Only include a maximum number of workers or a runtime version if specified.\n",
    "# Otherwise let the service use its defaults.\n",
    "#if max_worker_count:\n",
    "#    body['predictionInput']['maxWorkerCount'] = max_worker_count\n",
    "\n",
    "if runtime_version:\n",
    "    body['predictionInput']['runtimeVersion'] = runtime_version\n",
    "\n",
    "# Create a request to call projects.models.create.\n",
    "request = ai_platform_serving.projects().jobs().create(parent=project_id,\n",
    "                                                       body=body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'jobId': 'tf_bert_classification_test_batch_us_central1_20200708_093754',\n",
       " 'predictionInput': {'dataFormat': 'TEXT',\n",
       "  'inputPaths': ['gs://multilingual_text_classification/serving/sst2/input_predict_gcloud_census.json'],\n",
       "  'outputPath': 'gs://multilingual_text_classification/batch_prediction_census_2020_07_08_113752',\n",
       "  'region': 'us-central1',\n",
       "  'modelName': 'projects/axarevvicnonprod/models/tf_bert_classification_test_batch_us_central1'}}"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job [tf_bert_classification_test_batch_us_central1_20200707_test3] submitted successfully.\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ai-platform jobs describe tf_bert_classification_test_batch_us_central1_20200707_test3\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "  $ gcloud ai-platform jobs stream-logs tf_bert_classification_test_batch_us_central1_20200707_test3\n",
      "jobId: tf_bert_classification_test_batch_us_central1_20200707_test3\n",
      "state: QUEUED\n"
     ]
    }
   ],
   "source": [
    "#--model 'tf_bert_classification_test_batch_us_central1' \\\n",
    "#--input-paths 'gs://multilingual_text_classification/serving/sst2/input_predict_gcloud.json' \\\n",
    "!gcloud ai-platform jobs submit prediction 'tf_bert_classification_test_batch_us_central1_20200707_test3' \\\n",
    "    --model 'tf_bert_classification_test_census_batch_us_central1' \\\n",
    "    --input-paths 'gs://multilingual_text_classification/serving/sst2/input_predict_gcloud_census.json' \\\n",
    "    --output-path 'gs://multilingual_text_classification/test_3' \\\n",
    "    --region 'us-central1' \\\n",
    "    --data-format 'TEXT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "createTime: '2020-07-08T06:54:29Z'\n",
      "etag: bHops9zsgYM=\n",
      "jobId: tf_bert_classification_test_batch_us_central1_20200707_test2\n",
      "predictionInput:\n",
      "  dataFormat: JSON\n",
      "  inputPaths:\n",
      "  - gs://multilingual_text_classification/serving/sst2/input_predict_gcloud_census.json\n",
      "  modelName: projects/axarevvicnonprod/models/tf_bert_classification_test_census_batch_us_central1\n",
      "  outputPath: gs://multilingual_text_classification/\n",
      "  region: us-central1\n",
      "  runtimeVersion: '2.1'\n",
      "predictionOutput:\n",
      "  outputPath: gs://multilingual_text_classification/\n",
      "startTime: '2020-07-08T06:54:30Z'\n",
      "state: RUNNING\n",
      "\n",
      "View job in the Cloud Console at:\n",
      "https://console.cloud.google.com/mlengine/jobs/tf_bert_classification_test_batch_us_central1_20200707_test2?project=axarevvicnonprod\n",
      "\n",
      "View logs at:\n",
      "https://console.cloud.google.com/logs?resource=ml_job%2Fjob_id%2Ftf_bert_classification_test_batch_us_central1_20200707_test2&project=axarevvicnonprod\n"
     ]
    }
   ],
   "source": [
    "!gcloud ai-platform jobs describe tf_bert_classification_test_batch_us_central1_20200707_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO\t2020-07-08 08:54:28 +0200\tservice\t\tValidating job requirements...\n",
      "INFO\t2020-07-08 08:54:29 +0200\tservice\t\tJob creation request has been successfully validated.\n",
      "INFO\t2020-07-08 08:54:29 +0200\tservice\t\tJob tf_bert_classification_test_batch_us_central1_20200707_test2 is queued.\n",
      "INFO\t2020-07-08 09:00:56 +0200\tservice\t\tJob completed successfully.\n"
     ]
    }
   ],
   "source": [
    "!gcloud ai-platform jobs stream-logs tf_bert_classification_test_batch_us_central1_20200707_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There was an error making prediction. Check the details:\n",
      "Internal error encountered.\n"
     ]
    }
   ],
   "source": [
    "# Make the call.\n",
    "try:\n",
    "    response = request.execute()\n",
    "    print('job requested.')\n",
    "\n",
    "    # The state returned will almost always be QUEUED.\n",
    "    print('state : {}'.format(response['state']))\n",
    "\n",
    "except errors.HttpError as err:\n",
    "    # Something went wrong, print out soFinme information.\n",
    "    print('There was an error making prediction. Check the details:')\n",
    "    print(err._get_reason())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "ename": "HttpError",
     "evalue": "<HttpError 500 when requesting https://ml.googleapis.com/v1/projects/axarevvicnonprod/jobs?alt=json returned \"Internal error encountered.\">",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHttpError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-125-809a8d6ce253>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda-release/conda-env/env_multilingual_class/lib/python3.7/site-packages/googleapiclient/_helpers.py\u001b[0m in \u001b[0;36mpositional_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mpositional_parameters_enforcement\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mPOSITIONAL_WARNING\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpositional_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda-release/conda-env/env_multilingual_class/lib/python3.7/site-packages/googleapiclient/http.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, http, num_retries)\u001b[0m\n\u001b[1;32m    896\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 898\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHttpError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muri\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    899\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostproc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHttpError\u001b[0m: <HttpError 500 when requesting https://ml.googleapis.com/v1/projects/axarevvicnonprod/jobs?alt=json returned \"Internal error encountered.\">"
     ]
    }
   ],
   "source": [
    "request.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:env_multilingual_class]",
   "language": "python",
   "name": "conda-env-env_multilingual_class-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
