{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "toc-hr-collapsed": false
   },
   "source": [
    "# Preprocessing using Beam/Dataflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pathlib\n",
    "import logging\n",
    "import subprocess\n",
    "import datetime\n",
    "import subprocess, requests\n",
    "import apache_beam as beam\n",
    "from google.cloud import bigquery\n",
    "from apache_beam.options.pipeline_options import PipelineOptions\n",
    "from apache_beam.options.pipeline_options import StandardOptions\n",
    "from apache_beam.options.pipeline_options import GoogleCloudOptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Defined GCP env variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Env variable GOOGLE_APPLICATION_CREDENTIALS not defined!\n",
      "Env variable REQUESTS_CA_BUNDLE not defined!\n",
      "Env variable AXA_CA_CA_BUNDLE not defined!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tmp=os.environ['PROJECT_ID']\n",
    "except:\n",
    "    print('Env variable PROJECT not defined!') \n",
    "\n",
    "try:\n",
    "    tmp=os.environ['BUCKET_NAME']\n",
    "except:\n",
    "    print('Env variable BUCKET_NAME not defined!') \n",
    "\n",
    "try:\n",
    "    tmp=os.environ['REGION']\n",
    "except:\n",
    "    print('Env variable REGION not defined!') \n",
    "\n",
    "try:    \n",
    "    tmp=os.environ['GOOGLE_APPLICATION_CREDENTIALS']\n",
    "except:\n",
    "    print('Env variable GOOGLE_APPLICATION_CREDENTIALS not defined!') \n",
    "\n",
    "try:\n",
    "    tmp=os.environ['REQUESTS_CA_BUNDLE']\n",
    "except:\n",
    "    print('Env variable REQUESTS_CA_BUNDLE not defined!') \n",
    "\n",
    "try:\n",
    "    tmp=os.environ['AXA_CH_CA_BUNDLE']\n",
    "except:\n",
    "    print('Env variable AXA_CA_CA_BUNDLE not defined!') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Preprocessing using Beam/Dataflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Define a query to get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# define query table\n",
    "def create_query():\n",
    "    query = \"\"\"\n",
    "    SELECT\n",
    "    *\n",
    "    FROM\n",
    "    `bigquery-public-data.stackoverflow.tags`\n",
    "    LIMIT 100\n",
    "    \"\"\"\n",
    "\n",
    "    return query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Get the schema of the input table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"creationTime\": \"1477491432274\", \n",
      "  \"etag\": \"+9nuQ6pxbVUXEEgkOowfuw==\", \n",
      "  \"id\": \"bigquery-public-data:stackoverflow.tags\", \n",
      "  \"kind\": \"bigquery#table\", \n",
      "  \"lastModifiedTime\": \"1575026613006\", \n",
      "  \"location\": \"US\", \n",
      "  \"numBytes\": \"2284573\", \n",
      "  \"numLongTermBytes\": \"0\", \n",
      "  \"numRows\": \"55665\", \n",
      "  \"schema\": {\n",
      "    \"fields\": [\n",
      "      {\n",
      "        \"mode\": \"NULLABLE\", \n",
      "        \"name\": \"id\", \n",
      "        \"type\": \"INTEGER\"\n",
      "      }, \n",
      "      {\n",
      "        \"mode\": \"NULLABLE\", \n",
      "        \"name\": \"tag_name\", \n",
      "        \"type\": \"STRING\"\n",
      "      }, \n",
      "      {\n",
      "        \"mode\": \"NULLABLE\", \n",
      "        \"name\": \"count\", \n",
      "        \"type\": \"INTEGER\"\n",
      "      }, \n",
      "      {\n",
      "        \"mode\": \"NULLABLE\", \n",
      "        \"name\": \"excerpt_post_id\", \n",
      "        \"type\": \"INTEGER\"\n",
      "      }, \n",
      "      {\n",
      "        \"mode\": \"NULLABLE\", \n",
      "        \"name\": \"wiki_post_id\", \n",
      "        \"type\": \"INTEGER\"\n",
      "      }\n",
      "    ]\n",
      "  }, \n",
      "  \"selfLink\": \"https://bigquery.googleapis.com/bigquery/v2/projects/bigquery-public-data/datasets/stackoverflow/tables/tags\", \n",
      "  \"tableReference\": {\n",
      "    \"datasetId\": \"stackoverflow\", \n",
      "    \"projectId\": \"bigquery-public-data\", \n",
      "    \"tableId\": \"tags\"\n",
      "  }, \n",
      "  \"type\": \"TABLE\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# getting schema\n",
    "! bq show --format=prettyjson bigquery-public-data:stackoverflow.tags "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "table_schema = {\n",
    "    'fields': [\n",
    "        {\n",
    "            'mode': 'NULLABLE',\n",
    "            'name': 'id',\n",
    "            'type': 'INTEGER'\n",
    "        },\n",
    "        {\n",
    "            'mode': 'NULLABLE',\n",
    "            'name': 'tag_name',\n",
    "            'type': 'STRING'\n",
    "        },\n",
    "        {\n",
    "            'mode': 'NULLABLE',\n",
    "            'name': 'count',\n",
    "            'type': 'INTEGER'\n",
    "        },\n",
    "        {\n",
    "            'mode': 'NULLABLE',\n",
    "            'name': 'excerpt_post_id',\n",
    "            'type': 'INTEGER'\n",
    "        },\n",
    "        {\n",
    "            'mode': 'NULLABLE',\n",
    "            'name': 'wiki_post_id',\n",
    "            'type': 'INTEGER'\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Define the preprocessing steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def preprocess():\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        -RUNNER: \"DirectRunner\" or \"DataflowRunner\". Specfy to run the pipeline locally or on Google Cloud respectively.\n",
    "    Side-effects:\n",
    "        -Creates and executes dataflow pipeline.\n",
    "        See https://beam.apache.org/documentation/programming-guide/#creating-a-pipeline\n",
    "    \"\"\"\n",
    "    job_name = 'test-stackoverflow' + '-' + datetime.datetime.now().strftime('%y%m%d-%H%M%S')\n",
    "    project = os.environ['PROJECT_ID']\n",
    "    region = os.environ['REGION']\n",
    "    output_dir = \"gs://{0}/stackoverflow/\".format(os.environ['BUCKET_NAME'])\n",
    "\n",
    "    # options\n",
    "    options = PipelineOptions()\n",
    "    google_cloud_options = options.view_as(GoogleCloudOptions)\n",
    "    google_cloud_options.project =  project\n",
    "    google_cloud_options.job_name =  job_name\n",
    "    google_cloud_options.region = region\n",
    "    google_cloud_options.staging_location = os.path.join(output_dir, 'tmp', 'staging')\n",
    "    google_cloud_options.temp_location = os.path.join(output_dir, 'tmp')\n",
    "    # done by command line\n",
    "    options.view_as(StandardOptions).runner = 'DataflowRunner'\n",
    "\n",
    "    # instantantiate Pipeline object using PipelineOptions\n",
    "    print('Launching Dataflow job {} ... hang on'.format(job_name))\n",
    "\n",
    "    p = beam.Pipeline(options=options)\n",
    "    output = p | 'Read from BigQuery' >> beam.io.Read(beam.io.BigQuerySource(\n",
    "        # query\n",
    "        query=create_query(),\n",
    "        # use standard SQL for the above query\n",
    "        use_standard_sql=True))\n",
    "    output | 'Write to BigQuery' >> beam.io.WriteToBigQuery(\n",
    "        # The table name is a required argument for the BigQuery\n",
    "        table='test_stackoverflow_beam',\n",
    "        dataset='test',\n",
    "        project=project,\n",
    "        # Here we use the JSON schema read in from a JSON file.\n",
    "        # Specifying the schema allows the API to create the table correctly if it does not yet exist.\n",
    "        schema=table_schema,\n",
    "        # Creates the table in BigQuery if it does not yet exist.\n",
    "        create_disposition=beam.io.BigQueryDisposition.CREATE_IF_NEEDED,\n",
    "        # Deletes all data in the BigQuery table before writing.\n",
    "        write_disposition=beam.io.BigQueryDisposition.WRITE_TRUNCATE)\n",
    "        # not needed, from with clause\n",
    "\n",
    "    if options.view_as(StandardOptions).runner == 'DataflowRunner':\n",
    "        print('DataflowRunner')\n",
    "        p.run()\n",
    "    else:\n",
    "        print('Default: DirectRunner')\n",
    "        result = p.run()\n",
    "        result.wait_until_finish()\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting main process ...\n",
      "Launching Dataflow job test-stackoverflow-191129-165617 ... hang on\n",
      "DataflowRunner\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/.conda-env/env_nlp_text_class/lib/python3.6/site-packages/apache_beam/runners/dataflow/dataflow_runner.py:696: BeamDeprecationWarning: BigQuerySink is deprecated since 2.11.0. Use WriteToBigQuery instead.\n",
      "  kms_key=transform.kms_key))\n",
      "INFO:root:Setting socket default timeout to 60 seconds.\n",
      "INFO:root:socket default timeout is 60.0econds.\n",
      "DEBUG:root:Connecting using Google Application Default Credentials.\n",
      "INFO:root:Starting GCS upload to gs://nlp-text-classification/stackoverflow/tmp/staging/test-stackoverflow-191129-165617.1575046577.861365/pipeline.pb...\n",
      "INFO:oauth2client.transport:Attempting refresh to obtain initial access_token\n",
      "INFO:oauth2client.transport:Attempting refresh to obtain initial access_token\n",
      "INFO:root:Completed GCS upload to gs://nlp-text-classification/stackoverflow/tmp/staging/test-stackoverflow-191129-165617.1575046577.861365/pipeline.pb in 0 seconds.\n",
      "INFO:root:Downloading source distribution of the SDK from PyPi\n",
      "INFO:root:Executing command: ['/home/.conda-env/env_nlp_text_class/bin/python', '-m', 'pip', 'download', '--dest', '/tmp/tmpz8nlxr3a', 'apache-beam==2.16.0', '--no-deps', '--no-binary', ':all:']\n",
      "INFO:root:Staging SDK sources from PyPI to gs://nlp-text-classification/stackoverflow/tmp/staging/test-stackoverflow-191129-165617.1575046577.861365/dataflow_python_sdk.tar\n",
      "INFO:root:Starting GCS upload to gs://nlp-text-classification/stackoverflow/tmp/staging/test-stackoverflow-191129-165617.1575046577.861365/dataflow_python_sdk.tar...\n",
      "INFO:root:Completed GCS upload to gs://nlp-text-classification/stackoverflow/tmp/staging/test-stackoverflow-191129-165617.1575046577.861365/dataflow_python_sdk.tar in 1 seconds.\n",
      "INFO:root:Downloading binary distribution of the SDK from PyPi\n",
      "INFO:root:Executing command: ['/home/.conda-env/env_nlp_text_class/bin/python', '-m', 'pip', 'download', '--dest', '/tmp/tmpz8nlxr3a', 'apache-beam==2.16.0', '--no-deps', '--only-binary', ':all:', '--python-version', '36', '--implementation', 'cp', '--abi', 'cp36m', '--platform', 'manylinux1_x86_64']\n",
      "INFO:root:Staging binary distribution of the SDK from PyPI to gs://nlp-text-classification/stackoverflow/tmp/staging/test-stackoverflow-191129-165617.1575046577.861365/apache_beam-2.16.0-cp36-cp36m-manylinux1_x86_64.whl\n",
      "INFO:root:Starting GCS upload to gs://nlp-text-classification/stackoverflow/tmp/staging/test-stackoverflow-191129-165617.1575046577.861365/apache_beam-2.16.0-cp36-cp36m-manylinux1_x86_64.whl...\n",
      "INFO:root:Completed GCS upload to gs://nlp-text-classification/stackoverflow/tmp/staging/test-stackoverflow-191129-165617.1575046577.861365/apache_beam-2.16.0-cp36-cp36m-manylinux1_x86_64.whl in 1 seconds.\n",
      "WARNING:root:Discarding unparseable args: ['-f', '/root/.local/share/jupyter/runtime/kernel-ad87f9c7-9f42-4a3a-9dda-c31a9c926d70.json']\n",
      "WARNING:root:Discarding unparseable args: ['-f', '/root/.local/share/jupyter/runtime/kernel-ad87f9c7-9f42-4a3a-9dda-c31a9c926d70.json']\n",
      "DEBUG:root:JOB: {\n",
      "  \"environment\": {\n",
      "    \"clusterManagerApiService\": \"compute.googleapis.com\",\n",
      "    \"dataset\": \"bigquery.googleapis.com/cloud_dataflow\",\n",
      "    \"experiments\": [\n",
      "      \"use_fastavro\"\n",
      "    ],\n",
      "    \"sdkPipelineOptions\": {\n",
      "      \"display_data\": [\n",
      "        {\n",
      "          \"key\": \"runner\",\n",
      "          \"namespace\": \"apache_beam.options.pipeline_options.PipelineOptions\",\n",
      "          \"type\": \"STRING\",\n",
      "          \"value\": \"DataflowRunner\"\n",
      "        },\n",
      "        {\n",
      "          \"key\": \"project\",\n",
      "          \"namespace\": \"apache_beam.options.pipeline_options.PipelineOptions\",\n",
      "          \"type\": \"STRING\",\n",
      "          \"value\": \"nlp-text-classification\"\n",
      "        },\n",
      "        {\n",
      "          \"key\": \"job_name\",\n",
      "          \"namespace\": \"apache_beam.options.pipeline_options.PipelineOptions\",\n",
      "          \"type\": \"STRING\",\n",
      "          \"value\": \"test-stackoverflow-191129-165617\"\n",
      "        },\n",
      "        {\n",
      "          \"key\": \"staging_location\",\n",
      "          \"namespace\": \"apache_beam.options.pipeline_options.PipelineOptions\",\n",
      "          \"type\": \"STRING\",\n",
      "          \"value\": \"gs://nlp-text-classification/stackoverflow/tmp/staging/test-stackoverflow-191129-165617.1575046577.861365\"\n",
      "        },\n",
      "        {\n",
      "          \"key\": \"temp_location\",\n",
      "          \"namespace\": \"apache_beam.options.pipeline_options.PipelineOptions\",\n",
      "          \"type\": \"STRING\",\n",
      "          \"value\": \"gs://nlp-text-classification/stackoverflow/tmp/test-stackoverflow-191129-165617.1575046577.861365\"\n",
      "        },\n",
      "        {\n",
      "          \"key\": \"region\",\n",
      "          \"namespace\": \"apache_beam.options.pipeline_options.PipelineOptions\",\n",
      "          \"type\": \"STRING\",\n",
      "          \"value\": \"us-central1\"\n",
      "        },\n",
      "        {\n",
      "          \"key\": \"experiments\",\n",
      "          \"namespace\": \"apache_beam.options.pipeline_options.PipelineOptions\",\n",
      "          \"type\": \"STRING\",\n",
      "          \"value\": \"['use_fastavro']\"\n",
      "        },\n",
      "        {\n",
      "          \"key\": \"beam_plugins\",\n",
      "          \"namespace\": \"apache_beam.options.pipeline_options.PipelineOptions\",\n",
      "          \"type\": \"STRING\",\n",
      "          \"value\": \"['apache_beam.io.filesystem.FileSystem', 'apache_beam.io.hadoopfilesystem.HadoopFileSystem', 'apache_beam.io.localfilesystem.LocalFileSystem', 'apache_beam.io.gcp.gcsfilesystem.GCSFileSystem']\"\n",
      "        }\n",
      "      ],\n",
      "      \"options\": {\n",
      "        \"beam_plugins\": [\n",
      "          \"apache_beam.io.filesystem.FileSystem\",\n",
      "          \"apache_beam.io.hadoopfilesystem.HadoopFileSystem\",\n",
      "          \"apache_beam.io.localfilesystem.LocalFileSystem\",\n",
      "          \"apache_beam.io.gcp.gcsfilesystem.GCSFileSystem\"\n",
      "        ],\n",
      "        \"dataflow_endpoint\": \"https://dataflow.googleapis.com\",\n",
      "        \"direct_num_workers\": 1,\n",
      "        \"direct_runner_bundle_repeat\": 0,\n",
      "        \"direct_runner_use_stacked_bundle\": true,\n",
      "        \"dry_run\": false,\n",
      "        \"enable_streaming_engine\": false,\n",
      "        \"environment_cache_millis\": 0,\n",
      "        \"experiments\": [\n",
      "          \"use_fastavro\"\n",
      "        ],\n",
      "        \"job_name\": \"test-stackoverflow-191129-165617\",\n",
      "        \"no_auth\": false,\n",
      "        \"pipelineUrl\": \"gs://nlp-text-classification/stackoverflow/tmp/staging/test-stackoverflow-191129-165617.1575046577.861365/pipeline.pb\",\n",
      "        \"pipeline_type_check\": true,\n",
      "        \"profile_cpu\": false,\n",
      "        \"profile_memory\": false,\n",
      "        \"profile_sample_rate\": 1.0,\n",
      "        \"project\": \"nlp-text-classification\",\n",
      "        \"region\": \"us-central1\",\n",
      "        \"runner\": \"DataflowRunner\",\n",
      "        \"runtime_type_check\": false,\n",
      "        \"save_main_session\": false,\n",
      "        \"sdk_location\": \"default\",\n",
      "        \"sdk_worker_parallelism\": 0,\n",
      "        \"staging_location\": \"gs://nlp-text-classification/stackoverflow/tmp/staging/test-stackoverflow-191129-165617.1575046577.861365\",\n",
      "        \"streaming\": false,\n",
      "        \"temp_location\": \"gs://nlp-text-classification/stackoverflow/tmp/test-stackoverflow-191129-165617.1575046577.861365\",\n",
      "        \"type_check_strictness\": \"DEFAULT_TO_ANY\",\n",
      "        \"update\": false\n",
      "      }\n",
      "    },\n",
      "    \"tempStoragePrefix\": \"storage.googleapis.com/nlp-text-classification/stackoverflow/tmp/test-stackoverflow-191129-165617.1575046577.861365\",\n",
      "    \"userAgent\": {\n",
      "      \"name\": \"Apache Beam Python 3.6 SDK\",\n",
      "      \"version\": \"2.16.0\"\n",
      "    },\n",
      "    \"version\": {\n",
      "      \"job_type\": \"PYTHON_BATCH\",\n",
      "      \"major\": \"7\"\n",
      "    },\n",
      "    \"workerPools\": [\n",
      "      {\n",
      "        \"autoscalingSettings\": {},\n",
      "        \"kind\": \"harness\",\n",
      "        \"packages\": [\n",
      "          {\n",
      "            \"location\": \"storage.googleapis.com/nlp-text-classification/stackoverflow/tmp/staging/test-stackoverflow-191129-165617.1575046577.861365/dataflow_python_sdk.tar\",\n",
      "            \"name\": \"dataflow_python_sdk.tar\"\n",
      "          },\n",
      "          {\n",
      "            \"location\": \"storage.googleapis.com/nlp-text-classification/stackoverflow/tmp/staging/test-stackoverflow-191129-165617.1575046577.861365/apache_beam-2.16.0-cp36-cp36m-manylinux1_x86_64.whl\",\n",
      "            \"name\": \"apache_beam-2.16.0-cp36-cp36m-manylinux1_x86_64.whl\"\n",
      "          }\n",
      "        ],\n",
      "        \"taskrunnerSettings\": {\n",
      "          \"parallelWorkerSettings\": {\n",
      "            \"baseUrl\": \"https://dataflow.googleapis.com\",\n",
      "            \"servicePath\": \"https://dataflow.googleapis.com\"\n",
      "          }\n",
      "        },\n",
      "        \"workerHarnessContainerImage\": \"gcr.io/cloud-dataflow/v1beta3/python36:2.16.0\"\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"name\": \"test-stackoverflow-191129-165617\",\n",
      "  \"steps\": [\n",
      "    {\n",
      "      \"kind\": \"ParallelRead\",\n",
      "      \"name\": \"s1\",\n",
      "      \"properties\": {\n",
      "        \"bigquery_export_format\": \"FORMAT_AVRO\",\n",
      "        \"bigquery_flatten_results\": true,\n",
      "        \"bigquery_query\": \"\\n    SELECT\\n    *\\n    FROM\\n    `bigquery-public-data.stackoverflow.tags`\\n    LIMIT 100\\n    \",\n",
      "        \"bigquery_use_legacy_sql\": false,\n",
      "        \"display_data\": [\n",
      "          {\n",
      "            \"key\": \"source\",\n",
      "            \"label\": \"Read Source\",\n",
      "            \"namespace\": \"apache_beam.io.iobase.Read\",\n",
      "            \"shortValue\": \"BigQuerySource\",\n",
      "            \"type\": \"STRING\",\n",
      "            \"value\": \"apache_beam.io.gcp.bigquery.BigQuerySource\"\n",
      "          },\n",
      "          {\n",
      "            \"key\": \"query\",\n",
      "            \"label\": \"Query\",\n",
      "            \"namespace\": \"apache_beam.io.gcp.bigquery.BigQuerySource\",\n",
      "            \"type\": \"STRING\",\n",
      "            \"value\": \"\\n    SELECT\\n    *\\n    FROM\\n    `bigquery-public-data.stackoverflow.tags`\\n    LIMIT 100\\n    \"\n",
      "          },\n",
      "          {\n",
      "            \"key\": \"validation\",\n",
      "            \"label\": \"Validation Enabled\",\n",
      "            \"namespace\": \"apache_beam.io.gcp.bigquery.BigQuerySource\",\n",
      "            \"type\": \"BOOLEAN\",\n",
      "            \"value\": false\n",
      "          }\n",
      "        ],\n",
      "        \"format\": \"bigquery\",\n",
      "        \"output_info\": [\n",
      "          {\n",
      "            \"encoding\": {\n",
      "              \"@type\": \"kind:windowed_value\",\n",
      "              \"component_encodings\": [\n",
      "                {\n",
      "                  \"@type\": \"FastPrimitivesCoder$eNprYE5OLEhMzkiNT0pNzNVLzk9JLSqGUlxuicUlAUWZuZklmWWpxc4gQa5CBs3GQsbaQqYIfgYGhvi0xJycpMTk7HiwlkJ8pgVkJmfnpEJNYQGawlpbyJZUnKQHACYlLgM=\",\n",
      "                  \"component_encodings\": [\n",
      "                    {\n",
      "                      \"@type\": \"FastPrimitivesCoder$eNprYE5OLEhMzkiNT0pNzNVLzk9JLSqGUlxuicUlAUWZuZklmWWpxc4gQa5CBs3GQsbaQqYIfgYGhvi0xJycpMTk7HiwlkJ8pgVkJmfnpEJNYQGawlpbyJZUnKQHACYlLgM=\",\n",
      "                      \"component_encodings\": []\n",
      "                    },\n",
      "                    {\n",
      "                      \"@type\": \"FastPrimitivesCoder$eNprYE5OLEhMzkiNT0pNzNVLzk9JLSqGUlxuicUlAUWZuZklmWWpxc4gQa5CBs3GQsbaQqYIfgYGhvi0xJycpMTk7HiwlkJ8pgVkJmfnpEJNYQGawlpbyJZUnKQHACYlLgM=\",\n",
      "                      \"component_encodings\": []\n",
      "                    }\n",
      "                  ],\n",
      "                  \"is_pair_like\": true\n",
      "                },\n",
      "                {\n",
      "                  \"@type\": \"kind:global_window\"\n",
      "                }\n",
      "              ],\n",
      "              \"is_wrapper\": true\n",
      "            },\n",
      "            \"output_name\": \"out\",\n",
      "            \"user_name\": \"Read from BigQuery.out\"\n",
      "          }\n",
      "        ],\n",
      "        \"user_name\": \"Read from BigQuery\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"kind\": \"ParallelWrite\",\n",
      "      \"name\": \"s2\",\n",
      "      \"properties\": {\n",
      "        \"create_disposition\": \"CREATE_IF_NEEDED\",\n",
      "        \"dataset\": \"test\",\n",
      "        \"display_data\": [],\n",
      "        \"encoding\": {\n",
      "          \"@type\": \"kind:windowed_value\",\n",
      "          \"component_encodings\": [\n",
      "            {\n",
      "              \"@type\": \"RowAsDictJsonCoder$eNprYE5OLEhMzkiNT0pNzNXLzNdLTy7QS8pMLyxNLaqML8nPzynmCsovdyx2yUwu8SrOz3POT0kt4ipk0GwsZKwtZErSAwBK5xfp\",\n",
      "              \"component_encodings\": []\n",
      "            },\n",
      "            {\n",
      "              \"@type\": \"kind:global_window\"\n",
      "            }\n",
      "          ],\n",
      "          \"is_wrapper\": true\n",
      "        },\n",
      "        \"format\": \"bigquery\",\n",
      "        \"parallel_input\": {\n",
      "          \"@type\": \"OutputReference\",\n",
      "          \"output_name\": \"out\",\n",
      "          \"step_name\": \"s1\"\n",
      "        },\n",
      "        \"project\": \"nlp-text-classification\",\n",
      "        \"schema\": \"{\\\"fields\\\": [{\\\"name\\\": \\\"id\\\", \\\"type\\\": \\\"INTEGER\\\", \\\"mode\\\": \\\"NULLABLE\\\"}, {\\\"name\\\": \\\"tag_name\\\", \\\"type\\\": \\\"STRING\\\", \\\"mode\\\": \\\"NULLABLE\\\"}, {\\\"name\\\": \\\"count\\\", \\\"type\\\": \\\"INTEGER\\\", \\\"mode\\\": \\\"NULLABLE\\\"}, {\\\"name\\\": \\\"excerpt_post_id\\\", \\\"type\\\": \\\"INTEGER\\\", \\\"mode\\\": \\\"NULLABLE\\\"}, {\\\"name\\\": \\\"wiki_post_id\\\", \\\"type\\\": \\\"INTEGER\\\", \\\"mode\\\": \\\"NULLABLE\\\"}]}\",\n",
      "        \"table\": \"test_stackoverflow_beam\",\n",
      "        \"user_name\": \"Write to BigQuery/WriteToBigQuery/NativeWrite\",\n",
      "        \"write_disposition\": \"WRITE_TRUNCATE\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"type\": \"JOB_TYPE_BATCH\"\n",
      "}\n",
      "INFO:root:Create job: <Job\n",
      " createTime: '2019-11-29T16:56:24.546474Z'\n",
      " currentStateTime: '1970-01-01T00:00:00Z'\n",
      " id: '2019-11-29_08_56_23-16475436262069206045'\n",
      " location: 'us-central1'\n",
      " name: 'test-stackoverflow-191129-165617'\n",
      " projectId: 'nlp-text-classification'\n",
      " stageStates: []\n",
      " startTime: '2019-11-29T16:56:24.546474Z'\n",
      " steps: []\n",
      " tempFiles: []\n",
      " type: TypeValueValuesEnum(JOB_TYPE_BATCH, 1)>\n",
      "INFO:root:Created job with id: [2019-11-29_08_56_23-16475436262069206045]\n",
      "INFO:root:To access the Dataflow monitoring console, please navigate to https://console.cloud.google.com/dataflow/jobsDetail/locations/us-central1/jobs/2019-11-29_08_56_23-16475436262069206045?project=nlp-text-classification\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    logging.getLogger().setLevel(logging.DEBUG)\n",
    "\n",
    "    print('Starting main process ...')\n",
    "    preprocess()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:env_nlp_text_class]",
   "language": "python",
   "name": "conda-env-env_nlp_text_class-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
