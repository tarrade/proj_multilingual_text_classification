{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# The Stanford Sentiment Treebank \n",
    "The Stanford Sentiment Treebank consists of sentences from movie reviews and human annotations of their sentiment. The task is to predict the sentiment of a given sentence. We use the two-way (positive/negative) class split, and use only sentence-level labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Environment variables that need to be defined:   \n",
       "`export DIR_PROJ=your_path_git_repository`  \n",
       "`export PYTHONPATH=$DIR_PROJ/src`  \n",
       "`export PATH_TENSORBOARD=your_path_tensorboard`  \n",
       "`export PATH_DATASETS=your_path_datasets`  \n",
       "`export PROJECT_ID=your_gcp_project_id`  \n",
       "`export BUCKET_NAME=your_gcp_gs_bucket_name`  \n",
       "`export REGION=your_region`  \n",
       "`export PATH_SAVE_MODEL=your_path_to_save_model` \n",
       "\n",
       "- Use local Jupyter Lab \n",
       "    - you need to have the `jupyter-notebook` Anaconda python environment created [link](local_jupyter_lab_installation.md) \n",
       "    - you need to have the `jupyter-notebook` Anaconda python environment activated [link](local_jupyter_lab_installation.md) \n",
       "    - then define the environment variables above (copy and paste) \n",
       "    - you need to have the `env_multilingual_class` Anaconda python environment created [link](local_jupyter_lab_installation.md)  \n",
       "    - start Jupyter Lab:  `jupyter lab` \n",
       "    - open a Jupyter Lab notebook from `notebook/` \n",
       "     - clone this repositiory: `git clone https://github.com/tarrade/proj_multilingual_text_classification.git`\n",
       "    - choose the proper Anaconda python environment:  `Python [conda env:env_multilingual_class]` [link](conda_env.md) \n",
       "    - clone this repositiory: `git clone https://github.com/tarrade/proj_multilingual_text_classification.git`\n",
       "\n",
       "\n",
       "- Use GCP Jupyter Lab \n",
       "    - Go on GCP\n",
       "    - open a Cloud Shell\n",
       "    - `ssh-keygen -t rsa -b 4096 -C firstName_lastName`\n",
       "    - `cp .ssh/id_rsa.pub .`\n",
       "    - use Cloud Editor to edit this file `id_rsa.pub` and copy the full content\n",
       "    - Go on Compute Engine -> Metadata\n",
       "    - Click SSH Keys\n",
       "    - Click Edit\n",
       "    - Click + Add item, copy the content of `id_rsa.pub`\n",
       "    - You should see firstName_lastName of the left\n",
       "    - Click Save\n",
       "    - you need to start a AI Platform instance \n",
       "    - open a Jupyter Lab terminal and got to `/home/gcp_user_name/`\n",
       "    - clone this repositiory: `git clone https://github.com/tarrade/proj_multilingual_text_classification.git`\n",
       "    - then `cd proj_multilingual_text_classification/`\n",
       "    - create the Anacond Python environment `conda env create -f env/environment.yml`\n",
       "    - create a file `config.sh` in `/home` with the following information: \n",
       "    ```\n",
       "    #!/bin/bash\n",
       "    \n",
       "    echo \"applying some configuration ...\"\n",
       "    git config --global user.email user_email\n",
       "    git config --global user.name user_name\n",
       "    git config --global credential.helper store\n",
       "        \n",
       "    # Add here the enviroment variables from above below\n",
       "    # [EDIT ME]\n",
       "    export DIR_PROJ=your_path_git_repository\n",
       "    export PYTHONPATH=$DIR_PROJ/src\n",
       "  \n",
       "    cd /home/gcp_user_name/\n",
       "    \n",
       "    conda activate env_multilingual_class\n",
       "\n",
       "    export PS1='\\[\\e[91m\\]\\u@:\\[\\e[32m\\]\\w\\[\\e[0m\\]$'\n",
       "    ```\n",
       "    - Got to AI Platform Notebook, select your instance and click \"Reset\".\n",
       "    - Wait and reshreh you Web browser with the Notebook\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "with open('../../doc/env_variables_setup.md', 'r') as fh:\n",
    "    content = fh.read()\n",
    "display(Markdown(content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from transformers import (\n",
    "    BertConfig,\n",
    "    BertTokenizer,\n",
    "    TFBertModel,\n",
    "    TFBertForSequenceClassification,\n",
    "    glue_convert_examples_to_features,\n",
    "    glue_processors\n",
    ")\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import shutil\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v2.2.0-rc1-34-ge6e5d6df2a 2.2.0-rc2\n"
     ]
    }
   ],
   "source": [
    "print(tf.version.GIT_VERSION, tf.version.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0-tf\n"
     ]
    }
   ],
   "source": [
    "print(tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Define Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    data_dir=os.environ['PATH_DATASETS']\n",
    "except KeyError:\n",
    "    print('missing PATH_DATASETS')\n",
    "try:   \n",
    "    tensorboard_dir=os.environ['PATH_TENSORBOARD']\n",
    "except KeyError:\n",
    "    print('missing PATH_TENSORBOARD')\n",
    "try:   \n",
    "    checkpoint_dir=os.environ['PATH_SAVE_MODEL']\n",
    "except KeyError:\n",
    "    print('missing PATH_SAVE_MODEL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Import local packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import preprocessing.preprocessing as pp\n",
    "import utils.model_metrics as mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(pp);\n",
    "importlib.reload(mm);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Loading a data from Tensorflow Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Overwrite dataset info from restored data version.\n",
      "INFO:absl:Reusing dataset glue (/home/fabien_tarrade/data/glue/sst2/1.0.0)\n",
      "INFO:absl:Constructing tf.data.Dataset for split None, from /home/fabien_tarrade/data/glue/sst2/1.0.0\n"
     ]
    }
   ],
   "source": [
    "data, info = tensorflow_datasets.load(name='glue/sst2',\n",
    "                                      data_dir=data_dir,\n",
    "                                      with_info=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Checking baics info from the metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tfds.core.DatasetInfo(\n",
       "    name='glue',\n",
       "    version=1.0.0,\n",
       "    description='GLUE, the General Language Understanding Evaluation benchmark\n",
       "(https://gluebenchmark.com/) is a collection of resources for training,\n",
       "evaluating, and analyzing natural language understanding systems.\n",
       "\n",
       "            The Stanford Sentiment Treebank consists of sentences from movie reviews and\n",
       "            human annotations of their sentiment. The task is to predict the sentiment of a\n",
       "            given sentence. We use the two-way (positive/negative) class split, and use only\n",
       "            sentence-level labels.',\n",
       "    homepage='https://nlp.stanford.edu/sentiment/index.html',\n",
       "    features=FeaturesDict({\n",
       "        'idx': tf.int32,\n",
       "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),\n",
       "        'sentence': Text(shape=(), dtype=tf.string),\n",
       "    }),\n",
       "    total_num_examples=70042,\n",
       "    splits={\n",
       "        'test': 1821,\n",
       "        'train': 67349,\n",
       "        'validation': 872,\n",
       "    },\n",
       "    supervised_keys=None,\n",
       "    citation=\"\"\"@inproceedings{socher2013recursive,\n",
       "                  title={Recursive deep models for semantic compositionality over a sentiment treebank},\n",
       "                  author={Socher, Richard and Perelygin, Alex and Wu, Jean and Chuang, Jason and Manning, Christopher D and Ng, Andrew and Potts, Christopher},\n",
       "                  booktitle={Proceedings of the 2013 conference on empirical methods in natural language processing},\n",
       "                  pages={1631--1642},\n",
       "                  year={2013}\n",
       "                }\n",
       "    @inproceedings{wang2019glue,\n",
       "      title={{GLUE}: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding},\n",
       "      author={Wang, Alex and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel R.},\n",
       "      note={In the Proceedings of ICLR.},\n",
       "      year={2019}\n",
       "    }\n",
       "    \n",
       "    Note that each GLUE dataset has its own citation. Please see the source to see\n",
       "    the correct citation for each contained dataset.\"\"\",\n",
       "    redistribution_info=,\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels:\n",
      "      ['negative', 'positive']\n",
      "\n",
      "Number of label:\n",
      "      2\n",
      "\n",
      "Structure of the data:\n",
      "      dict_keys(['sentence', 'label', 'idx'])\n",
      "\n",
      "Number of entries:\n",
      "   Train dataset: 67349\n",
      "   Test dataset:  1821\n",
      "   Valid dataset: 872\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pp.print_info_dataset(info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Checking baics info from the metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test': <DatasetV1Adapter shapes: {idx: (), label: (), sentence: ()}, types: {idx: tf.int32, label: tf.int64, sentence: tf.string}>,\n",
       " 'train': <DatasetV1Adapter shapes: {idx: (), label: (), sentence: ()}, types: {idx: tf.int32, label: tf.int64, sentence: tf.string}>,\n",
       " 'validation': <DatasetV1Adapter shapes: {idx: (), label: (), sentence: ()}, types: {idx: tf.int32, label: tf.int64, sentence: tf.string}>}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['test', 'train', 'validation'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Structure of the data:\n",
      "\n",
      "   <DatasetV1Adapter shapes: {idx: (), label: (), sentence: ()}, types: {idx: tf.int32, label: tf.int64, sentence: tf.string}>\n",
      "\n",
      "# Output shape of one entry:\n",
      "   {'idx': TensorShape([]), 'label': TensorShape([]), 'sentence': TensorShape([])}\n",
      "\n",
      "# Output types of one entry:\n",
      "   {'idx': tf.int32, 'label': tf.int64, 'sentence': tf.string}\n",
      "\n",
      "# Output typesof one entry:\n",
      "   {'idx': <class 'tensorflow.python.framework.ops.Tensor'>, 'label': <class 'tensorflow.python.framework.ops.Tensor'>, 'sentence': <class 'tensorflow.python.framework.ops.Tensor'>}\n",
      " \n",
      "\n",
      "# Shape of the data:\n",
      "\n",
      "   (67349,)\n",
      "   ---> 67349 entries\n",
      "   ---> 1 dim\n",
      "        dict structure\n",
      "           dim: 3\n",
      "           [idx       / label     / sentence ]\n",
      "           [()        / ()        / ()       ]\n",
      "           [int32     / int64     / bytes    ]\n",
      "\n",
      "\n",
      "# Examples of data:\n",
      "{'idx': 16399,\n",
      " 'label': 0,\n",
      " 'sentence': b'for the uninitiated plays better on video with the sound '}\n",
      "{'idx': 1680,\n",
      " 'label': 0,\n",
      " 'sentence': b'like a giant commercial for universal studios , where much of th'\n",
      "             b'e action takes place '}\n",
      "{'idx': 47917,\n",
      " 'label': 1,\n",
      " 'sentence': b'company once again dazzle and delight us '}\n",
      "{'idx': 17307,\n",
      " 'label': 1,\n",
      " 'sentence': b\"'s no surprise that as a director washington demands and receive\"\n",
      "             b's excellent performances , from himself and from newcomer derek '\n",
      "             b'luke '}\n"
     ]
    }
   ],
   "source": [
    "pp.print_info_data(data['train'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Define parameters of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size:           67349/  1821/   872\n",
      "Batch size:                32/    32/    64\n",
      "Step per epoch:          2105/    57/    29\n",
      "Total number of batch:   6315/   171/    87\n"
     ]
    }
   ],
   "source": [
    "# define parameters\n",
    "BATCH_SIZE_TRAIN = 32\n",
    "BATCH_SIZE_TEST = 32\n",
    "BATCH_SIZE_VALID = 64\n",
    "EPOCH = 2\n",
    "\n",
    "# extract parameters\n",
    "size_train_dataset = info.splits['train'].num_examples\n",
    "size_test_dataset = info.splits['test'].num_examples\n",
    "size_valid_dataset = info.splits['validation'].num_examples\n",
    "number_label = info.features[\"label\"].num_classes\n",
    "\n",
    "# computer parameter\n",
    "STEP_EPOCH_TRAIN = math.ceil(size_train_dataset/BATCH_SIZE_TRAIN)\n",
    "STEP_EPOCH_TEST = math.ceil(size_test_dataset/BATCH_SIZE_TEST)\n",
    "STEP_EPOCH_VALID = math.ceil(size_test_dataset/BATCH_SIZE_VALID)\n",
    "\n",
    "\n",
    "print('Dataset size:          {:6}/{:6}/{:6}'.format(size_train_dataset, size_test_dataset, size_valid_dataset))\n",
    "print('Batch size:            {:6}/{:6}/{:6}'.format(BATCH_SIZE_TRAIN, BATCH_SIZE_TEST, BATCH_SIZE_VALID))\n",
    "print('Step per epoch:        {:6}/{:6}/{:6}'.format(STEP_EPOCH_TRAIN, STEP_EPOCH_TEST, STEP_EPOCH_VALID))\n",
    "print('Total number of batch: {:6}/{:6}/{:6}'.format(STEP_EPOCH_TRAIN*(EPOCH+1), STEP_EPOCH_TEST*(EPOCH+1), STEP_EPOCH_VALID*(EPOCH+1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Tokenizer and prepare data for BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Load tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<DatasetV1Adapter shapes: {idx: (), label: (), sentence: ()}, types: {idx: tf.int32, label: tf.int64, sentence: tf.string}>\n",
      "tf.Tensor(67349, shape=(), dtype=int64)\n",
      "tf.Tensor(1821, shape=(), dtype=int64)\n",
      "tf.Tensor(872, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "# recap of input dataset\n",
    "print(data['train'])\n",
    "print(tf.data.experimental.cardinality(data['train']))\n",
    "print(tf.data.experimental.cardinality(data['test']))\n",
    "print(tf.data.experimental.cardinality(data['validation']))\n",
    "# super slow since looping over all data\n",
    "#print(len(list(data['train'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Prepare data for BERT\n",
    "train_dataset = glue_convert_examples_to_features(data['train'], \n",
    "                                                  tokenizer, \n",
    "                                                  max_length=128, \n",
    "                                                  task='sst-2')\n",
    "test_dataset = glue_convert_examples_to_features(data['test'], \n",
    "                                                  tokenizer, \n",
    "                                                  max_length=128, \n",
    "                                                  task='sst-2')\n",
    "valid_dataset = glue_convert_examples_to_features(data['validation'], \n",
    "                                                  tokenizer, \n",
    "                                                  max_length=128, \n",
    "                                                  task='sst-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FlatMapDataset shapes: ({input_ids: (None,), attention_mask: (None,), token_type_ids: (None,)}, ()), types: ({input_ids: tf.int32, attention_mask: tf.int32, token_type_ids: tf.int32}, tf.int64)>\n",
      "tf.Tensor(-2, shape=(), dtype=int64)\n",
      "tf.Tensor(-2, shape=(), dtype=int64)\n",
      "tf.Tensor(-2, shape=(), dtype=int64)\n",
      "67349\n"
     ]
    }
   ],
   "source": [
    "# recap of pre processing dataset\n",
    "print(train_dataset)\n",
    "print(tf.data.experimental.cardinality(train_dataset))\n",
    "print(tf.data.experimental.cardinality(test_dataset))\n",
    "print(tf.data.experimental.cardinality(valid_dataset))\n",
    "# super slow since looping over all data\n",
    "print(len(list(train_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# set shuffle and batch size\n",
    "train_dataset = train_dataset.shuffle(100).batch(BATCH_SIZE_TRAIN).repeat(EPOCH+1)\n",
    "test_dataset = test_dataset.shuffle(100).batch(BATCH_SIZE_TEST).repeat(EPOCH+1)\n",
    "valid_dataset = valid_dataset.batch(BATCH_SIZE_VALID) #.repeat(EPOCH+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Check the final data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Structure of the data:\n",
      "\n",
      "   <RepeatDataset shapes: ({input_ids: (None, None), attention_mask: (None, None), token_type_ids: (None, None)}, (None,)), types: ({input_ids: tf.int32, attention_mask: tf.int32, token_type_ids: tf.int32}, tf.int64)>\n",
      "\n",
      "# Output shape of one entry:\n",
      "   ({'input_ids': TensorShape([None, None]), 'attention_mask': TensorShape([None, None]), 'token_type_ids': TensorShape([None, None])}, TensorShape([None]))\n",
      "\n",
      "# Output types of one entry:\n",
      "   ({'input_ids': tf.int32, 'attention_mask': tf.int32, 'token_type_ids': tf.int32}, tf.int64)\n",
      "\n",
      "# Output typesof one entry:\n",
      "   ({'input_ids': <class 'tensorflow.python.framework.ops.Tensor'>, 'attention_mask': <class 'tensorflow.python.framework.ops.Tensor'>, 'token_type_ids': <class 'tensorflow.python.framework.ops.Tensor'>}, <class 'tensorflow.python.framework.ops.Tensor'>)\n",
      " \n",
      "\n",
      "# Shape of the data:\n",
      "\n",
      "   (6315, 2)\n",
      "   ---> 6315 batches\n",
      "   ---> 2 dim\n",
      "        label\n",
      "           shape: (32,)\n",
      "        dict structure\n",
      "           dim: 3\n",
      "           [input_ids       / attention_mask  / token_type_ids ]\n",
      "           [(32, 128)       / (32, 128)       / (32, 128)      ]\n",
      "           [ndarray         / ndarray         / ndarray        ]\n"
     ]
    }
   ],
   "source": [
    "pp.print_info_data(train_dataset,print_example=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " input_ids     ---->    attention_mask    token_type_ids    modified text                 \n",
      "\n",
      "       101     ---->           1                 1          [ C L S ]                     \n",
      "      1110     ---->           1                 1          i s                           \n",
      "       170     ---->           1                 1          a                             \n",
      "      1376     ---->           1                 1          l i t t l e                   \n",
      "      1315     ---->           1                 1          t o o                         \n",
      "      1107     ---->           1                 1          i n                           \n",
      "      1567     ---->           1                 1          l o v e                       \n",
      "       102     ---->           1                 1          [ S E P ]                     \n",
      "         0     ---->           0                 0          [ P A D ]                     \n",
      "         0     ---->           0                 0          [ P A D ]                     \n",
      "         0     ---->           0                 0          [ P A D ]                     \n",
      "         0     ---->           0                 0          [ P A D ]                     \n",
      "         0     ---->           0                 0          [ P A D ]                     \n",
      "         0     ---->           0                 0          [ P A D ]                     \n",
      "         0     ---->           0                 0          [ P A D ]                     \n",
      "         0     ---->           0                 0          [ P A D ]                     \n",
      "         0     ---->           0                 0          [ P A D ]                     \n",
      "         0     ---->           0                 0          [ P A D ]                     \n",
      "         0     ---->           0                 0          [ P A D ]                     \n",
      "         0     ---->           0                 0          [ P A D ]                     \n",
      "         0     ---->           0                 0          [ P A D ]                     \n",
      "         0     ---->           0                 0          [ P A D ]                     \n"
     ]
    }
   ],
   "source": [
    "pp.print_detail_tokeniser(train_dataset, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Building a classification model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Define the callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Define the checkpoint directory to store the checkpoints\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_prefix,\n",
    "                                                         save_weights_only=True),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### Decaying learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Function for decaying the learning rate.\n",
    "def decay(epoch):\n",
    "    if epoch < 3:\n",
    "        return 1e-3\n",
    "    elif epoch >= 3 and epoch < 7:\n",
    "        return 1e-4\n",
    "    else:\n",
    "        return 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "decay_callback = tf.keras.callbacks.LearningRateScheduler(decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### Print learning rate at the end of each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Callback for printing the LR at the end of each epoch.\n",
    "class PrintLR(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print('\\nLearning rate for epoch {} is {}'.format(epoch + 1, model.optimizer.lr.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20200331-082115\n"
     ]
    }
   ],
   "source": [
    "# checking existing folders\n",
    "for i in os.listdir(tensorboard_dir):\n",
    "    if os.path.isdir(tensorboard_dir+'/'+i):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20200331-082115\n"
     ]
    }
   ],
   "source": [
    "# clean old TensorBoard directory \n",
    "for i in os.listdir(tensorboard_dir):\n",
    "        if os.path.isdir(tensorboard_dir+'/'+i):\n",
    "            print(i)\n",
    "            shutil.rmtree(tensorboard_dir+'/'+i, ignore_errors=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "log_dir=tensorboard_dir+'/'+datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "os.mkdir(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, \n",
    "                                                      histogram_freq=1, \n",
    "                                                      embeddings_freq=1,\n",
    "                                                      write_graph=True,\n",
    "                                                      update_freq='batch',\n",
    "                                                      profile_batch=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### Loss and efficiency per step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "class History_per_step(tf.keras.callbacks.Callback):\n",
    "    \n",
    "    def __init__(self, validation_data, N):\n",
    "        self.validation_data = validation_data\n",
    "        self.N = N\n",
    "        self.batch = 1\n",
    "\n",
    "    def on_train_begin(self, validation_data, logs={}):\n",
    "        self.steps = []\n",
    "        self.losses = []\n",
    "        self.accuracies = []\n",
    "        self.val_steps = []\n",
    "        self.val_losses = []\n",
    "        self.val_accuracies = []\n",
    "\n",
    "    def on_train_batch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.accuracies.append(logs.get('accuracy'))\n",
    "        self.steps.append(self.batch)\n",
    "        print('\\n training set -> batch:{} loss:{} and acc: {}'.format(self.batch,logs.get('loss'),logs.get('accuracy')))\n",
    "        \n",
    "        if self.batch % self.N == 0:\n",
    "            loss_val, acc_val = self.model.evaluate(self.validation_data, verbose=0)\n",
    "            self.val_losses.append(loss_val)\n",
    "            self.val_accuracies.append(acc_val)\n",
    "            self.val_steps.append(self.batch)\n",
    "            print('\\n validation set -> batch:{} val loss:{} and val acc: {}'.format(self.batch,loss_val, acc_val))\n",
    "\n",
    "        self.batch += 1\n",
    "    \n",
    "    def on_test_batch_end(self, batch, logs={}):    \n",
    "        #print('{}\\n'.format(logs))\n",
    "        return\n",
    "    \n",
    "    def on_epoch_end(self, batch, logs={}): \n",
    "        #print('{}\\n'.format(logs))\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Checks callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelCheckpoint need to unpack this tuple by adding *\n"
     ]
    }
   ],
   "source": [
    "list_callback = [tensorboard_callback, checkpoint_callback, decay_callback]\n",
    "for cb in list_callback:\n",
    "    if type(cb).__name__=='tuple':\n",
    "        print(cb[0].__class__.__name__, 'need to unpack this tuple by adding *')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Use TFBertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of devices: 1\n"
     ]
    }
   ],
   "source": [
    "# Define some parameters\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5, epsilon=1e-08)\n",
    "# Gradient clipping in the optimizer (by setting clipnorm or clipvalue) is currently unsupported when using a distribution strategy\n",
    "# clipnorm=1.0\n",
    "\n",
    "# loss\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "# Uses the tf.distribute.MirroredStrategy, which does in-graph replication with synchronous training on many GPUs on one machine\n",
    "strategy_model_1 = tf.distribute.MirroredStrategy()\n",
    "print('Number of devices: {}'.format(strategy_model_1.num_replicas_in_sync))\n",
    "\n",
    "# create and compile the Keras model in the context of strategy.scope\n",
    "with strategy_model_1.scope():\n",
    "    # metric\n",
    "    metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "    \n",
    "    # model\n",
    "    model_1 = TFBertForSequenceClassification.from_pretrained('bert-base-cased',num_labels=number_label)\n",
    "    #model.layers[-1].activation = tf.keras.activations.softmax\n",
    "    model_1._name='tf_bert_classification'\n",
    "    model_1.compile(optimizer=optimizer,\n",
    "                    loss=loss, \n",
    "                    metrics=[metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_classification\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bert (TFBertMainLayer)       multiple                  108310272 \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "classifier (Dense)           multiple                  1538      \n",
      "=================================================================\n",
      "Total params: 108,311,810\n",
      "Trainable params: 108,311,810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Building a custom classification model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def custom_keras_model(number_classes, bert_model):\n",
    "\n",
    "    # create model\n",
    "    input_layer = tf.keras.Input(shape = (128,), dtype='int64')    \n",
    "    bert_ini = TFBertModel.from_pretrained('bert-base-cased') (input_layer)\n",
    "    # This is because in a bert pretraining progress, there are two tasks: \n",
    "    # masked token prediction and next sentence predition . \n",
    "    # The first needs hidden state of each tokens ( shape: [batch_size, sequence_length, hidden_size]) \n",
    "    # the second needs the embedding of the whole sequence (shape : [batch_size, hidden_size] ) .\n",
    "    bert = bert_ini[1]    \n",
    "    dropout = tf.keras.layers.Dropout(0.1)(bert)\n",
    "    flat = tf.keras.layers.Flatten()(dropout)\n",
    "    classifier = tf.keras.layers.Dense(units=number_classes )(flat) # activation='softmax'               \n",
    "    \n",
    "    model = tf.keras.Model(inputs=input_layer, outputs=classifier, name='custom_tf_bert_classification')\n",
    "\n",
    "    return model, bert_ini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of devices: 1\n"
     ]
    }
   ],
   "source": [
    "# Define some parameters\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5, epsilon=1e-08)\n",
    "# Gradient clipping in the optimizer (by setting clipnorm or clipvalue) is currently unsupported when using a distribution strategy\n",
    "# clipnorm=1.0\n",
    "\n",
    "# loss\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "# Uses the tf.distribute.MirroredStrategy, which does in-graph replication with synchronous training on many GPUs on one machine\n",
    "strategy_model_2 = tf.distribute.MirroredStrategy()\n",
    "print('Number of devices: {}'.format(strategy_model_1.num_replicas_in_sync))\n",
    "\n",
    "# create and compile the Keras model in the context of strategy.scope\n",
    "with strategy_model_2.scope():\n",
    "    # metric\n",
    "    metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "    \n",
    "    # model\n",
    "    model_2, bert_ini = custom_keras_model(number_label, 'bert-base-cased')\n",
    "    model_2.compile(optimizer=optimizer,\n",
    "                    loss=loss, \n",
    "                    metrics=[metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'tf_bert_model/Identity:0' shape=(None, 128, 768) dtype=float32>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_ini[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'tf_bert_model/Identity_1:0' shape=(None, 768) dtype=float32>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_ini[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"custom_tf_bert_classification\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 128)]             0         \n",
      "_________________________________________________________________\n",
      "tf_bert_model (TFBertModel)  ((None, 128, 768), (None, 108310272 \n",
      "_________________________________________________________________\n",
      "dropout_75 (Dropout)         (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 1538      \n",
      "=================================================================\n",
      "Total params: 108,311,810\n",
      "Trainable params: 108,311,810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Choose the model you want to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model's name: tf_bert_classification\n"
     ]
    }
   ],
   "source": [
    "model=model_1\n",
    "print('model\\'s name: {}'.format(model.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-10870e336525a18a\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-10870e336525a18a\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "#%reload_ext tensorboard\n",
    "%tensorboard  --logdir   {log_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Final feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def data_feature_extraction(data, name):\n",
    "    if name=='custom_tf_bert_classification':\n",
    "        print('custom model: {}'.format(name))\n",
    "        return data.map(pp.feature_selection)\n",
    "    elif name=='tf_bert_classification':\n",
    "        print('standard model: {}'.format(name))\n",
    "        return data\n",
    "    else:\n",
    "        print('!!! non defined model !!!!')\n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standard model: tf_bert_classification\n",
      "standard model: tf_bert_classification\n",
      "Epoch 1/2\n",
      "\n",
      " training set -> batch:1 loss:0.6850024461746216 and acc: 0.5625\n",
      "  1/500 [..............................] - ETA: 0s - loss: 0.6850 - accuracy: 0.5625\n",
      " training set -> batch:2 loss:0.688239336013794 and acc: 0.53125\n",
      "  2/500 [..............................] - ETA: 40:56 - loss: 0.6882 - accuracy: 0.5312\n",
      " training set -> batch:3 loss:0.6732398867607117 and acc: 0.5625\n",
      "  3/500 [..............................] - ETA: 53:20 - loss: 0.6732 - accuracy: 0.5625\n",
      " training set -> batch:4 loss:0.6630906462669373 and acc: 0.5859375\n",
      "  4/500 [..............................] - ETA: 59:25 - loss: 0.6631 - accuracy: 0.5859\n",
      " training set -> batch:5 loss:0.6723388433456421 and acc: 0.581250011920929\n",
      "  5/500 [..............................] - ETA: 1:03:07 - loss: 0.6723 - accuracy: 0.5813\n",
      " training set -> batch:6 loss:0.6761485934257507 and acc: 0.5833333134651184\n",
      "  6/500 [..............................] - ETA: 1:05:25 - loss: 0.6761 - accuracy: 0.5833\n",
      " training set -> batch:7 loss:0.6711565256118774 and acc: 0.5803571343421936\n",
      "  7/500 [..............................] - ETA: 1:07:08 - loss: 0.6712 - accuracy: 0.5804\n",
      " training set -> batch:8 loss:0.6563771367073059 and acc: 0.59765625\n",
      "  8/500 [..............................] - ETA: 1:08:15 - loss: 0.6564 - accuracy: 0.5977\n",
      " training set -> batch:9 loss:0.6466162204742432 and acc: 0.6180555820465088\n",
      "  9/500 [..............................] - ETA: 1:09:15 - loss: 0.6466 - accuracy: 0.6181\n",
      " training set -> batch:10 loss:0.6516114473342896 and acc: 0.621874988079071\n",
      " 10/500 [..............................] - ETA: 1:09:59 - loss: 0.6516 - accuracy: 0.6219\n",
      " training set -> batch:11 loss:0.6465807557106018 and acc: 0.6193181872367859\n",
      " 11/500 [..............................] - ETA: 1:10:27 - loss: 0.6466 - accuracy: 0.6193\n",
      " training set -> batch:12 loss:0.6376188397407532 and acc: 0.6276041865348816\n",
      " 12/500 [..............................] - ETA: 1:10:42 - loss: 0.6376 - accuracy: 0.6276\n",
      " training set -> batch:13 loss:0.6339536905288696 and acc: 0.6394230723381042\n",
      " 13/500 [..............................] - ETA: 1:11:00 - loss: 0.6340 - accuracy: 0.6394\n",
      " training set -> batch:14 loss:0.6276934742927551 and acc: 0.6428571343421936\n",
      " 14/500 [..............................] - ETA: 1:11:20 - loss: 0.6277 - accuracy: 0.6429\n",
      " training set -> batch:15 loss:0.6196587085723877 and acc: 0.6541666388511658\n",
      " 15/500 [..............................] - ETA: 1:11:35 - loss: 0.6197 - accuracy: 0.6542\n",
      " training set -> batch:16 loss:0.6144357323646545 and acc: 0.66015625\n",
      " 16/500 [..............................] - ETA: 1:11:52 - loss: 0.6144 - accuracy: 0.6602\n",
      " training set -> batch:17 loss:0.6084052324295044 and acc: 0.6691176295280457\n",
      " 17/500 [>.............................] - ETA: 1:11:57 - loss: 0.6084 - accuracy: 0.6691\n",
      " training set -> batch:18 loss:0.6065433025360107 and acc: 0.6701388955116272\n",
      " 18/500 [>.............................] - ETA: 1:12:03 - loss: 0.6065 - accuracy: 0.6701\n",
      " training set -> batch:19 loss:0.6008191704750061 and acc: 0.6792762875556946\n",
      " 19/500 [>.............................] - ETA: 1:12:09 - loss: 0.6008 - accuracy: 0.6793\n",
      " training set -> batch:21 loss:0.5879517793655396 and acc: 0.6919642686843872\n",
      " 21/500 [>.............................] - ETA: 1:12:13 - loss: 0.5880 - accuracy: 0.6920\n",
      " training set -> batch:22 loss:0.5802650451660156 and acc: 0.6988636255264282\n",
      " 22/500 [>.............................] - ETA: 1:12:09 - loss: 0.5803 - accuracy: 0.6989\n",
      " training set -> batch:23 loss:0.5735981464385986 and acc: 0.70923912525177\n",
      " 23/500 [>.............................] - ETA: 1:12:06 - loss: 0.5736 - accuracy: 0.7092\n",
      " training set -> batch:24 loss:0.5668488144874573 and acc: 0.7161458134651184\n",
      " 24/500 [>.............................] - ETA: 1:12:02 - loss: 0.5668 - accuracy: 0.7161\n",
      " training set -> batch:25 loss:0.5620158314704895 and acc: 0.7174999713897705\n",
      " 25/500 [>.............................] - ETA: 1:11:59 - loss: 0.5620 - accuracy: 0.7175\n",
      " training set -> batch:26 loss:0.5535673499107361 and acc: 0.7247596383094788\n",
      " 26/500 [>.............................] - ETA: 1:11:56 - loss: 0.5536 - accuracy: 0.7248\n",
      " training set -> batch:27 loss:0.5480915307998657 and acc: 0.7303240895271301\n",
      " 27/500 [>.............................] - ETA: 1:11:59 - loss: 0.5481 - accuracy: 0.7303\n",
      " training set -> batch:28 loss:0.5404731035232544 and acc: 0.7366071343421936\n",
      " 28/500 [>.............................] - ETA: 1:11:54 - loss: 0.5405 - accuracy: 0.7366\n",
      " training set -> batch:29 loss:0.5379288196563721 and acc: 0.7381465435028076\n",
      " 29/500 [>.............................] - ETA: 1:11:50 - loss: 0.5379 - accuracy: 0.7381\n",
      " training set -> batch:30 loss:0.5316609740257263 and acc: 0.7427083253860474\n",
      " 30/500 [>.............................] - ETA: 1:11:47 - loss: 0.5317 - accuracy: 0.7427\n",
      " training set -> batch:31 loss:0.5221133828163147 and acc: 0.7489919066429138\n",
      " 31/500 [>.............................] - ETA: 1:11:42 - loss: 0.5221 - accuracy: 0.7490\n",
      " training set -> batch:32 loss:0.5177145600318909 and acc: 0.7509765625\n",
      " 32/500 [>.............................] - ETA: 1:11:35 - loss: 0.5177 - accuracy: 0.7510\n",
      " training set -> batch:33 loss:0.5132155418395996 and acc: 0.7547348737716675\n",
      " 33/500 [>.............................] - ETA: 1:11:29 - loss: 0.5132 - accuracy: 0.7547\n",
      " training set -> batch:34 loss:0.5123893618583679 and acc: 0.7555146813392639\n",
      " 34/500 [=>............................] - ETA: 1:11:21 - loss: 0.5124 - accuracy: 0.7555\n",
      " training set -> batch:35 loss:0.5061889886856079 and acc: 0.7589285969734192\n",
      " 35/500 [=>............................] - ETA: 1:11:15 - loss: 0.5062 - accuracy: 0.7589\n",
      " training set -> batch:36 loss:0.4985184073448181 and acc: 0.7638888955116272\n",
      " 36/500 [=>............................] - ETA: 1:11:08 - loss: 0.4985 - accuracy: 0.7639\n",
      " training set -> batch:37 loss:0.49475422501564026 and acc: 0.7668918967247009\n",
      " 37/500 [=>............................] - ETA: 1:11:03 - loss: 0.4948 - accuracy: 0.7669\n",
      " training set -> batch:38 loss:0.4918135106563568 and acc: 0.7689144611358643\n",
      " 38/500 [=>............................] - ETA: 1:10:55 - loss: 0.4918 - accuracy: 0.7689\n",
      " training set -> batch:39 loss:0.485189288854599 and acc: 0.7724359035491943\n",
      " 39/500 [=>............................] - ETA: 1:10:46 - loss: 0.4852 - accuracy: 0.7724\n",
      " training set -> batch:40 loss:0.4816367030143738 and acc: 0.774218738079071\n",
      " 40/500 [=>............................] - ETA: 1:10:40 - loss: 0.4816 - accuracy: 0.7742\n",
      " training set -> batch:41 loss:0.47939541935920715 and acc: 0.7766768336296082\n",
      " 41/500 [=>............................] - ETA: 1:10:36 - loss: 0.4794 - accuracy: 0.7767\n",
      " training set -> batch:42 loss:0.4744041860103607 and acc: 0.7805059552192688\n",
      " 42/500 [=>............................] - ETA: 1:10:28 - loss: 0.4744 - accuracy: 0.7805\n",
      " training set -> batch:43 loss:0.4741372764110565 and acc: 0.7805232405662537\n",
      " 43/500 [=>............................] - ETA: 1:10:21 - loss: 0.4741 - accuracy: 0.7805\n",
      " training set -> batch:44 loss:0.4712983965873718 and acc: 0.7826704382896423\n",
      " 44/500 [=>............................] - ETA: 1:10:14 - loss: 0.4713 - accuracy: 0.7827\n",
      " training set -> batch:45 loss:0.4674513638019562 and acc: 0.7847222089767456\n",
      " 45/500 [=>............................] - ETA: 1:10:06 - loss: 0.4675 - accuracy: 0.7847\n",
      " training set -> batch:46 loss:0.4647666811943054 and acc: 0.7866848111152649\n",
      " 46/500 [=>............................] - ETA: 1:10:00 - loss: 0.4648 - accuracy: 0.7867\n",
      " training set -> batch:47 loss:0.4620855748653412 and acc: 0.7885638475418091\n",
      " 47/500 [=>............................] - ETA: 1:09:51 - loss: 0.4621 - accuracy: 0.7886\n",
      " training set -> batch:48 loss:0.457181453704834 and acc: 0.7916666865348816\n",
      " 48/500 [=>............................] - ETA: 1:09:43 - loss: 0.4572 - accuracy: 0.7917\n",
      " training set -> batch:49 loss:0.45545047521591187 and acc: 0.7927296161651611\n",
      " 49/500 [=>............................] - ETA: 1:09:36 - loss: 0.4555 - accuracy: 0.7927\n",
      " training set -> batch:50 loss:0.4555150866508484 and acc: 0.793749988079071\n",
      "\n",
      " validation set -> batch:50 val loss:0.42481932044029236 and val acc: 0.8337156176567078\n",
      " 50/500 [==>...........................] - ETA: 1:23:06 - loss: 0.4555 - accuracy: 0.7937\n",
      " training set -> batch:51 loss:0.42390570044517517 and acc: 0.8351770043373108\n",
      " 51/500 [==>...........................] - ETA: 1:22:40 - loss: 0.4239 - accuracy: 0.8352\n",
      " training set -> batch:52 loss:0.4137708246707916 and acc: 0.8365384340286255\n",
      " 52/500 [==>...........................] - ETA: 1:22:14 - loss: 0.4138 - accuracy: 0.8365\n",
      " training set -> batch:53 loss:0.4291698634624481 and acc: 0.8336777091026306\n",
      " 53/500 [==>...........................] - ETA: 1:21:49 - loss: 0.4292 - accuracy: 0.8337\n",
      " training set -> batch:54 loss:0.41996991634368896 and acc: 0.8360000252723694\n",
      " 54/500 [==>...........................] - ETA: 1:21:24 - loss: 0.4200 - accuracy: 0.8360\n",
      " training set -> batch:55 loss:0.41668328642845154 and acc: 0.838178277015686\n",
      " 55/500 [==>...........................] - ETA: 1:21:01 - loss: 0.4167 - accuracy: 0.8382\n",
      " training set -> batch:56 loss:0.4179333746433258 and acc: 0.8355262875556946\n",
      " 56/500 [==>...........................] - ETA: 1:20:38 - loss: 0.4179 - accuracy: 0.8355\n",
      " training set -> batch:57 loss:0.4133041799068451 and acc: 0.8366788029670715\n",
      " 57/500 [==>...........................] - ETA: 1:20:16 - loss: 0.4133 - accuracy: 0.8367\n",
      " training set -> batch:58 loss:0.4096677899360657 and acc: 0.8359929323196411\n",
      " 58/500 [==>...........................] - ETA: 1:19:53 - loss: 0.4097 - accuracy: 0.8360\n",
      " training set -> batch:59 loss:0.4087136387825012 and acc: 0.8379310369491577\n",
      " 59/500 [==>...........................] - ETA: 1:19:31 - loss: 0.4087 - accuracy: 0.8379\n",
      " training set -> batch:60 loss:0.40106555819511414 and acc: 0.8406040072441101\n",
      " 60/500 [==>...........................] - ETA: 1:19:11 - loss: 0.4011 - accuracy: 0.8406\n",
      " training set -> batch:61 loss:0.39624249935150146 and acc: 0.8423202633857727\n",
      " 61/500 [==>...........................] - ETA: 1:18:50 - loss: 0.3962 - accuracy: 0.8423\n",
      " training set -> batch:62 loss:0.3869484066963196 and acc: 0.8455414175987244\n",
      " 62/500 [==>...........................] - ETA: 1:18:30 - loss: 0.3869 - accuracy: 0.8455\n",
      " training set -> batch:63 loss:0.3809777498245239 and acc: 0.8486024737358093\n",
      " 63/500 [==>...........................] - ETA: 1:18:11 - loss: 0.3810 - accuracy: 0.8486\n",
      " training set -> batch:64 loss:0.377311646938324 and acc: 0.8492424488067627\n",
      " 64/500 [==>...........................] - ETA: 1:17:51 - loss: 0.3773 - accuracy: 0.8492\n",
      " training set -> batch:65 loss:0.37156590819358826 and acc: 0.851331353187561\n",
      " 65/500 [==>...........................] - ETA: 1:17:31 - loss: 0.3716 - accuracy: 0.8513\n",
      " training set -> batch:66 loss:0.37033894658088684 and acc: 0.852601170539856\n",
      " 66/500 [==>...........................] - ETA: 1:17:12 - loss: 0.3703 - accuracy: 0.8526\n",
      " training set -> batch:67 loss:0.36851876974105835 and acc: 0.8524011373519897\n",
      " 67/500 [===>..........................] - ETA: 1:16:52 - loss: 0.3685 - accuracy: 0.8524\n",
      " training set -> batch:68 loss:0.3725232779979706 and acc: 0.8508287072181702\n",
      " 68/500 [===>..........................] - ETA: 1:16:35 - loss: 0.3725 - accuracy: 0.8508\n",
      " training set -> batch:69 loss:0.37255024909973145 and acc: 0.8513513803482056\n",
      " 69/500 [===>..........................] - ETA: 1:16:17 - loss: 0.3726 - accuracy: 0.8514\n",
      " training set -> batch:70 loss:0.37089648842811584 and acc: 0.8505290746688843\n",
      " 70/500 [===>..........................] - ETA: 1:16:00 - loss: 0.3709 - accuracy: 0.8505\n",
      " training set -> batch:71 loss:0.3676437437534332 and acc: 0.8510362505912781\n",
      " 71/500 [===>..........................] - ETA: 1:15:42 - loss: 0.3676 - accuracy: 0.8510\n",
      " training set -> batch:72 loss:0.36490461230278015 and acc: 0.8515228629112244\n",
      " 72/500 [===>..........................] - ETA: 1:15:26 - loss: 0.3649 - accuracy: 0.8515\n",
      " training set -> batch:73 loss:0.36529284715652466 and acc: 0.8513681888580322\n",
      " 73/500 [===>..........................] - ETA: 1:15:09 - loss: 0.3653 - accuracy: 0.8514\n",
      " training set -> batch:74 loss:0.36932793259620667 and acc: 0.8500000238418579\n",
      " 74/500 [===>..........................] - ETA: 1:14:51 - loss: 0.3693 - accuracy: 0.8500\n",
      " training set -> batch:75 loss:0.3679346740245819 and acc: 0.8498803973197937\n",
      " 75/500 [===>..........................] - ETA: 1:14:35 - loss: 0.3679 - accuracy: 0.8499\n",
      " training set -> batch:76 loss:0.3666106164455414 and acc: 0.8503521084785461\n",
      " 76/500 [===>..........................] - ETA: 1:14:19 - loss: 0.3666 - accuracy: 0.8504\n",
      " training set -> batch:77 loss:0.3666090667247772 and acc: 0.8496543765068054\n",
      " 77/500 [===>..........................] - ETA: 1:14:02 - loss: 0.3666 - accuracy: 0.8497\n",
      " training set -> batch:78 loss:0.36646735668182373 and acc: 0.8501130938529968\n",
      " 78/500 [===>..........................] - ETA: 1:13:46 - loss: 0.3665 - accuracy: 0.8501\n",
      " training set -> batch:79 loss:0.36933353543281555 and acc: 0.847777783870697\n",
      " 79/500 [===>..........................] - ETA: 1:13:30 - loss: 0.3693 - accuracy: 0.8478\n",
      " training set -> batch:80 loss:0.3718721568584442 and acc: 0.847161591053009\n",
      " 80/500 [===>..........................] - ETA: 1:13:15 - loss: 0.3719 - accuracy: 0.8472\n",
      " training set -> batch:81 loss:0.3721795678138733 and acc: 0.8465664982795715\n",
      " 81/500 [===>..........................] - ETA: 1:12:59 - loss: 0.3722 - accuracy: 0.8466\n",
      " training set -> batch:82 loss:0.37103042006492615 and acc: 0.8459915518760681\n",
      " 82/500 [===>..........................] - ETA: 1:12:43 - loss: 0.3710 - accuracy: 0.8460\n",
      " training set -> batch:83 loss:0.36942818760871887 and acc: 0.8475103974342346\n",
      " 83/500 [===>..........................] - ETA: 1:12:30 - loss: 0.3694 - accuracy: 0.8475\n",
      " training set -> batch:84 loss:0.3687276840209961 and acc: 0.8479591608047485\n",
      " 84/500 [====>.........................] - ETA: 1:12:14 - loss: 0.3687 - accuracy: 0.8480\n",
      " training set -> batch:85 loss:0.37271860241889954 and acc: 0.8448795080184937\n",
      " 85/500 [====>.........................] - ETA: 1:11:59 - loss: 0.3727 - accuracy: 0.8449\n",
      " training set -> batch:86 loss:0.3761666417121887 and acc: 0.8428853750228882\n",
      " 86/500 [====>.........................] - ETA: 1:11:45 - loss: 0.3762 - accuracy: 0.8429\n",
      " training set -> batch:87 loss:0.3751733899116516 and acc: 0.8424124717712402\n",
      " 87/500 [====>.........................] - ETA: 1:11:29 - loss: 0.3752 - accuracy: 0.8424\n",
      " training set -> batch:88 loss:0.37444666028022766 and acc: 0.8429118990898132\n",
      " 88/500 [====>.........................] - ETA: 1:11:15 - loss: 0.3744 - accuracy: 0.8429\n",
      " training set -> batch:89 loss:0.3742114007472992 and acc: 0.8433962464332581\n",
      " 89/500 [====>.........................] - ETA: 1:11:01 - loss: 0.3742 - accuracy: 0.8434\n",
      " training set -> batch:90 loss:0.3729154169559479 and acc: 0.8438661694526672\n",
      " 90/500 [====>.........................] - ETA: 1:10:46 - loss: 0.3729 - accuracy: 0.8439\n",
      " training set -> batch:91 loss:0.37260645627975464 and acc: 0.8438644409179688\n",
      " 91/500 [====>.........................] - ETA: 1:10:32 - loss: 0.3726 - accuracy: 0.8439\n",
      " training set -> batch:92 loss:0.3725937008857727 and acc: 0.8434115648269653\n",
      " 92/500 [====>.........................] - ETA: 1:10:17 - loss: 0.3726 - accuracy: 0.8434\n",
      " training set -> batch:93 loss:0.3752593696117401 and acc: 0.8420818448066711\n",
      " 93/500 [====>.........................] - ETA: 1:10:03 - loss: 0.3753 - accuracy: 0.8421\n",
      " training set -> batch:94 loss:0.37604644894599915 and acc: 0.8416666388511658\n",
      " 94/500 [====>.........................] - ETA: 1:09:50 - loss: 0.3760 - accuracy: 0.8417\n",
      " training set -> batch:95 loss:0.37448474764823914 and acc: 0.8416954874992371\n",
      " 95/500 [====>.........................] - ETA: 1:09:35 - loss: 0.3745 - accuracy: 0.8417\n",
      " training set -> batch:96 loss:0.3738606572151184 and acc: 0.8421501517295837\n",
      " 96/500 [====>.........................] - ETA: 1:09:21 - loss: 0.3739 - accuracy: 0.8422\n",
      " training set -> batch:97 loss:0.37100300192832947 and acc: 0.8434343338012695\n",
      " 97/500 [====>.........................] - ETA: 1:09:07 - loss: 0.3710 - accuracy: 0.8434\n",
      " training set -> batch:98 loss:0.3714791238307953 and acc: 0.8434385657310486\n",
      " 98/500 [====>.........................] - ETA: 1:08:53 - loss: 0.3715 - accuracy: 0.8434\n",
      " training set -> batch:99 loss:0.3740942180156708 and acc: 0.841803252696991\n",
      " 99/500 [====>.........................] - ETA: 1:08:39 - loss: 0.3741 - accuracy: 0.8418\n",
      " training set -> batch:100 loss:0.37354621291160583 and acc: 0.8422330021858215\n",
      "\n",
      " validation set -> batch:100 val loss:0.310955286026001 and val acc: 0.872706413269043\n",
      "100/500 [=====>........................] - ETA: 1:14:30 - loss: 0.3735 - accuracy: 0.8422\n",
      " training set -> batch:101 loss:0.3089205026626587 and acc: 0.872787594795227\n",
      "101/500 [=====>........................] - ETA: 1:14:12 - loss: 0.3089 - accuracy: 0.8728\n",
      " training set -> batch:102 loss:0.29755011200904846 and acc: 0.8760683536529541\n",
      "102/500 [=====>........................] - ETA: 1:13:54 - loss: 0.2976 - accuracy: 0.8761\n",
      " training set -> batch:103 loss:0.29644399881362915 and acc: 0.8760330677032471\n",
      "103/500 [=====>........................] - ETA: 1:13:36 - loss: 0.2964 - accuracy: 0.8760\n",
      " training set -> batch:104 loss:0.3103606402873993 and acc: 0.8709999918937683\n",
      "104/500 [=====>........................] - ETA: 1:13:19 - loss: 0.3104 - accuracy: 0.8710\n",
      " training set -> batch:105 loss:0.3064275085926056 and acc: 0.873062014579773\n",
      "105/500 [=====>........................] - ETA: 1:13:02 - loss: 0.3064 - accuracy: 0.8731\n",
      " training set -> batch:106 loss:0.30820927023887634 and acc: 0.8731203079223633\n",
      "106/500 [=====>........................] - ETA: 1:12:46 - loss: 0.3082 - accuracy: 0.8731\n",
      " training set -> batch:107 loss:0.30142292380332947 and acc: 0.8759124279022217\n",
      "107/500 [=====>........................] - ETA: 1:12:28 - loss: 0.3014 - accuracy: 0.8759\n",
      " training set -> batch:108 loss:0.3042341470718384 and acc: 0.875\n",
      "108/500 [=====>........................] - ETA: 1:12:11 - loss: 0.3042 - accuracy: 0.8750\n",
      " training set -> batch:109 loss:0.30069485306739807 and acc: 0.876724123954773\n",
      "109/500 [=====>........................] - ETA: 1:11:54 - loss: 0.3007 - accuracy: 0.8767\n",
      " training set -> batch:110 loss:0.3019848167896271 and acc: 0.8758389353752136\n",
      "110/500 [=====>........................] - ETA: 1:11:38 - loss: 0.3020 - accuracy: 0.8758\n",
      " training set -> batch:111 loss:0.29914364218711853 and acc: 0.8774510025978088\n",
      "111/500 [=====>........................] - ETA: 1:11:22 - loss: 0.2991 - accuracy: 0.8775\n",
      " training set -> batch:112 loss:0.29869797825813293 and acc: 0.8781847357749939\n",
      "112/500 [=====>........................] - ETA: 1:11:05 - loss: 0.2987 - accuracy: 0.8782\n",
      " training set -> batch:113 loss:0.30047908425331116 and acc: 0.8773291707038879\n",
      "113/500 [=====>........................] - ETA: 1:10:49 - loss: 0.3005 - accuracy: 0.8773\n",
      " training set -> batch:114 loss:0.29920321702957153 and acc: 0.8772727251052856\n",
      "114/500 [=====>........................] - ETA: 1:10:33 - loss: 0.2992 - accuracy: 0.8773\n",
      " training set -> batch:115 loss:0.3076498806476593 and acc: 0.8757396340370178\n",
      "115/500 [=====>........................] - ETA: 1:10:16 - loss: 0.3076 - accuracy: 0.8757\n",
      " training set -> batch:116 loss:0.30321744084358215 and acc: 0.8771676421165466\n",
      "116/500 [=====>........................] - ETA: 1:10:00 - loss: 0.3032 - accuracy: 0.8772\n",
      " training set -> batch:117 loss:0.30445918440818787 and acc: 0.8778248429298401\n",
      "117/500 [======>.......................] - ETA: 1:09:44 - loss: 0.3045 - accuracy: 0.8778\n",
      " training set -> batch:118 loss:0.30457696318626404 and acc: 0.8784530162811279\n",
      "118/500 [======>.......................] - ETA: 1:09:28 - loss: 0.3046 - accuracy: 0.8785\n",
      " training set -> batch:119 loss:0.30106881260871887 and acc: 0.8797297477722168\n",
      "119/500 [======>.......................] - ETA: 1:09:13 - loss: 0.3011 - accuracy: 0.8797\n",
      " training set -> batch:120 loss:0.30312082171440125 and acc: 0.8783068656921387\n",
      "120/500 [======>.......................] - ETA: 1:08:57 - loss: 0.3031 - accuracy: 0.8783\n",
      " training set -> batch:121 loss:0.3043254017829895 and acc: 0.8775906562805176\n",
      "121/500 [======>.......................] - ETA: 1:08:41 - loss: 0.3043 - accuracy: 0.8776\n",
      " training set -> batch:122 loss:0.3043956458568573 and acc: 0.8762690424919128\n",
      "122/500 [======>.......................] - ETA: 1:08:26 - loss: 0.3044 - accuracy: 0.8763\n",
      " training set -> batch:123 loss:0.30296415090560913 and acc: 0.8768656849861145\n",
      "123/500 [======>.......................] - ETA: 1:08:10 - loss: 0.3030 - accuracy: 0.8769\n",
      " training set -> batch:124 loss:0.3049992322921753 and acc: 0.875\n",
      "124/500 [======>.......................] - ETA: 1:07:54 - loss: 0.3050 - accuracy: 0.8750\n",
      " training set -> batch:125 loss:0.3030377924442291 and acc: 0.8755980730056763\n",
      "125/500 [======>.......................] - ETA: 1:07:39 - loss: 0.3030 - accuracy: 0.8756\n",
      " training set -> batch:126 loss:0.2999441921710968 and acc: 0.8773474097251892\n",
      "126/500 [======>.......................] - ETA: 1:07:25 - loss: 0.2999 - accuracy: 0.8773\n",
      " training set -> batch:127 loss:0.29725515842437744 and acc: 0.8778801560401917\n",
      "127/500 [======>.......................] - ETA: 1:07:10 - loss: 0.2973 - accuracy: 0.8779\n",
      " training set -> batch:128 loss:0.2994197905063629 and acc: 0.8772624731063843\n",
      "128/500 [======>.......................] - ETA: 1:06:55 - loss: 0.2994 - accuracy: 0.8773\n",
      " training set -> batch:129 loss:0.29948189854621887 and acc: 0.878333330154419\n",
      "129/500 [======>.......................] - ETA: 1:06:41 - loss: 0.2995 - accuracy: 0.8783\n",
      " training set -> batch:130 loss:0.30017632246017456 and acc: 0.8782750964164734\n",
      "130/500 [======>.......................] - ETA: 1:06:26 - loss: 0.3002 - accuracy: 0.8783\n",
      " training set -> batch:131 loss:0.296384334564209 and acc: 0.8803648352622986\n",
      "131/500 [======>.......................] - ETA: 1:06:12 - loss: 0.2964 - accuracy: 0.8804\n",
      " training set -> batch:132 loss:0.2958223521709442 and acc: 0.8813291192054749\n",
      "132/500 [======>.......................] - ETA: 1:05:58 - loss: 0.2958 - accuracy: 0.8813\n",
      " training set -> batch:133 loss:0.2942996025085449 and acc: 0.8812240958213806\n",
      "133/500 [======>.......................] - ETA: 1:05:43 - loss: 0.2943 - accuracy: 0.8812\n",
      " training set -> batch:134 loss:0.29657748341560364 and acc: 0.8816326260566711\n",
      "134/500 [=======>......................] - ETA: 1:05:29 - loss: 0.2966 - accuracy: 0.8816\n",
      " training set -> batch:135 loss:0.2983425259590149 and acc: 0.8805220723152161\n",
      "135/500 [=======>......................] - ETA: 1:05:15 - loss: 0.2983 - accuracy: 0.8805\n",
      " training set -> batch:136 loss:0.2992672026157379 and acc: 0.8804348111152649\n",
      "136/500 [=======>......................] - ETA: 1:05:01 - loss: 0.2993 - accuracy: 0.8804\n",
      " training set -> batch:137 loss:0.29926183819770813 and acc: 0.880836546421051\n",
      "137/500 [=======>......................] - ETA: 1:04:46 - loss: 0.2993 - accuracy: 0.8808\n",
      " training set -> batch:138 loss:0.29977333545684814 and acc: 0.8802682161331177\n",
      "138/500 [=======>......................] - ETA: 1:04:32 - loss: 0.2998 - accuracy: 0.8803\n",
      " training set -> batch:139 loss:0.29655033349990845 and acc: 0.8816037774085999\n",
      "139/500 [=======>......................] - ETA: 1:04:19 - loss: 0.2966 - accuracy: 0.8816\n",
      " training set -> batch:140 loss:0.29490894079208374 and acc: 0.8819702863693237\n",
      "140/500 [=======>......................] - ETA: 1:04:05 - loss: 0.2949 - accuracy: 0.8820\n",
      " training set -> batch:141 loss:0.2940044403076172 and acc: 0.8818681240081787\n",
      "141/500 [=======>......................] - ETA: 1:03:51 - loss: 0.2940 - accuracy: 0.8819\n",
      " training set -> batch:142 loss:0.295274943113327 and acc: 0.881317675113678\n",
      "142/500 [=======>......................] - ETA: 1:03:37 - loss: 0.2953 - accuracy: 0.8813\n",
      " training set -> batch:143 loss:0.2934994697570801 and acc: 0.8816726207733154\n",
      "143/500 [=======>......................] - ETA: 1:03:23 - loss: 0.2935 - accuracy: 0.8817\n",
      " training set -> batch:144 loss:0.29381486773490906 and acc: 0.8820175528526306\n",
      "144/500 [=======>......................] - ETA: 1:03:10 - loss: 0.2938 - accuracy: 0.8820\n",
      " training set -> batch:145 loss:0.2944938838481903 and acc: 0.8819203972816467\n",
      "145/500 [=======>......................] - ETA: 1:02:56 - loss: 0.2945 - accuracy: 0.8819\n",
      " training set -> batch:146 loss:0.29230862855911255 and acc: 0.8831058144569397\n",
      "146/500 [=======>......................] - ETA: 1:02:42 - loss: 0.2923 - accuracy: 0.8831\n",
      " training set -> batch:147 loss:0.29229357838630676 and acc: 0.8829966187477112\n",
      "147/500 [=======>......................] - ETA: 1:02:29 - loss: 0.2923 - accuracy: 0.8830\n",
      " training set -> batch:148 loss:0.2884683310985565 and acc: 0.884551465511322\n",
      "148/500 [=======>......................] - ETA: 1:02:16 - loss: 0.2885 - accuracy: 0.8846\n",
      " training set -> batch:149 loss:0.28918716311454773 and acc: 0.8844262361526489\n",
      "149/500 [=======>......................] - ETA: 1:02:02 - loss: 0.2892 - accuracy: 0.8844\n",
      " training set -> batch:150 loss:0.2901873290538788 and acc: 0.8847087621688843\n",
      "\n",
      " validation set -> batch:150 val loss:0.32326647639274597 and val acc: 0.8681192398071289\n",
      "150/500 [========>.....................] - ETA: 1:05:20 - loss: 0.2902 - accuracy: 0.8847\n",
      " training set -> batch:151 loss:0.35567301511764526 and acc: 0.8650442361831665\n",
      "151/500 [========>.....................] - ETA: 1:05:05 - loss: 0.3557 - accuracy: 0.8650\n",
      " training set -> batch:152 loss:0.35496416687965393 and acc: 0.8653846383094788\n",
      "152/500 [========>.....................] - ETA: 1:04:50 - loss: 0.3550 - accuracy: 0.8654\n",
      " training set -> batch:153 loss:0.3539748787879944 and acc: 0.8646694421768188\n",
      "153/500 [========>.....................] - ETA: 1:04:35 - loss: 0.3540 - accuracy: 0.8647\n",
      " training set -> batch:154 loss:0.3531041145324707 and acc: 0.8650000095367432\n",
      "154/500 [========>.....................] - ETA: 1:04:21 - loss: 0.3531 - accuracy: 0.8650\n",
      " training set -> batch:155 loss:0.355996698141098 and acc: 0.8643410801887512\n",
      "155/500 [========>.....................] - ETA: 1:04:06 - loss: 0.3560 - accuracy: 0.8643\n",
      " training set -> batch:156 loss:0.34594497084617615 and acc: 0.8656014800071716\n",
      "156/500 [========>.....................] - ETA: 1:03:51 - loss: 0.3459 - accuracy: 0.8656\n",
      " training set -> batch:157 loss:0.3585723638534546 and acc: 0.8631386756896973\n",
      "157/500 [========>.....................] - ETA: 1:03:36 - loss: 0.3586 - accuracy: 0.8631\n",
      " training set -> batch:158 loss:0.35761767625808716 and acc: 0.8617021441459656\n",
      "158/500 [========>.....................] - ETA: 1:03:21 - loss: 0.3576 - accuracy: 0.8617\n",
      " training set -> batch:159 loss:0.3623490631580353 and acc: 0.8603448271751404\n",
      "159/500 [========>.....................] - ETA: 1:03:06 - loss: 0.3623 - accuracy: 0.8603\n",
      " training set -> batch:160 loss:0.36439236998558044 and acc: 0.8607382774353027\n",
      "160/500 [========>.....................] - ETA: 1:02:52 - loss: 0.3644 - accuracy: 0.8607\n",
      " training set -> batch:161 loss:0.3580359220504761 and acc: 0.8627451062202454\n",
      "161/500 [========>.....................] - ETA: 1:02:37 - loss: 0.3580 - accuracy: 0.8627\n",
      " training set -> batch:162 loss:0.3508323132991791 and acc: 0.8646496534347534\n",
      "162/500 [========>.....................] - ETA: 1:02:23 - loss: 0.3508 - accuracy: 0.8646\n",
      " training set -> batch:163 loss:0.34640878438949585 and acc: 0.8664596080780029\n",
      "163/500 [========>.....................] - ETA: 1:02:09 - loss: 0.3464 - accuracy: 0.8665\n",
      " training set -> batch:164 loss:0.34379854798316956 and acc: 0.8681818246841431\n",
      "164/500 [========>.....................] - ETA: 1:01:55 - loss: 0.3438 - accuracy: 0.8682\n",
      " training set -> batch:165 loss:0.33556067943573 and acc: 0.8705621361732483\n",
      "165/500 [========>.....................] - ETA: 1:01:40 - loss: 0.3356 - accuracy: 0.8706\n",
      " training set -> batch:166 loss:0.3351173996925354 and acc: 0.8692196607589722\n",
      "166/500 [========>.....................] - ETA: 1:01:26 - loss: 0.3351 - accuracy: 0.8692\n",
      " training set -> batch:167 loss:0.3349037170410156 and acc: 0.869350254535675\n",
      "167/500 [=========>....................] - ETA: 1:01:11 - loss: 0.3349 - accuracy: 0.8694\n",
      " training set -> batch:168 loss:0.3360653519630432 and acc: 0.8694751262664795\n",
      "168/500 [=========>....................] - ETA: 1:00:58 - loss: 0.3361 - accuracy: 0.8695\n",
      " training set -> batch:169 loss:0.3401286005973816 and acc: 0.8675675392150879\n",
      "169/500 [=========>....................] - ETA: 1:00:44 - loss: 0.3401 - accuracy: 0.8676\n",
      " training set -> batch:170 loss:0.3366696834564209 and acc: 0.8690476417541504\n",
      "170/500 [=========>....................] - ETA: 1:00:29 - loss: 0.3367 - accuracy: 0.8690\n",
      " training set -> batch:171 loss:0.3319738805294037 and acc: 0.8704662919044495\n",
      "171/500 [=========>....................] - ETA: 1:00:15 - loss: 0.3320 - accuracy: 0.8705\n",
      " training set -> batch:172 loss:0.32519352436065674 and acc: 0.8730964660644531\n",
      "172/500 [=========>....................] - ETA: 1:00:02 - loss: 0.3252 - accuracy: 0.8731\n",
      " training set -> batch:173 loss:0.32682982087135315 and acc: 0.8718905448913574\n",
      "173/500 [=========>....................] - ETA: 59:48 - loss: 0.3268 - accuracy: 0.8719  \n",
      " training set -> batch:174 loss:0.32425084710121155 and acc: 0.872560977935791\n",
      "174/500 [=========>....................] - ETA: 59:34 - loss: 0.3243 - accuracy: 0.8726\n",
      " training set -> batch:175 loss:0.3232860267162323 and acc: 0.8726076483726501\n",
      "175/500 [=========>....................] - ETA: 59:21 - loss: 0.3233 - accuracy: 0.8726\n",
      " training set -> batch:176 loss:0.31982097029685974 and acc: 0.873826265335083\n",
      "176/500 [=========>....................] - ETA: 59:07 - loss: 0.3198 - accuracy: 0.8738\n",
      " training set -> batch:177 loss:0.31954678893089294 and acc: 0.8732718825340271\n",
      "177/500 [=========>....................] - ETA: 58:54 - loss: 0.3195 - accuracy: 0.8733\n",
      " training set -> batch:178 loss:0.3192398250102997 and acc: 0.8727375268936157\n",
      "178/500 [=========>....................] - ETA: 58:40 - loss: 0.3192 - accuracy: 0.8727\n",
      " training set -> batch:179 loss:0.3209908902645111 and acc: 0.8722222447395325\n",
      "179/500 [=========>....................] - ETA: 58:26 - loss: 0.3210 - accuracy: 0.8722\n",
      " training set -> batch:180 loss:0.31835103034973145 and acc: 0.8733624219894409\n",
      "180/500 [=========>....................] - ETA: 58:13 - loss: 0.3184 - accuracy: 0.8734\n",
      " training set -> batch:181 loss:0.31589993834495544 and acc: 0.8744634985923767\n",
      "181/500 [=========>....................] - ETA: 57:59 - loss: 0.3159 - accuracy: 0.8745\n",
      " training set -> batch:182 loss:0.3128093481063843 and acc: 0.875\n",
      "182/500 [=========>....................] - ETA: 57:46 - loss: 0.3128 - accuracy: 0.8750\n",
      " training set -> batch:183 loss:0.31705325841903687 and acc: 0.8734439611434937\n",
      "183/500 [=========>....................] - ETA: 57:32 - loss: 0.3171 - accuracy: 0.8734\n",
      " training set -> batch:184 loss:0.3166782557964325 and acc: 0.8739795684814453\n",
      "184/500 [==========>...................] - ETA: 57:19 - loss: 0.3167 - accuracy: 0.8740\n",
      " training set -> batch:185 loss:0.31676918268203735 and acc: 0.8744980096817017\n",
      "185/500 [==========>...................] - ETA: 57:06 - loss: 0.3168 - accuracy: 0.8745\n",
      " training set -> batch:186 loss:0.31349095702171326 and acc: 0.8754940629005432\n",
      "186/500 [==========>...................] - ETA: 56:53 - loss: 0.3135 - accuracy: 0.8755\n",
      " training set -> batch:187 loss:0.3125682473182678 and acc: 0.8754863739013672\n",
      "187/500 [==========>...................] - ETA: 56:39 - loss: 0.3126 - accuracy: 0.8755\n",
      " training set -> batch:188 loss:0.31067150831222534 and acc: 0.8764367699623108\n",
      "188/500 [==========>...................] - ETA: 56:26 - loss: 0.3107 - accuracy: 0.8764\n",
      " training set -> batch:189 loss:0.31198376417160034 and acc: 0.8759434223175049\n",
      "189/500 [==========>...................] - ETA: 56:13 - loss: 0.3120 - accuracy: 0.8759\n",
      " training set -> batch:190 loss:0.3144969642162323 and acc: 0.875\n",
      "190/500 [==========>...................] - ETA: 56:00 - loss: 0.3145 - accuracy: 0.8750\n",
      " training set -> batch:191 loss:0.31599804759025574 and acc: 0.875\n",
      "191/500 [==========>...................] - ETA: 55:48 - loss: 0.3160 - accuracy: 0.8750\n",
      " training set -> batch:192 loss:0.3142871558666229 and acc: 0.875902533531189\n",
      "192/500 [==========>...................] - ETA: 55:35 - loss: 0.3143 - accuracy: 0.8759\n",
      " training set -> batch:193 loss:0.3164483308792114 and acc: 0.8754448294639587\n",
      "193/500 [==========>...................] - ETA: 55:22 - loss: 0.3164 - accuracy: 0.8754\n",
      " training set -> batch:194 loss:0.3168366849422455 and acc: 0.8745614290237427\n",
      "194/500 [==========>...................] - ETA: 55:09 - loss: 0.3168 - accuracy: 0.8746\n",
      " training set -> batch:195 loss:0.3145940601825714 and acc: 0.875432550907135\n",
      "195/500 [==========>...................] - ETA: 54:57 - loss: 0.3146 - accuracy: 0.8754\n",
      " training set -> batch:196 loss:0.3121372163295746 and acc: 0.876279890537262\n",
      "196/500 [==========>...................] - ETA: 54:44 - loss: 0.3121 - accuracy: 0.8763\n",
      " training set -> batch:197 loss:0.31078040599823 and acc: 0.8762626051902771\n",
      "197/500 [==========>...................] - ETA: 54:31 - loss: 0.3108 - accuracy: 0.8763\n",
      " training set -> batch:198 loss:0.31078705191612244 and acc: 0.8766611218452454\n",
      "198/500 [==========>...................] - ETA: 54:18 - loss: 0.3108 - accuracy: 0.8767\n",
      " training set -> batch:199 loss:0.3091227412223816 and acc: 0.8770492076873779\n",
      "199/500 [==========>...................] - ETA: 54:05 - loss: 0.3091 - accuracy: 0.8770\n",
      " training set -> batch:200 loss:0.3074740171432495 and acc: 0.8782362341880798\n",
      "\n",
      " validation set -> batch:200 val loss:0.2514605224132538 and val acc: 0.8979358077049255\n",
      "200/500 [===========>..................] - ETA: 56:10 - loss: 0.3075 - accuracy: 0.8782\n",
      " training set -> batch:201 loss:0.2537631392478943 and acc: 0.8982300758361816\n",
      "201/500 [===========>..................] - ETA: 55:56 - loss: 0.2538 - accuracy: 0.8982\n",
      " training set -> batch:202 loss:0.24838721752166748 and acc: 0.9006410241127014\n",
      "202/500 [===========>..................] - ETA: 55:42 - loss: 0.2484 - accuracy: 0.9006\n",
      " training set -> batch:203 loss:0.24602781236171722 and acc: 0.9018595218658447\n",
      "203/500 [===========>..................] - ETA: 55:29 - loss: 0.2460 - accuracy: 0.9019\n",
      " training set -> batch:204 loss:0.24578849971294403 and acc: 0.902999997138977\n",
      "204/500 [===========>..................] - ETA: 55:15 - loss: 0.2458 - accuracy: 0.9030\n",
      " training set -> batch:205 loss:0.2480272799730301 and acc: 0.9031007885932922\n",
      "205/500 [===========>..................] - ETA: 55:01 - loss: 0.2480 - accuracy: 0.9031\n",
      " training set -> batch:206 loss:0.24307815730571747 and acc: 0.9031955003738403\n",
      "206/500 [===========>..................] - ETA: 54:47 - loss: 0.2431 - accuracy: 0.9032\n",
      " training set -> batch:207 loss:0.24336767196655273 and acc: 0.9032846689224243\n",
      "207/500 [===========>..................] - ETA: 54:33 - loss: 0.2434 - accuracy: 0.9033\n",
      " training set -> batch:208 loss:0.2434641271829605 and acc: 0.9033687710762024\n",
      "208/500 [===========>..................] - ETA: 54:20 - loss: 0.2435 - accuracy: 0.9034\n",
      " training set -> batch:209 loss:0.24033722281455994 and acc: 0.9034482836723328\n",
      "209/500 [===========>..................] - ETA: 54:06 - loss: 0.2403 - accuracy: 0.9034\n",
      " training set -> batch:210 loss:0.2534228265285492 and acc: 0.9001677632331848\n",
      "210/500 [===========>..................] - ETA: 53:52 - loss: 0.2534 - accuracy: 0.9002\n",
      " training set -> batch:211 loss:0.2711889147758484 and acc: 0.8970588445663452\n",
      "211/500 [===========>..................] - ETA: 53:39 - loss: 0.2712 - accuracy: 0.8971\n",
      " training set -> batch:212 loss:0.2641441524028778 and acc: 0.8988853693008423\n",
      "212/500 [===========>..................] - ETA: 53:26 - loss: 0.2641 - accuracy: 0.8989\n",
      " training set -> batch:213 loss:0.2629348933696747 and acc: 0.899068295955658\n",
      "213/500 [===========>..................] - ETA: 53:12 - loss: 0.2629 - accuracy: 0.8991\n",
      " training set -> batch:214 loss:0.26260051131248474 and acc: 0.8999999761581421\n",
      "214/500 [===========>..................] - ETA: 52:59 - loss: 0.2626 - accuracy: 0.9000\n",
      " training set -> batch:215 loss:0.26118361949920654 and acc: 0.8994082808494568\n",
      "215/500 [===========>..................] - ETA: 52:45 - loss: 0.2612 - accuracy: 0.8994\n",
      " training set -> batch:216 loss:0.25924691557884216 and acc: 0.900288999080658\n",
      "216/500 [===========>..................] - ETA: 52:32 - loss: 0.2592 - accuracy: 0.9003\n",
      " training set -> batch:217 loss:0.26870599389076233 and acc: 0.8990113139152527\n",
      "217/500 [============>.................] - ETA: 52:19 - loss: 0.2687 - accuracy: 0.8990\n",
      " training set -> batch:218 loss:0.2682092785835266 and acc: 0.8977900743484497\n",
      "218/500 [============>.................] - ETA: 52:06 - loss: 0.2682 - accuracy: 0.8978\n",
      " training set -> batch:219 loss:0.2683970630168915 and acc: 0.8979730010032654\n",
      "219/500 [============>.................] - ETA: 51:53 - loss: 0.2684 - accuracy: 0.8980\n",
      " training set -> batch:220 loss:0.26416242122650146 and acc: 0.898809552192688\n",
      "220/500 [============>.................] - ETA: 51:40 - loss: 0.2642 - accuracy: 0.8988\n",
      " training set -> batch:221 loss:0.2719861567020416 and acc: 0.897020697593689\n",
      "221/500 [============>.................] - ETA: 51:26 - loss: 0.2720 - accuracy: 0.8970\n",
      " training set -> batch:222 loss:0.27249622344970703 and acc: 0.8959391117095947\n",
      "222/500 [============>.................] - ETA: 51:13 - loss: 0.2725 - accuracy: 0.8959\n",
      " training set -> batch:223 loss:0.2739415168762207 and acc: 0.89552241563797\n",
      "223/500 [============>.................] - ETA: 51:00 - loss: 0.2739 - accuracy: 0.8955\n",
      " training set -> batch:224 loss:0.2811422049999237 and acc: 0.8926829099655151\n",
      "224/500 [============>.................] - ETA: 50:47 - loss: 0.2811 - accuracy: 0.8927\n",
      " training set -> batch:225 loss:0.2789284288883209 and acc: 0.8935406804084778\n",
      "225/500 [============>.................] - ETA: 50:34 - loss: 0.2789 - accuracy: 0.8935\n",
      " training set -> batch:226 loss:0.27830690145492554 and acc: 0.8931924700737\n",
      "226/500 [============>.................] - ETA: 50:21 - loss: 0.2783 - accuracy: 0.8932\n",
      " training set -> batch:227 loss:0.27831965684890747 and acc: 0.8928571343421936\n",
      "227/500 [============>.................] - ETA: 50:09 - loss: 0.2783 - accuracy: 0.8929\n",
      " training set -> batch:228 loss:0.27844560146331787 and acc: 0.8930995464324951\n",
      "228/500 [============>.................] - ETA: 49:56 - loss: 0.2784 - accuracy: 0.8931\n",
      " training set -> batch:229 loss:0.28108498454093933 and acc: 0.8916666507720947\n",
      "229/500 [============>.................] - ETA: 49:43 - loss: 0.2811 - accuracy: 0.8917\n",
      " training set -> batch:230 loss:0.2778679430484772 and acc: 0.8924672603607178\n",
      "230/500 [============>.................] - ETA: 49:30 - loss: 0.2779 - accuracy: 0.8925\n",
      " training set -> batch:231 loss:0.27693289518356323 and acc: 0.8937768340110779\n",
      "231/500 [============>.................] - ETA: 49:18 - loss: 0.2769 - accuracy: 0.8938\n",
      " training set -> batch:232 loss:0.27595457434654236 and acc: 0.8939873576164246\n",
      "232/500 [============>.................] - ETA: 49:05 - loss: 0.2760 - accuracy: 0.8940\n",
      " training set -> batch:233 loss:0.2773464620113373 and acc: 0.8931535482406616\n",
      "233/500 [============>.................] - ETA: 48:52 - loss: 0.2773 - accuracy: 0.8932\n",
      " training set -> batch:234 loss:0.27780595421791077 and acc: 0.893367350101471\n",
      "234/500 [=============>................] - ETA: 48:39 - loss: 0.2778 - accuracy: 0.8934\n",
      " training set -> batch:235 loss:0.2765871286392212 and acc: 0.8935742974281311\n",
      "235/500 [=============>................] - ETA: 48:27 - loss: 0.2766 - accuracy: 0.8936\n",
      " training set -> batch:236 loss:0.2761126160621643 and acc: 0.893774688243866\n",
      "236/500 [=============>................] - ETA: 48:14 - loss: 0.2761 - accuracy: 0.8938\n",
      " training set -> batch:237 loss:0.274718314409256 and acc: 0.8939688801765442\n",
      "237/500 [=============>................] - ETA: 48:02 - loss: 0.2747 - accuracy: 0.8940\n",
      " training set -> batch:238 loss:0.27345898747444153 and acc: 0.8946360349655151\n",
      "238/500 [=============>................] - ETA: 47:49 - loss: 0.2735 - accuracy: 0.8946\n",
      " training set -> batch:239 loss:0.2713821828365326 and acc: 0.895283043384552\n",
      "239/500 [=============>................] - ETA: 47:37 - loss: 0.2714 - accuracy: 0.8953\n",
      " training set -> batch:240 loss:0.2715199887752533 and acc: 0.8949813842773438\n",
      "240/500 [=============>................] - ETA: 47:24 - loss: 0.2715 - accuracy: 0.8950\n",
      " training set -> batch:241 loss:0.2705584466457367 and acc: 0.8956043720245361\n",
      "241/500 [=============>................] - ETA: 47:12 - loss: 0.2706 - accuracy: 0.8956\n",
      " training set -> batch:242 loss:0.26876121759414673 and acc: 0.8962093591690063\n",
      "242/500 [=============>................] - ETA: 46:59 - loss: 0.2688 - accuracy: 0.8962\n",
      " training set -> batch:243 loss:0.26751741766929626 and acc: 0.8963522911071777\n",
      "243/500 [=============>................] - ETA: 46:47 - loss: 0.2675 - accuracy: 0.8964\n",
      " training set -> batch:244 loss:0.26553112268447876 and acc: 0.8973684310913086\n",
      "244/500 [=============>................] - ETA: 46:35 - loss: 0.2655 - accuracy: 0.8974\n",
      " training set -> batch:245 loss:0.2624073624610901 and acc: 0.8987889289855957\n",
      "245/500 [=============>................] - ETA: 46:22 - loss: 0.2624 - accuracy: 0.8988\n",
      " training set -> batch:246 loss:0.2627308964729309 and acc: 0.8988907933235168\n",
      "246/500 [=============>................] - ETA: 46:10 - loss: 0.2627 - accuracy: 0.8989\n",
      " training set -> batch:247 loss:0.2632996737957001 and acc: 0.8989899158477783\n",
      "247/500 [=============>................] - ETA: 45:58 - loss: 0.2633 - accuracy: 0.8990\n",
      " training set -> batch:248 loss:0.2611616551876068 and acc: 0.89991694688797\n",
      "248/500 [=============>................] - ETA: 45:45 - loss: 0.2612 - accuracy: 0.8999\n",
      " training set -> batch:249 loss:0.25901567935943604 and acc: 0.9004098176956177\n",
      "249/500 [=============>................] - ETA: 45:33 - loss: 0.2590 - accuracy: 0.9004\n",
      " training set -> batch:250 loss:0.25667649507522583 and acc: 0.901294469833374\n",
      "\n",
      " validation set -> batch:250 val loss:0.2646074593067169 and val acc: 0.8899082541465759\n",
      "250/500 [==============>...............] - ETA: 46:52 - loss: 0.2567 - accuracy: 0.9013\n",
      " training set -> batch:251 loss:0.252691388130188 and acc: 0.8938053250312805\n",
      "251/500 [==============>...............] - ETA: 46:39 - loss: 0.2527 - accuracy: 0.8938\n",
      " training set -> batch:252 loss:0.2455502599477768 and acc: 0.8963675498962402\n",
      "252/500 [==============>...............] - ETA: 46:26 - loss: 0.2456 - accuracy: 0.8964\n",
      " training set -> batch:253 loss:0.26555174589157104 and acc: 0.89462810754776\n",
      "253/500 [==============>...............] - ETA: 46:13 - loss: 0.2656 - accuracy: 0.8946\n",
      " training set -> batch:254 loss:0.2791038155555725 and acc: 0.8930000066757202\n",
      "254/500 [==============>...............] - ETA: 46:00 - loss: 0.2791 - accuracy: 0.8930\n",
      " training set -> batch:255 loss:0.2801746129989624 and acc: 0.893410861492157\n",
      "255/500 [==============>...............] - ETA: 45:47 - loss: 0.2802 - accuracy: 0.8934\n",
      " training set -> batch:256 loss:0.283012330532074 and acc: 0.893796980381012\n",
      "256/500 [==============>...............] - ETA: 45:34 - loss: 0.2830 - accuracy: 0.8938\n",
      " training set -> batch:257 loss:0.2860890030860901 and acc: 0.8932482004165649\n",
      "257/500 [==============>...............] - ETA: 45:21 - loss: 0.2861 - accuracy: 0.8932\n",
      " training set -> batch:258 loss:0.2780875563621521 and acc: 0.8953900933265686\n",
      "258/500 [==============>...............] - ETA: 45:09 - loss: 0.2781 - accuracy: 0.8954\n",
      " training set -> batch:259 loss:0.2689909040927887 and acc: 0.8982758522033691\n",
      "259/500 [==============>...............] - ETA: 44:56 - loss: 0.2690 - accuracy: 0.8983\n",
      " training set -> batch:260 loss:0.2681216299533844 and acc: 0.8984899520874023\n",
      "260/500 [==============>...............] - ETA: 44:43 - loss: 0.2681 - accuracy: 0.8985\n",
      " training set -> batch:261 loss:0.2650940418243408 and acc: 0.898692786693573\n",
      "261/500 [==============>...............] - ETA: 44:31 - loss: 0.2651 - accuracy: 0.8987\n",
      " training set -> batch:262 loss:0.26203280687332153 and acc: 0.8996815085411072\n",
      "262/500 [==============>...............] - ETA: 44:18 - loss: 0.2620 - accuracy: 0.8997\n",
      " training set -> batch:263 loss:0.2615293264389038 and acc: 0.899068295955658\n",
      "263/500 [==============>...............] - ETA: 44:05 - loss: 0.2615 - accuracy: 0.8991\n",
      " training set -> batch:264 loss:0.2648906409740448 and acc: 0.8977272510528564\n",
      "264/500 [==============>...............] - ETA: 43:52 - loss: 0.2649 - accuracy: 0.8977\n",
      " training set -> batch:265 loss:0.25893542170524597 and acc: 0.8994082808494568\n",
      "265/500 [==============>...............] - ETA: 43:40 - loss: 0.2589 - accuracy: 0.8994\n",
      " training set -> batch:266 loss:0.2589649558067322 and acc: 0.900288999080658\n",
      "266/500 [==============>...............] - ETA: 43:27 - loss: 0.2590 - accuracy: 0.9003\n",
      " training set -> batch:267 loss:0.2587423622608185 and acc: 0.8997175097465515\n",
      "267/500 [===============>..............] - ETA: 43:15 - loss: 0.2587 - accuracy: 0.8997\n",
      " training set -> batch:268 loss:0.2536458373069763 and acc: 0.9012430906295776\n",
      "268/500 [===============>..............] - ETA: 43:02 - loss: 0.2536 - accuracy: 0.9012\n",
      " training set -> batch:269 loss:0.254351407289505 and acc: 0.9006756544113159\n",
      "269/500 [===============>..............] - ETA: 42:50 - loss: 0.2544 - accuracy: 0.9007\n",
      " training set -> batch:270 loss:0.261705219745636 and acc: 0.8961640000343323\n",
      "270/500 [===============>..............] - ETA: 42:37 - loss: 0.2617 - accuracy: 0.8962\n",
      " training set -> batch:271 loss:0.26862525939941406 and acc: 0.893782377243042\n",
      "271/500 [===============>..............] - ETA: 42:25 - loss: 0.2686 - accuracy: 0.8938\n",
      " training set -> batch:272 loss:0.26766422390937805 and acc: 0.8946700692176819\n",
      "272/500 [===============>..............] - ETA: 42:12 - loss: 0.2677 - accuracy: 0.8947\n",
      " training set -> batch:273 loss:0.2657686471939087 and acc: 0.8949005007743835\n",
      "273/500 [===============>..............] - ETA: 42:00 - loss: 0.2658 - accuracy: 0.8949\n",
      " training set -> batch:274 loss:0.2628810703754425 and acc: 0.8963414430618286\n",
      "274/500 [===============>..............] - ETA: 41:48 - loss: 0.2629 - accuracy: 0.8963\n",
      " training set -> batch:275 loss:0.2589682936668396 and acc: 0.8983253836631775\n",
      "275/500 [===============>..............] - ETA: 41:35 - loss: 0.2590 - accuracy: 0.8983\n",
      " training set -> batch:276 loss:0.26035019755363464 and acc: 0.8973004817962646\n",
      "276/500 [===============>..............] - ETA: 41:23 - loss: 0.2604 - accuracy: 0.8973\n",
      " training set -> batch:277 loss:0.2570713460445404 and acc: 0.8986175060272217\n",
      "277/500 [===============>..............] - ETA: 41:11 - loss: 0.2571 - accuracy: 0.8986\n",
      " training set -> batch:278 loss:0.2606711983680725 and acc: 0.8953620195388794\n",
      "278/500 [===============>..............] - ETA: 40:58 - loss: 0.2607 - accuracy: 0.8954\n",
      " training set -> batch:279 loss:0.26634377241134644 and acc: 0.894444465637207\n",
      "279/500 [===============>..............] - ETA: 40:46 - loss: 0.2663 - accuracy: 0.8944\n",
      " training set -> batch:280 loss:0.26764264702796936 and acc: 0.8946506381034851\n",
      "280/500 [===============>..............] - ETA: 40:34 - loss: 0.2676 - accuracy: 0.8947\n",
      " training set -> batch:281 loss:0.26681554317474365 and acc: 0.8948497772216797\n",
      "281/500 [===============>..............] - ETA: 40:22 - loss: 0.2668 - accuracy: 0.8948\n",
      " training set -> batch:282 loss:0.2641671299934387 and acc: 0.8960970640182495\n",
      "282/500 [===============>..............] - ETA: 40:10 - loss: 0.2642 - accuracy: 0.8961\n",
      " training set -> batch:283 loss:0.2622494101524353 and acc: 0.896784245967865\n",
      "283/500 [===============>..............] - ETA: 39:57 - loss: 0.2622 - accuracy: 0.8968\n",
      " training set -> batch:284 loss:0.2664528787136078 and acc: 0.8948979377746582\n",
      "284/500 [================>.............] - ETA: 39:45 - loss: 0.2665 - accuracy: 0.8949\n",
      " training set -> batch:285 loss:0.2637031078338623 and acc: 0.8960843086242676\n",
      "285/500 [================>.............] - ETA: 39:33 - loss: 0.2637 - accuracy: 0.8961\n",
      " training set -> batch:286 loss:0.26701053977012634 and acc: 0.8942687511444092\n",
      "286/500 [================>.............] - ETA: 39:21 - loss: 0.2670 - accuracy: 0.8943\n",
      " training set -> batch:287 loss:0.2643645703792572 and acc: 0.8954280018806458\n",
      "287/500 [================>.............] - ETA: 39:09 - loss: 0.2644 - accuracy: 0.8954\n",
      " training set -> batch:288 loss:0.26306986808776855 and acc: 0.8955938816070557\n",
      "288/500 [================>.............] - ETA: 38:57 - loss: 0.2631 - accuracy: 0.8956\n",
      " training set -> batch:289 loss:0.26213353872299194 and acc: 0.8962264060974121\n",
      "289/500 [================>.............] - ETA: 38:44 - loss: 0.2621 - accuracy: 0.8962\n",
      " training set -> batch:290 loss:0.2634981572628021 and acc: 0.8959107995033264\n",
      "290/500 [================>.............] - ETA: 38:32 - loss: 0.2635 - accuracy: 0.8959\n",
      " training set -> batch:291 loss:0.26244962215423584 and acc: 0.8965201377868652\n",
      "291/500 [================>.............] - ETA: 38:20 - loss: 0.2624 - accuracy: 0.8965\n",
      " training set -> batch:292 loss:0.2626354396343231 and acc: 0.8962093591690063\n",
      "292/500 [================>.............] - ETA: 38:08 - loss: 0.2626 - accuracy: 0.8962\n",
      " training set -> batch:293 loss:0.26101014018058777 and acc: 0.89724200963974\n",
      "293/500 [================>.............] - ETA: 37:56 - loss: 0.2610 - accuracy: 0.8972\n",
      " training set -> batch:294 loss:0.2609131336212158 and acc: 0.8969298005104065\n",
      "294/500 [================>.............] - ETA: 37:44 - loss: 0.2609 - accuracy: 0.8969\n",
      " training set -> batch:295 loss:0.26087895035743713 and acc: 0.8966262936592102\n",
      "295/500 [================>.............] - ETA: 37:32 - loss: 0.2609 - accuracy: 0.8966\n",
      " training set -> batch:296 loss:0.2587226331233978 and acc: 0.8976109027862549\n",
      "296/500 [================>.............] - ETA: 37:20 - loss: 0.2587 - accuracy: 0.8976\n",
      " training set -> batch:297 loss:0.2559928596019745 and acc: 0.8985690474510193\n",
      "297/500 [================>.............] - ETA: 37:08 - loss: 0.2560 - accuracy: 0.8986\n",
      " training set -> batch:298 loss:0.2545972764492035 and acc: 0.8990863561630249\n",
      "298/500 [================>.............] - ETA: 36:56 - loss: 0.2546 - accuracy: 0.8991\n",
      " training set -> batch:299 loss:0.25281041860580444 and acc: 0.8995901346206665\n",
      "299/500 [================>.............] - ETA: 36:44 - loss: 0.2528 - accuracy: 0.8996\n",
      " training set -> batch:300 loss:0.25250008702278137 and acc: 0.8996763825416565\n",
      "\n",
      " validation set -> batch:300 val loss:0.25163161754608154 and val acc: 0.896789014339447\n",
      "300/500 [=================>............] - ETA: 37:33 - loss: 0.2525 - accuracy: 0.8997\n",
      " training set -> batch:301 loss:0.2537415325641632 and acc: 0.8971238732337952\n",
      "301/500 [=================>............] - ETA: 37:21 - loss: 0.2537 - accuracy: 0.8971\n",
      " training set -> batch:302 loss:0.2562805414199829 and acc: 0.8974359035491943\n",
      "302/500 [=================>............] - ETA: 37:08 - loss: 0.2563 - accuracy: 0.8974\n",
      " training set -> batch:303 loss:0.24990564584732056 and acc: 0.8997933864593506\n",
      "303/500 [=================>............] - ETA: 36:56 - loss: 0.2499 - accuracy: 0.8998\n",
      " training set -> batch:304 loss:0.25690850615501404 and acc: 0.8980000019073486\n",
      "304/500 [=================>............] - ETA: 36:43 - loss: 0.2569 - accuracy: 0.8980\n",
      " training set -> batch:305 loss:0.24917422235012054 and acc: 0.8992248177528381\n",
      "305/500 [=================>............] - ETA: 36:31 - loss: 0.2492 - accuracy: 0.8992\n",
      " training set -> batch:306 loss:0.2565935254096985 and acc: 0.8975563645362854\n",
      "306/500 [=================>............] - ETA: 36:18 - loss: 0.2566 - accuracy: 0.8976\n",
      " training set -> batch:307 loss:0.2547895014286041 and acc: 0.8987226486206055\n",
      "307/500 [=================>............] - ETA: 36:06 - loss: 0.2548 - accuracy: 0.8987\n",
      " training set -> batch:308 loss:0.24676965177059174 and acc: 0.9007092118263245\n",
      "308/500 [=================>............] - ETA: 35:54 - loss: 0.2468 - accuracy: 0.9007\n",
      " training set -> batch:309 loss:0.2495747059583664 and acc: 0.8999999761581421\n",
      "309/500 [=================>............] - ETA: 35:42 - loss: 0.2496 - accuracy: 0.9000\n",
      " training set -> batch:310 loss:0.25018107891082764 and acc: 0.9010066986083984\n",
      "310/500 [=================>............] - ETA: 35:29 - loss: 0.2502 - accuracy: 0.9010\n",
      " training set -> batch:311 loss:0.24752755463123322 and acc: 0.9003267884254456\n",
      "311/500 [=================>............] - ETA: 35:17 - loss: 0.2475 - accuracy: 0.9003\n",
      " training set -> batch:312 loss:0.24608835577964783 and acc: 0.8996815085411072\n",
      "312/500 [=================>............] - ETA: 35:05 - loss: 0.2461 - accuracy: 0.8997\n",
      " training set -> batch:313 loss:0.24939168989658356 and acc: 0.8998447060585022\n",
      "313/500 [=================>............] - ETA: 34:52 - loss: 0.2494 - accuracy: 0.8998\n",
      " training set -> batch:314 loss:0.2472703456878662 and acc: 0.9007575511932373\n",
      "314/500 [=================>............] - ETA: 34:40 - loss: 0.2473 - accuracy: 0.9008\n",
      " training set -> batch:315 loss:0.24584046006202698 and acc: 0.901627242565155\n",
      "315/500 [=================>............] - ETA: 34:28 - loss: 0.2458 - accuracy: 0.9016\n",
      " training set -> batch:316 loss:0.2426021695137024 and acc: 0.9024566411972046\n",
      "316/500 [=================>............] - ETA: 34:16 - loss: 0.2426 - accuracy: 0.9025\n",
      " training set -> batch:317 loss:0.25962355732917786 and acc: 0.8983050584793091\n",
      "317/500 [==================>...........] - ETA: 34:04 - loss: 0.2596 - accuracy: 0.8983\n",
      " training set -> batch:318 loss:0.2602560818195343 and acc: 0.8977900743484497\n",
      "318/500 [==================>...........] - ETA: 33:52 - loss: 0.2603 - accuracy: 0.8978\n",
      " training set -> batch:319 loss:0.2606348991394043 and acc: 0.8972973227500916\n",
      "319/500 [==================>...........] - ETA: 33:40 - loss: 0.2606 - accuracy: 0.8973\n",
      " training set -> batch:320 loss:0.2574865221977234 and acc: 0.898809552192688\n",
      "320/500 [==================>...........] - ETA: 33:27 - loss: 0.2575 - accuracy: 0.8988\n",
      " training set -> batch:321 loss:0.26182305812835693 and acc: 0.8963730335235596\n",
      "321/500 [==================>...........] - ETA: 33:15 - loss: 0.2618 - accuracy: 0.8964\n",
      " training set -> batch:322 loss:0.25914257764816284 and acc: 0.8965736031532288\n",
      "322/500 [==================>...........] - ETA: 33:03 - loss: 0.2591 - accuracy: 0.8966\n",
      " training set -> batch:323 loss:0.2600100636482239 and acc: 0.896766185760498\n",
      "323/500 [==================>...........] - ETA: 32:51 - loss: 0.2600 - accuracy: 0.8968\n",
      " training set -> batch:324 loss:0.2577468752861023 and acc: 0.8969511985778809\n",
      "324/500 [==================>...........] - ETA: 32:39 - loss: 0.2577 - accuracy: 0.8970\n",
      " training set -> batch:325 loss:0.256552129983902 and acc: 0.8971291780471802\n",
      "325/500 [==================>...........] - ETA: 32:27 - loss: 0.2566 - accuracy: 0.8971\n",
      " training set -> batch:326 loss:0.25752055644989014 and acc: 0.8973004817962646\n",
      "326/500 [==================>...........] - ETA: 32:15 - loss: 0.2575 - accuracy: 0.8973\n",
      " training set -> batch:327 loss:0.25972115993499756 and acc: 0.8968893885612488\n",
      "327/500 [==================>...........] - ETA: 32:03 - loss: 0.2597 - accuracy: 0.8969\n",
      " training set -> batch:328 loss:0.26230165362358093 and acc: 0.8959276080131531\n",
      "328/500 [==================>...........] - ETA: 31:52 - loss: 0.2623 - accuracy: 0.8959\n",
      " training set -> batch:329 loss:0.2630077004432678 and acc: 0.8955555558204651\n",
      "329/500 [==================>...........] - ETA: 31:40 - loss: 0.2630 - accuracy: 0.8956\n",
      " training set -> batch:330 loss:0.2648114860057831 and acc: 0.8930131196975708\n",
      "330/500 [==================>...........] - ETA: 31:28 - loss: 0.2648 - accuracy: 0.8930\n",
      " training set -> batch:331 loss:0.2650112211704254 and acc: 0.8927038908004761\n",
      "331/500 [==================>...........] - ETA: 31:16 - loss: 0.2650 - accuracy: 0.8927\n",
      " training set -> batch:332 loss:0.26481035351753235 and acc: 0.892405092716217\n",
      "332/500 [==================>...........] - ETA: 31:04 - loss: 0.2648 - accuracy: 0.8924\n",
      " training set -> batch:333 loss:0.2646315097808838 and acc: 0.8936722278594971\n",
      "333/500 [==================>...........] - ETA: 30:52 - loss: 0.2646 - accuracy: 0.8937\n",
      " training set -> batch:334 loss:0.2626494765281677 and acc: 0.8943877816200256\n",
      "334/500 [===================>..........] - ETA: 30:41 - loss: 0.2626 - accuracy: 0.8944\n",
      " training set -> batch:335 loss:0.26271650195121765 and acc: 0.8945783376693726\n",
      "335/500 [===================>..........] - ETA: 30:29 - loss: 0.2627 - accuracy: 0.8946\n",
      " training set -> batch:336 loss:0.26675236225128174 and acc: 0.8932806253433228\n",
      "336/500 [===================>..........] - ETA: 30:17 - loss: 0.2668 - accuracy: 0.8933\n",
      " training set -> batch:337 loss:0.2707080543041229 and acc: 0.8915369510650635\n",
      "337/500 [===================>..........] - ETA: 30:05 - loss: 0.2707 - accuracy: 0.8915\n",
      " training set -> batch:338 loss:0.26789590716362 and acc: 0.8927202820777893\n",
      "338/500 [===================>..........] - ETA: 29:53 - loss: 0.2679 - accuracy: 0.8927\n",
      " training set -> batch:339 loss:0.2666736841201782 and acc: 0.8929245471954346\n",
      "339/500 [===================>..........] - ETA: 29:41 - loss: 0.2667 - accuracy: 0.8929\n",
      " training set -> batch:340 loss:0.26602646708488464 and acc: 0.8935873508453369\n",
      "340/500 [===================>..........] - ETA: 29:29 - loss: 0.2660 - accuracy: 0.8936\n",
      " training set -> batch:341 loss:0.26365581154823303 and acc: 0.8946886658668518\n",
      "341/500 [===================>..........] - ETA: 29:18 - loss: 0.2637 - accuracy: 0.8947\n",
      " training set -> batch:342 loss:0.2650218605995178 and acc: 0.8944043517112732\n",
      "342/500 [===================>..........] - ETA: 29:06 - loss: 0.2650 - accuracy: 0.8944\n",
      " training set -> batch:343 loss:0.2640485167503357 and acc: 0.8945729732513428\n",
      "343/500 [===================>..........] - ETA: 28:54 - loss: 0.2640 - accuracy: 0.8946\n",
      " training set -> batch:344 loss:0.2651074528694153 and acc: 0.894298255443573\n",
      "344/500 [===================>..........] - ETA: 28:42 - loss: 0.2651 - accuracy: 0.8943\n",
      " training set -> batch:345 loss:0.2662692964076996 and acc: 0.8940311670303345\n",
      "345/500 [===================>..........] - ETA: 28:31 - loss: 0.2663 - accuracy: 0.8940\n",
      " training set -> batch:346 loss:0.26380470395088196 and acc: 0.8950511813163757\n",
      "346/500 [===================>..........] - ETA: 28:19 - loss: 0.2638 - accuracy: 0.8951\n",
      " training set -> batch:347 loss:0.26355159282684326 and acc: 0.8956229090690613\n",
      "347/500 [===================>..........] - ETA: 28:07 - loss: 0.2636 - accuracy: 0.8956\n",
      " training set -> batch:348 loss:0.26428768038749695 and acc: 0.894518256187439\n",
      "348/500 [===================>..........] - ETA: 27:56 - loss: 0.2643 - accuracy: 0.8945\n",
      " training set -> batch:349 loss:0.263937771320343 and acc: 0.8950819969177246\n",
      "349/500 [===================>..........] - ETA: 27:44 - loss: 0.2639 - accuracy: 0.8951\n",
      " training set -> batch:350 loss:0.26299017667770386 and acc: 0.8952265381813049\n",
      "\n",
      " validation set -> batch:350 val loss:0.2550548017024994 and val acc: 0.8864678740501404\n",
      "350/500 [====================>.........] - ETA: 28:11 - loss: 0.2630 - accuracy: 0.8952\n",
      " training set -> batch:351 loss:0.25898605585098267 and acc: 0.88606196641922\n",
      "351/500 [====================>.........] - ETA: 28:00 - loss: 0.2590 - accuracy: 0.8861\n",
      " training set -> batch:352 loss:0.2551446557044983 and acc: 0.8878205418586731\n",
      "352/500 [====================>.........] - ETA: 27:48 - loss: 0.2551 - accuracy: 0.8878\n",
      " training set -> batch:353 loss:0.24977877736091614 and acc: 0.8884297609329224\n",
      "353/500 [====================>.........] - ETA: 27:35 - loss: 0.2498 - accuracy: 0.8884\n",
      " training set -> batch:354 loss:0.24812732636928558 and acc: 0.8880000114440918\n",
      "354/500 [====================>.........] - ETA: 27:23 - loss: 0.2481 - accuracy: 0.8880\n",
      " training set -> batch:355 loss:0.23994295299053192 and acc: 0.8905038833618164\n",
      "355/500 [====================>.........] - ETA: 27:11 - loss: 0.2399 - accuracy: 0.8905\n",
      " training set -> batch:356 loss:0.23618097603321075 and acc: 0.8919172883033752\n",
      "356/500 [====================>.........] - ETA: 26:59 - loss: 0.2362 - accuracy: 0.8919\n",
      " training set -> batch:357 loss:0.23325768113136292 and acc: 0.8941605687141418\n",
      "357/500 [====================>.........] - ETA: 26:47 - loss: 0.2333 - accuracy: 0.8942\n",
      " training set -> batch:358 loss:0.23362575471401215 and acc: 0.8936170339584351\n",
      "358/500 [====================>.........] - ETA: 26:36 - loss: 0.2336 - accuracy: 0.8936\n",
      " training set -> batch:359 loss:0.23397758603096008 and acc: 0.8931034207344055\n",
      "359/500 [====================>.........] - ETA: 26:24 - loss: 0.2340 - accuracy: 0.8931\n",
      " training set -> batch:360 loss:0.23605775833129883 and acc: 0.8942952752113342\n",
      "360/500 [====================>.........] - ETA: 26:12 - loss: 0.2361 - accuracy: 0.8943\n",
      " training set -> batch:361 loss:0.23059414327144623 and acc: 0.8970588445663452\n",
      "361/500 [====================>.........] - ETA: 26:00 - loss: 0.2306 - accuracy: 0.8971\n",
      " training set -> batch:362 loss:0.22668789327144623 and acc: 0.8980891704559326\n",
      "362/500 [====================>.........] - ETA: 25:48 - loss: 0.2267 - accuracy: 0.8981\n",
      " training set -> batch:363 loss:0.22219926118850708 and acc: 0.9006211161613464\n",
      "363/500 [====================>.........] - ETA: 25:36 - loss: 0.2222 - accuracy: 0.9006\n",
      " training set -> batch:364 loss:0.21811310946941376 and acc: 0.9022727012634277\n",
      "364/500 [====================>.........] - ETA: 25:25 - loss: 0.2181 - accuracy: 0.9023\n",
      " training set -> batch:365 loss:0.21849040687084198 and acc: 0.9008875489234924\n",
      "365/500 [====================>.........] - ETA: 25:13 - loss: 0.2185 - accuracy: 0.9009\n",
      " training set -> batch:366 loss:0.2159520834684372 and acc: 0.9024566411972046\n",
      "366/500 [====================>.........] - ETA: 25:01 - loss: 0.2160 - accuracy: 0.9025\n",
      " training set -> batch:367 loss:0.21662971377372742 and acc: 0.9025423526763916\n",
      "367/500 [=====================>........] - ETA: 24:49 - loss: 0.2166 - accuracy: 0.9025\n",
      " training set -> batch:368 loss:0.21920624375343323 and acc: 0.9026243090629578\n",
      "368/500 [=====================>........] - ETA: 24:37 - loss: 0.2192 - accuracy: 0.9026\n",
      " training set -> batch:369 loss:0.22325295209884644 and acc: 0.9020270109176636\n",
      "369/500 [=====================>........] - ETA: 24:26 - loss: 0.2233 - accuracy: 0.9020\n",
      " training set -> batch:370 loss:0.2183251827955246 and acc: 0.9041005373001099\n",
      "370/500 [=====================>........] - ETA: 24:14 - loss: 0.2183 - accuracy: 0.9041\n",
      " training set -> batch:371 loss:0.22028470039367676 and acc: 0.9047927260398865\n",
      "371/500 [=====================>........] - ETA: 24:02 - loss: 0.2203 - accuracy: 0.9048\n",
      " training set -> batch:372 loss:0.21791812777519226 and acc: 0.9054568409919739\n",
      "372/500 [=====================>........] - ETA: 23:50 - loss: 0.2179 - accuracy: 0.9055\n",
      " training set -> batch:373 loss:0.22138391435146332 and acc: 0.9042288661003113\n",
      "373/500 [=====================>........] - ETA: 23:39 - loss: 0.2214 - accuracy: 0.9042\n",
      " training set -> batch:374 loss:0.2190365344285965 and acc: 0.9054877758026123\n",
      "374/500 [=====================>........] - ETA: 23:27 - loss: 0.2190 - accuracy: 0.9055\n",
      " training set -> batch:375 loss:0.22916065156459808 and acc: 0.9037081599235535\n",
      "375/500 [=====================>........] - ETA: 23:15 - loss: 0.2292 - accuracy: 0.9037\n",
      " training set -> batch:376 loss:0.22670789062976837 and acc: 0.9049295783042908\n",
      "376/500 [=====================>........] - ETA: 23:03 - loss: 0.2267 - accuracy: 0.9049\n",
      " training set -> batch:377 loss:0.22334043681621552 and acc: 0.9061059951782227\n",
      "377/500 [=====================>........] - ETA: 22:52 - loss: 0.2233 - accuracy: 0.9061\n",
      " training set -> batch:378 loss:0.22208647429943085 and acc: 0.9061086177825928\n",
      "378/500 [=====================>........] - ETA: 22:40 - loss: 0.2221 - accuracy: 0.9061\n",
      " training set -> batch:379 loss:0.2213418185710907 and acc: 0.9066666960716248\n",
      "379/500 [=====================>........] - ETA: 22:28 - loss: 0.2213 - accuracy: 0.9067\n",
      " training set -> batch:380 loss:0.2183915674686432 and acc: 0.9072052240371704\n",
      "380/500 [=====================>........] - ETA: 22:17 - loss: 0.2184 - accuracy: 0.9072\n",
      " training set -> batch:381 loss:0.21679161489009857 and acc: 0.908261775970459\n",
      "381/500 [=====================>........] - ETA: 22:05 - loss: 0.2168 - accuracy: 0.9083\n",
      " training set -> batch:382 loss:0.21767657995224 and acc: 0.9087553024291992\n",
      "382/500 [=====================>........] - ETA: 21:53 - loss: 0.2177 - accuracy: 0.9088\n",
      " training set -> batch:383 loss:0.2194339632987976 and acc: 0.9081950187683105\n",
      "383/500 [=====================>........] - ETA: 21:42 - loss: 0.2194 - accuracy: 0.9082\n",
      " training set -> batch:384 loss:0.22115124762058258 and acc: 0.9076530337333679\n",
      "384/500 [======================>.......] - ETA: 21:30 - loss: 0.2212 - accuracy: 0.9077\n",
      " training set -> batch:385 loss:0.22206130623817444 and acc: 0.9081325531005859\n",
      "385/500 [======================>.......] - ETA: 21:19 - loss: 0.2221 - accuracy: 0.9081\n",
      " training set -> batch:386 loss:0.22503799200057983 and acc: 0.9071146249771118\n",
      "386/500 [======================>.......] - ETA: 21:07 - loss: 0.2250 - accuracy: 0.9071\n",
      " training set -> batch:387 loss:0.22453637421131134 and acc: 0.9071011543273926\n",
      "387/500 [======================>.......] - ETA: 20:55 - loss: 0.2245 - accuracy: 0.9071\n",
      " training set -> batch:388 loss:0.22570094466209412 and acc: 0.9070881009101868\n",
      "388/500 [======================>.......] - ETA: 20:44 - loss: 0.2257 - accuracy: 0.9071\n",
      " training set -> batch:389 loss:0.22418710589408875 and acc: 0.9075471758842468\n",
      "389/500 [======================>.......] - ETA: 20:32 - loss: 0.2242 - accuracy: 0.9075\n",
      " training set -> batch:390 loss:0.22694629430770874 and acc: 0.9065985083580017\n",
      "390/500 [======================>.......] - ETA: 20:21 - loss: 0.2269 - accuracy: 0.9066\n",
      " training set -> batch:391 loss:0.22649528086185455 and acc: 0.906593382358551\n",
      "391/500 [======================>.......] - ETA: 20:09 - loss: 0.2265 - accuracy: 0.9066\n",
      " training set -> batch:392 loss:0.22552892565727234 and acc: 0.9070397019386292\n",
      "392/500 [======================>.......] - ETA: 19:58 - loss: 0.2255 - accuracy: 0.9070\n",
      " training set -> batch:393 loss:0.22570060193538666 and acc: 0.9065836071968079\n",
      "393/500 [======================>.......] - ETA: 19:46 - loss: 0.2257 - accuracy: 0.9066\n",
      " training set -> batch:394 loss:0.22699788212776184 and acc: 0.9061403274536133\n",
      "394/500 [======================>.......] - ETA: 19:35 - loss: 0.2270 - accuracy: 0.9061\n",
      " training set -> batch:395 loss:0.22858023643493652 and acc: 0.9052768349647522\n",
      "395/500 [======================>.......] - ETA: 19:23 - loss: 0.2286 - accuracy: 0.9053\n",
      " training set -> batch:396 loss:0.23066926002502441 and acc: 0.9048634767532349\n",
      "396/500 [======================>.......] - ETA: 19:12 - loss: 0.2307 - accuracy: 0.9049\n",
      " training set -> batch:397 loss:0.23088163137435913 and acc: 0.9048821330070496\n",
      "397/500 [======================>.......] - ETA: 19:00 - loss: 0.2309 - accuracy: 0.9049\n",
      " training set -> batch:398 loss:0.2306029349565506 and acc: 0.904900312423706\n",
      "398/500 [======================>.......] - ETA: 18:49 - loss: 0.2306 - accuracy: 0.9049\n",
      " training set -> batch:399 loss:0.23319819569587708 and acc: 0.9045081734657288\n",
      "399/500 [======================>.......] - ETA: 18:37 - loss: 0.2332 - accuracy: 0.9045\n",
      " training set -> batch:400 loss:0.23318709433078766 and acc: 0.9041262269020081\n",
      "\n",
      " validation set -> batch:400 val loss:0.24505086243152618 and val acc: 0.8853210806846619\n",
      "400/500 [=======================>......] - ETA: 18:49 - loss: 0.2332 - accuracy: 0.9041\n",
      " training set -> batch:401 loss:0.2509893774986267 and acc: 0.88606196641922\n",
      "401/500 [=======================>......] - ETA: 18:37 - loss: 0.2510 - accuracy: 0.8861\n",
      " training set -> batch:402 loss:0.24725717306137085 and acc: 0.8878205418586731\n",
      "402/500 [=======================>......] - ETA: 18:25 - loss: 0.2473 - accuracy: 0.8878\n",
      " training set -> batch:403 loss:0.23899297416210175 and acc: 0.8915289044380188\n",
      "403/500 [=======================>......] - ETA: 18:14 - loss: 0.2390 - accuracy: 0.8915\n",
      " training set -> batch:404 loss:0.2399706095457077 and acc: 0.890999972820282\n",
      "404/500 [=======================>......] - ETA: 18:02 - loss: 0.2400 - accuracy: 0.8910\n",
      " training set -> batch:405 loss:0.2499077171087265 and acc: 0.8885658979415894\n",
      "405/500 [=======================>......] - ETA: 17:50 - loss: 0.2499 - accuracy: 0.8886\n",
      " training set -> batch:406 loss:0.25312545895576477 and acc: 0.8862782120704651\n",
      "406/500 [=======================>......] - ETA: 17:38 - loss: 0.2531 - accuracy: 0.8863\n",
      " training set -> batch:407 loss:0.24820634722709656 and acc: 0.8877737522125244\n",
      "407/500 [=======================>......] - ETA: 17:27 - loss: 0.2482 - accuracy: 0.8878\n",
      " training set -> batch:408 loss:0.2550281286239624 and acc: 0.8856382966041565\n",
      "408/500 [=======================>......] - ETA: 17:15 - loss: 0.2550 - accuracy: 0.8856\n",
      " training set -> batch:409 loss:0.25150129199028015 and acc: 0.8862069249153137\n",
      "409/500 [=======================>......] - ETA: 17:04 - loss: 0.2515 - accuracy: 0.8862\n",
      " training set -> batch:410 loss:0.2517010271549225 and acc: 0.8850671052932739\n",
      "410/500 [=======================>......] - ETA: 16:52 - loss: 0.2517 - accuracy: 0.8851\n",
      " training set -> batch:411 loss:0.25436991453170776 and acc: 0.8856208920478821\n",
      "411/500 [=======================>......] - ETA: 16:40 - loss: 0.2544 - accuracy: 0.8856\n",
      " training set -> batch:412 loss:0.25076672434806824 and acc: 0.887738823890686\n",
      "412/500 [=======================>......] - ETA: 16:29 - loss: 0.2508 - accuracy: 0.8877\n",
      " training set -> batch:413 loss:0.2540932893753052 and acc: 0.885869562625885\n",
      "413/500 [=======================>......] - ETA: 16:17 - loss: 0.2541 - accuracy: 0.8859\n",
      " training set -> batch:414 loss:0.2545921504497528 and acc: 0.8848484754562378\n",
      "414/500 [=======================>......] - ETA: 16:06 - loss: 0.2546 - accuracy: 0.8848\n",
      " training set -> batch:415 loss:0.252031147480011 and acc: 0.8860946893692017\n",
      "415/500 [=======================>......] - ETA: 15:54 - loss: 0.2520 - accuracy: 0.8861\n",
      " training set -> batch:416 loss:0.2539345622062683 and acc: 0.8858381509780884\n",
      "416/500 [=======================>......] - ETA: 15:42 - loss: 0.2539 - accuracy: 0.8858\n",
      " training set -> batch:417 loss:0.25575190782546997 and acc: 0.8855932354927063\n",
      "417/500 [========================>.....] - ETA: 15:31 - loss: 0.2558 - accuracy: 0.8856\n",
      " training set -> batch:418 loss:0.25516974925994873 and acc: 0.886049747467041\n",
      "418/500 [========================>.....] - ETA: 15:19 - loss: 0.2552 - accuracy: 0.8860\n",
      " training set -> batch:419 loss:0.2518809735774994 and acc: 0.887837827205658\n",
      "419/500 [========================>.....] - ETA: 15:08 - loss: 0.2519 - accuracy: 0.8878\n",
      " training set -> batch:420 loss:0.24931301176548004 and acc: 0.8888888955116272\n",
      "420/500 [========================>.....] - ETA: 14:56 - loss: 0.2493 - accuracy: 0.8889\n",
      " training set -> batch:421 loss:0.2483658641576767 and acc: 0.8898963928222656\n",
      "421/500 [========================>.....] - ETA: 14:45 - loss: 0.2484 - accuracy: 0.8899\n",
      " training set -> batch:422 loss:0.24832981824874878 and acc: 0.8908629417419434\n",
      "422/500 [========================>.....] - ETA: 14:33 - loss: 0.2483 - accuracy: 0.8909\n",
      " training set -> batch:423 loss:0.2444346398115158 and acc: 0.8924129605293274\n",
      "423/500 [========================>.....] - ETA: 14:22 - loss: 0.2444 - accuracy: 0.8924\n",
      " training set -> batch:424 loss:0.24408410489559174 and acc: 0.8914633989334106\n",
      "424/500 [========================>.....] - ETA: 14:10 - loss: 0.2441 - accuracy: 0.8915\n",
      " training set -> batch:425 loss:0.23895122110843658 and acc: 0.8935406804084778\n",
      "425/500 [========================>.....] - ETA: 13:59 - loss: 0.2390 - accuracy: 0.8935\n",
      " training set -> batch:426 loss:0.24042050540447235 and acc: 0.8937793374061584\n",
      "426/500 [========================>.....] - ETA: 13:47 - loss: 0.2404 - accuracy: 0.8938\n",
      " training set -> batch:427 loss:0.24197925627231598 and acc: 0.893433153629303\n",
      "427/500 [========================>.....] - ETA: 13:36 - loss: 0.2420 - accuracy: 0.8934\n",
      " training set -> batch:428 loss:0.24246132373809814 and acc: 0.8925339579582214\n",
      "428/500 [========================>.....] - ETA: 13:25 - loss: 0.2425 - accuracy: 0.8925\n",
      " training set -> batch:429 loss:0.24527551233768463 and acc: 0.8922222256660461\n",
      "429/500 [========================>.....] - ETA: 13:13 - loss: 0.2453 - accuracy: 0.8922\n",
      " training set -> batch:430 loss:0.24827145040035248 and acc: 0.8908296823501587\n",
      "430/500 [========================>.....] - ETA: 13:02 - loss: 0.2483 - accuracy: 0.8908\n",
      " training set -> batch:431 loss:0.24787406623363495 and acc: 0.891094446182251\n",
      "431/500 [========================>.....] - ETA: 12:50 - loss: 0.2479 - accuracy: 0.8911\n",
      " training set -> batch:432 loss:0.24413642287254333 and acc: 0.892405092716217\n",
      "432/500 [========================>.....] - ETA: 12:39 - loss: 0.2441 - accuracy: 0.8924\n",
      " training set -> batch:433 loss:0.24329964816570282 and acc: 0.8931535482406616\n",
      "433/500 [========================>.....] - ETA: 12:27 - loss: 0.2433 - accuracy: 0.8932\n",
      " training set -> batch:434 loss:0.24223218858242035 and acc: 0.8943877816200256\n",
      "434/500 [=========================>....] - ETA: 12:16 - loss: 0.2422 - accuracy: 0.8944\n",
      " training set -> batch:435 loss:0.24232624471187592 and acc: 0.8940762877464294\n",
      "435/500 [=========================>....] - ETA: 12:05 - loss: 0.2423 - accuracy: 0.8941\n",
      " training set -> batch:436 loss:0.2411273717880249 and acc: 0.8952569365501404\n",
      "436/500 [=========================>....] - ETA: 11:53 - loss: 0.2411 - accuracy: 0.8953\n",
      " training set -> batch:437 loss:0.23896482586860657 and acc: 0.8959143757820129\n",
      "437/500 [=========================>....] - ETA: 11:42 - loss: 0.2390 - accuracy: 0.8959\n",
      " training set -> batch:438 loss:0.23815979063510895 and acc: 0.8965517282485962\n",
      "438/500 [=========================>....] - ETA: 11:30 - loss: 0.2382 - accuracy: 0.8966\n",
      " training set -> batch:439 loss:0.23517921566963196 and acc: 0.8976414799690247\n",
      "439/500 [=========================>....] - ETA: 11:19 - loss: 0.2352 - accuracy: 0.8976\n",
      " training set -> batch:440 loss:0.23324190080165863 and acc: 0.8986988663673401\n",
      "440/500 [=========================>....] - ETA: 11:08 - loss: 0.2332 - accuracy: 0.8987\n",
      " training set -> batch:441 loss:0.23269237577915192 and acc: 0.898809552192688\n",
      "441/500 [=========================>....] - ETA: 10:56 - loss: 0.2327 - accuracy: 0.8988\n",
      " training set -> batch:442 loss:0.23202696442604065 and acc: 0.8993682265281677\n",
      "442/500 [=========================>....] - ETA: 10:45 - loss: 0.2320 - accuracy: 0.8994\n",
      " training set -> batch:443 loss:0.23066310584545135 and acc: 0.8999110460281372\n",
      "443/500 [=========================>....] - ETA: 10:34 - loss: 0.2307 - accuracy: 0.8999\n",
      " training set -> batch:444 loss:0.22771406173706055 and acc: 0.9008771777153015\n",
      "444/500 [=========================>....] - ETA: 10:22 - loss: 0.2277 - accuracy: 0.9009\n",
      " training set -> batch:445 loss:0.23098188638687134 and acc: 0.899653971195221\n",
      "445/500 [=========================>....] - ETA: 10:11 - loss: 0.2310 - accuracy: 0.8997\n",
      " training set -> batch:446 loss:0.23102477192878723 and acc: 0.8997440338134766\n",
      "446/500 [=========================>....] - ETA: 10:00 - loss: 0.2310 - accuracy: 0.8997\n",
      " training set -> batch:447 loss:0.23076161742210388 and acc: 0.8994107842445374\n",
      "447/500 [=========================>....] - ETA: 9:48 - loss: 0.2308 - accuracy: 0.8994 \n",
      " training set -> batch:448 loss:0.23093481361865997 and acc: 0.8995016813278198\n",
      "448/500 [=========================>....] - ETA: 9:37 - loss: 0.2309 - accuracy: 0.8995\n",
      " training set -> batch:449 loss:0.22862432897090912 and acc: 0.9004098176956177\n",
      "449/500 [=========================>....] - ETA: 9:26 - loss: 0.2286 - accuracy: 0.9004\n",
      " training set -> batch:450 loss:0.22964003682136536 and acc: 0.9000809192657471\n",
      "\n",
      " validation set -> batch:450 val loss:0.29072102904319763 and val acc: 0.8910550475120544\n",
      "450/500 [==========================>...] - ETA: 9:25 - loss: 0.2296 - accuracy: 0.9001\n",
      " training set -> batch:451 loss:0.27758559584617615 and acc: 0.8938053250312805\n",
      "451/500 [==========================>...] - ETA: 9:13 - loss: 0.2776 - accuracy: 0.8938\n",
      " training set -> batch:452 loss:0.2833009958267212 and acc: 0.8942307829856873\n",
      "452/500 [==========================>...] - ETA: 9:02 - loss: 0.2833 - accuracy: 0.8942\n",
      " training set -> batch:453 loss:0.28697308897972107 and acc: 0.89462810754776\n",
      "453/500 [==========================>...] - ETA: 8:50 - loss: 0.2870 - accuracy: 0.8946\n",
      " training set -> batch:454 loss:0.280800998210907 and acc: 0.8960000276565552\n",
      "454/500 [==========================>...] - ETA: 8:39 - loss: 0.2808 - accuracy: 0.8960\n",
      " training set -> batch:455 loss:0.28375619649887085 and acc: 0.8963178396224976\n",
      "455/500 [==========================>...] - ETA: 8:27 - loss: 0.2838 - accuracy: 0.8963\n",
      " training set -> batch:456 loss:0.2950320839881897 and acc: 0.8919172883033752\n",
      "456/500 [==========================>...] - ETA: 8:16 - loss: 0.2950 - accuracy: 0.8919\n",
      " training set -> batch:457 loss:0.29903388023376465 and acc: 0.8905109763145447\n",
      "457/500 [==========================>...] - ETA: 8:05 - loss: 0.2990 - accuracy: 0.8905\n",
      " training set -> batch:458 loss:0.3054811656475067 and acc: 0.8891844153404236\n",
      "458/500 [==========================>...] - ETA: 7:53 - loss: 0.3055 - accuracy: 0.8892\n",
      " training set -> batch:459 loss:0.3095932900905609 and acc: 0.8887931108474731\n",
      "459/500 [==========================>...] - ETA: 7:42 - loss: 0.3096 - accuracy: 0.8888\n",
      " training set -> batch:460 loss:0.3034966289997101 and acc: 0.8901006579399109\n",
      "460/500 [==========================>...] - ETA: 7:30 - loss: 0.3035 - accuracy: 0.8901\n",
      " training set -> batch:461 loss:0.3053261637687683 and acc: 0.8897058963775635\n",
      "461/500 [==========================>...] - ETA: 7:19 - loss: 0.3053 - accuracy: 0.8897\n",
      " training set -> batch:462 loss:0.3016146421432495 and acc: 0.8909235596656799\n",
      "462/500 [==========================>...] - ETA: 7:07 - loss: 0.3016 - accuracy: 0.8909\n",
      " training set -> batch:463 loss:0.3053453266620636 and acc: 0.8905279636383057\n",
      "463/500 [==========================>...] - ETA: 6:56 - loss: 0.3053 - accuracy: 0.8905\n",
      " training set -> batch:464 loss:0.300362765789032 and acc: 0.8909090757369995\n",
      "464/500 [==========================>...] - ETA: 6:45 - loss: 0.3004 - accuracy: 0.8909\n",
      " training set -> batch:465 loss:0.2947704792022705 and acc: 0.892011821269989\n",
      "465/500 [==========================>...] - ETA: 6:33 - loss: 0.2948 - accuracy: 0.8920\n",
      " training set -> batch:466 loss:0.29282599687576294 and acc: 0.8923410177230835\n",
      "466/500 [==========================>...] - ETA: 6:22 - loss: 0.2928 - accuracy: 0.8923\n",
      " training set -> batch:467 loss:0.28748705983161926 and acc: 0.8933615684509277\n",
      "467/500 [===========================>..] - ETA: 6:10 - loss: 0.2875 - accuracy: 0.8934\n",
      " training set -> batch:468 loss:0.28477415442466736 and acc: 0.894336998462677\n",
      "468/500 [===========================>..] - ETA: 5:59 - loss: 0.2848 - accuracy: 0.8943\n",
      " training set -> batch:469 loss:0.28900018334388733 and acc: 0.8939189314842224\n",
      "469/500 [===========================>..] - ETA: 5:48 - loss: 0.2890 - accuracy: 0.8939\n",
      " training set -> batch:470 loss:0.28464916348457336 and acc: 0.8955026268959045\n",
      "470/500 [===========================>..] - ETA: 5:36 - loss: 0.2846 - accuracy: 0.8955\n",
      " training set -> batch:471 loss:0.28409337997436523 and acc: 0.8950777053833008\n",
      "471/500 [===========================>..] - ETA: 5:25 - loss: 0.2841 - accuracy: 0.8951\n",
      " training set -> batch:472 loss:0.27817317843437195 and acc: 0.8972080945968628\n",
      "472/500 [===========================>..] - ETA: 5:14 - loss: 0.2782 - accuracy: 0.8972\n",
      " training set -> batch:473 loss:0.2747149169445038 and acc: 0.8980099558830261\n",
      "473/500 [===========================>..] - ETA: 5:02 - loss: 0.2747 - accuracy: 0.8980\n",
      " training set -> batch:474 loss:0.27564501762390137 and acc: 0.8975609540939331\n",
      "474/500 [===========================>..] - ETA: 4:51 - loss: 0.2756 - accuracy: 0.8976\n",
      " training set -> batch:475 loss:0.2784063518047333 and acc: 0.8965311050415039\n",
      "475/500 [===========================>..] - ETA: 4:40 - loss: 0.2784 - accuracy: 0.8965\n",
      " training set -> batch:476 loss:0.28292399644851685 and acc: 0.8949530720710754\n",
      "476/500 [===========================>..] - ETA: 4:29 - loss: 0.2829 - accuracy: 0.8950\n",
      " training set -> batch:477 loss:0.2801227867603302 and acc: 0.89573734998703\n",
      "477/500 [===========================>..] - ETA: 4:17 - loss: 0.2801 - accuracy: 0.8957\n",
      " training set -> batch:478 loss:0.2770017981529236 and acc: 0.8970588445663452\n",
      "478/500 [===========================>..] - ETA: 4:06 - loss: 0.2770 - accuracy: 0.8971\n",
      " training set -> batch:479 loss:0.27543553709983826 and acc: 0.8966666460037231\n",
      "479/500 [===========================>..] - ETA: 3:55 - loss: 0.2754 - accuracy: 0.8967\n",
      " training set -> batch:480 loss:0.27826347947120667 and acc: 0.8957423567771912\n",
      "480/500 [===========================>..] - ETA: 3:43 - loss: 0.2783 - accuracy: 0.8957\n",
      " training set -> batch:481 loss:0.277677059173584 and acc: 0.8959227204322815\n",
      "481/500 [===========================>..] - ETA: 3:32 - loss: 0.2777 - accuracy: 0.8959\n",
      " training set -> batch:482 loss:0.27549508213996887 and acc: 0.8971518874168396\n",
      "482/500 [===========================>..] - ETA: 3:21 - loss: 0.2755 - accuracy: 0.8972\n",
      " training set -> batch:483 loss:0.27250155806541443 and acc: 0.8978216052055359\n",
      "483/500 [===========================>..] - ETA: 3:10 - loss: 0.2725 - accuracy: 0.8978\n",
      " training set -> batch:484 loss:0.2699151039123535 and acc: 0.8984693884849548\n",
      "484/500 [============================>.] - ETA: 2:58 - loss: 0.2699 - accuracy: 0.8985\n",
      " training set -> batch:485 loss:0.2680310308933258 and acc: 0.8990963697433472\n",
      "485/500 [============================>.] - ETA: 2:47 - loss: 0.2680 - accuracy: 0.8991\n",
      " training set -> batch:486 loss:0.2679222822189331 and acc: 0.8992094993591309\n",
      "486/500 [============================>.] - ETA: 2:36 - loss: 0.2679 - accuracy: 0.8992\n",
      " training set -> batch:487 loss:0.26732391119003296 and acc: 0.899319052696228\n",
      "487/500 [============================>.] - ETA: 2:25 - loss: 0.2673 - accuracy: 0.8993\n",
      " training set -> batch:488 loss:0.26833659410476685 and acc: 0.8989463448524475\n",
      "488/500 [============================>.] - ETA: 2:14 - loss: 0.2683 - accuracy: 0.8989\n",
      " training set -> batch:489 loss:0.26646527647972107 and acc: 0.899056613445282\n",
      "489/500 [============================>.] - ETA: 2:02 - loss: 0.2665 - accuracy: 0.8991\n",
      " training set -> batch:490 loss:0.27319273352622986 and acc: 0.8973048329353333\n",
      "490/500 [============================>.] - ETA: 1:51 - loss: 0.2732 - accuracy: 0.8973\n",
      " training set -> batch:491 loss:0.27427512407302856 and acc: 0.8969780206680298\n",
      "491/500 [============================>.] - ETA: 1:40 - loss: 0.2743 - accuracy: 0.8970\n",
      " training set -> batch:492 loss:0.27675744891166687 and acc: 0.8948556184768677\n",
      "492/500 [============================>.] - ETA: 1:29 - loss: 0.2768 - accuracy: 0.8949\n",
      " training set -> batch:493 loss:0.27593159675598145 and acc: 0.8941280841827393\n",
      "493/500 [============================>.] - ETA: 1:18 - loss: 0.2759 - accuracy: 0.8941\n",
      " training set -> batch:494 loss:0.2752453088760376 and acc: 0.894298255443573\n",
      "494/500 [============================>.] - ETA: 1:06 - loss: 0.2752 - accuracy: 0.8943\n",
      " training set -> batch:495 loss:0.27285218238830566 and acc: 0.89532870054245\n",
      "495/500 [============================>.] - ETA: 55s - loss: 0.2729 - accuracy: 0.8953 \n",
      " training set -> batch:496 loss:0.2713536024093628 and acc: 0.8959044218063354\n",
      "496/500 [============================>.] - ETA: 44s - loss: 0.2714 - accuracy: 0.8959\n",
      " training set -> batch:497 loss:0.26870036125183105 and acc: 0.8968855142593384\n",
      "497/500 [============================>.] - ETA: 33s - loss: 0.2687 - accuracy: 0.8969\n",
      " training set -> batch:498 loss:0.26637643575668335 and acc: 0.8982558250427246\n",
      "498/500 [============================>.] - ETA: 22s - loss: 0.2664 - accuracy: 0.8983\n",
      " training set -> batch:499 loss:0.2634461224079132 and acc: 0.8995901346206665\n",
      "499/500 [============================>.] - ETA: 11s - loss: 0.2634 - accuracy: 0.8996\n",
      " training set -> batch:500 loss:0.26377764344215393 and acc: 0.8992718458175659\n",
      "\n",
      " validation set -> batch:500 val loss:0.2431633621454239 and val acc: 0.9025229215621948\n",
      "500/500 [==============================] - 5700s 11s/step - loss: 0.2638 - accuracy: 0.8993 - val_loss: 0.2233 - val_accuracy: 0.9323\n",
      "Epoch 2/2\n",
      "\n",
      " training set -> batch:501 loss:0.24736428260803223 and acc: 0.84375\n",
      "  1/500 [..............................] - ETA: 0s - loss: 0.2474 - accuracy: 0.8438\n",
      " training set -> batch:502 loss:0.30623865127563477 and acc: 0.84375\n",
      "  2/500 [..............................] - ETA: 41:25 - loss: 0.3062 - accuracy: 0.8438\n",
      " training set -> batch:503 loss:0.36518430709838867 and acc: 0.8333333134651184\n",
      "  3/500 [..............................] - ETA: 54:01 - loss: 0.3652 - accuracy: 0.8333\n",
      " training set -> batch:504 loss:0.3044813871383667 and acc: 0.8671875\n",
      "  4/500 [..............................] - ETA: 1:00:13 - loss: 0.3045 - accuracy: 0.8672\n",
      " training set -> batch:505 loss:0.33957967162132263 and acc: 0.856249988079071\n",
      "  5/500 [..............................] - ETA: 1:03:57 - loss: 0.3396 - accuracy: 0.8562\n",
      " training set -> batch:506 loss:0.3002001941204071 and acc: 0.8802083134651184\n",
      "  6/500 [..............................] - ETA: 1:06:23 - loss: 0.3002 - accuracy: 0.8802\n",
      " training set -> batch:507 loss:0.29045799374580383 and acc: 0.8839285969734192\n",
      "  7/500 [..............................] - ETA: 1:08:03 - loss: 0.2905 - accuracy: 0.8839\n",
      " training set -> batch:508 loss:0.26213744282722473 and acc: 0.8984375\n",
      "  8/500 [..............................] - ETA: 1:09:16 - loss: 0.2621 - accuracy: 0.8984\n",
      " training set -> batch:509 loss:0.2545127868652344 and acc: 0.9027777910232544\n",
      "  9/500 [..............................] - ETA: 1:10:11 - loss: 0.2545 - accuracy: 0.9028\n",
      " training set -> batch:510 loss:0.25114113092422485 and acc: 0.903124988079071\n",
      " 10/500 [..............................] - ETA: 1:11:01 - loss: 0.2511 - accuracy: 0.9031\n",
      " training set -> batch:511 loss:0.245732843875885 and acc: 0.90625\n",
      " 11/500 [..............................] - ETA: 1:11:32 - loss: 0.2457 - accuracy: 0.9062\n",
      " training set -> batch:512 loss:0.2404322624206543 and acc: 0.9114583134651184\n",
      " 12/500 [..............................] - ETA: 1:11:59 - loss: 0.2404 - accuracy: 0.9115\n",
      " training set -> batch:513 loss:0.2490973323583603 and acc: 0.90625\n",
      " 13/500 [..............................] - ETA: 1:12:22 - loss: 0.2491 - accuracy: 0.9062\n",
      " training set -> batch:514 loss:0.24637098610401154 and acc: 0.90625\n",
      " 14/500 [..............................] - ETA: 1:12:36 - loss: 0.2464 - accuracy: 0.9062\n",
      " training set -> batch:515 loss:0.24310779571533203 and acc: 0.90625\n",
      " 15/500 [..............................] - ETA: 1:12:47 - loss: 0.2431 - accuracy: 0.9062\n",
      " training set -> batch:516 loss:0.23407511413097382 and acc: 0.91015625\n",
      " 16/500 [..............................] - ETA: 1:12:52 - loss: 0.2341 - accuracy: 0.9102\n",
      " training set -> batch:517 loss:0.23600931465625763 and acc: 0.908088207244873\n",
      " 17/500 [>.............................] - ETA: 1:12:56 - loss: 0.2360 - accuracy: 0.9081\n",
      " training set -> batch:518 loss:0.24320155382156372 and acc: 0.90625\n",
      " 18/500 [>.............................] - ETA: 1:13:06 - loss: 0.2432 - accuracy: 0.9062\n",
      " training set -> batch:519 loss:0.24569563567638397 and acc: 0.90625\n",
      " 19/500 [>.............................] - ETA: 1:13:11 - loss: 0.2457 - accuracy: 0.9062\n",
      " training set -> batch:520 loss:0.24076656997203827 and acc: 0.909375011920929\n",
      " 20/500 [>.............................] - ETA: 1:13:15 - loss: 0.2408 - accuracy: 0.9094\n",
      " training set -> batch:521 loss:0.24105679988861084 and acc: 0.9077380895614624\n",
      " 21/500 [>.............................] - ETA: 1:13:18 - loss: 0.2411 - accuracy: 0.9077\n",
      " training set -> batch:522 loss:0.2420302927494049 and acc: 0.90625\n",
      " 22/500 [>.............................] - ETA: 1:13:19 - loss: 0.2420 - accuracy: 0.9062\n",
      " training set -> batch:523 loss:0.2462087720632553 and acc: 0.90625\n",
      " 23/500 [>.............................] - ETA: 1:13:18 - loss: 0.2462 - accuracy: 0.9062\n",
      " training set -> batch:524 loss:0.24205119907855988 and acc: 0.9075520634651184\n",
      " 24/500 [>.............................] - ETA: 1:13:14 - loss: 0.2421 - accuracy: 0.9076\n",
      " training set -> batch:525 loss:0.23988282680511475 and acc: 0.9075000286102295\n",
      " 25/500 [>.............................] - ETA: 1:13:15 - loss: 0.2399 - accuracy: 0.9075\n",
      " training set -> batch:526 loss:0.2435401827096939 and acc: 0.90625\n",
      " 26/500 [>.............................] - ETA: 1:13:15 - loss: 0.2435 - accuracy: 0.9062\n",
      " training set -> batch:527 loss:0.24336127936840057 and acc: 0.90625\n",
      " 27/500 [>.............................] - ETA: 1:13:14 - loss: 0.2434 - accuracy: 0.9062\n",
      " training set -> batch:528 loss:0.24337060749530792 and acc: 0.9051339030265808\n",
      " 28/500 [>.............................] - ETA: 1:13:08 - loss: 0.2434 - accuracy: 0.9051\n",
      " training set -> batch:529 loss:0.2403750866651535 and acc: 0.90625\n",
      " 29/500 [>.............................] - ETA: 1:13:04 - loss: 0.2404 - accuracy: 0.9062\n",
      " training set -> batch:530 loss:0.23913900554180145 and acc: 0.90625\n",
      " 30/500 [>.............................] - ETA: 1:12:59 - loss: 0.2391 - accuracy: 0.9062\n",
      " training set -> batch:531 loss:0.24219082295894623 and acc: 0.9052419066429138\n",
      " 31/500 [>.............................] - ETA: 1:12:55 - loss: 0.2422 - accuracy: 0.9052\n",
      " training set -> batch:532 loss:0.23958174884319305 and acc: 0.9052734375\n",
      " 32/500 [>.............................] - ETA: 1:12:51 - loss: 0.2396 - accuracy: 0.9053\n",
      " training set -> batch:533 loss:0.2389535903930664 and acc: 0.904356062412262\n",
      " 33/500 [>.............................] - ETA: 1:12:45 - loss: 0.2390 - accuracy: 0.9044\n",
      " training set -> batch:534 loss:0.23814694583415985 and acc: 0.904411792755127\n",
      " 34/500 [=>............................] - ETA: 1:12:39 - loss: 0.2381 - accuracy: 0.9044\n",
      " training set -> batch:535 loss:0.2374211996793747 and acc: 0.9035714268684387\n",
      " 35/500 [=>............................] - ETA: 1:12:35 - loss: 0.2374 - accuracy: 0.9036\n",
      " training set -> batch:536 loss:0.2346867471933365 and acc: 0.9053819179534912\n",
      " 36/500 [=>............................] - ETA: 1:12:27 - loss: 0.2347 - accuracy: 0.9054\n",
      " training set -> batch:537 loss:0.23751959204673767 and acc: 0.9037162065505981\n",
      " 37/500 [=>............................] - ETA: 1:12:18 - loss: 0.2375 - accuracy: 0.9037\n",
      " training set -> batch:538 loss:0.23745614290237427 and acc: 0.9037829041481018\n",
      " 38/500 [=>............................] - ETA: 1:12:11 - loss: 0.2375 - accuracy: 0.9038\n",
      " training set -> batch:539 loss:0.24285262823104858 and acc: 0.9006410241127014\n",
      " 39/500 [=>............................] - ETA: 1:12:04 - loss: 0.2429 - accuracy: 0.9006\n",
      " training set -> batch:540 loss:0.24568140506744385 and acc: 0.899218738079071\n",
      " 40/500 [=>............................] - ETA: 1:11:56 - loss: 0.2457 - accuracy: 0.8992\n",
      " training set -> batch:541 loss:0.2463824301958084 and acc: 0.8993902206420898\n",
      " 41/500 [=>............................] - ETA: 1:11:47 - loss: 0.2464 - accuracy: 0.8994\n",
      " training set -> batch:542 loss:0.246897354722023 and acc: 0.8995535969734192\n",
      " 42/500 [=>............................] - ETA: 1:11:38 - loss: 0.2469 - accuracy: 0.8996\n",
      " training set -> batch:543 loss:0.24445809423923492 and acc: 0.9011628031730652\n",
      " 43/500 [=>............................] - ETA: 1:11:31 - loss: 0.2445 - accuracy: 0.9012\n",
      " training set -> batch:544 loss:0.24305754899978638 and acc: 0.9019886255264282\n",
      " 44/500 [=>............................] - ETA: 1:11:24 - loss: 0.2431 - accuracy: 0.9020\n",
      " training set -> batch:545 loss:0.24454137682914734 and acc: 0.9013888835906982\n",
      " 45/500 [=>............................] - ETA: 1:11:16 - loss: 0.2445 - accuracy: 0.9014\n",
      " training set -> batch:546 loss:0.24229082465171814 and acc: 0.90285325050354\n",
      " 46/500 [=>............................] - ETA: 1:11:10 - loss: 0.2423 - accuracy: 0.9029\n",
      " training set -> batch:547 loss:0.24109666049480438 and acc: 0.9035904407501221\n",
      " 47/500 [=>............................] - ETA: 1:11:02 - loss: 0.2411 - accuracy: 0.9036\n",
      " training set -> batch:548 loss:0.23999647796154022 and acc: 0.9036458134651184\n",
      " 48/500 [=>............................] - ETA: 1:10:53 - loss: 0.2400 - accuracy: 0.9036\n",
      " training set -> batch:549 loss:0.23868727684020996 and acc: 0.9036989808082581\n",
      " 49/500 [=>............................] - ETA: 1:10:44 - loss: 0.2387 - accuracy: 0.9037\n",
      " training set -> batch:550 loss:0.237609401345253 and acc: 0.9043750166893005\n",
      "\n",
      " validation set -> batch:550 val loss:0.24148888885974884 and val acc: 0.89449542760849\n",
      " 50/500 [==>...........................] - ETA: 1:24:16 - loss: 0.2376 - accuracy: 0.9044\n",
      " training set -> batch:551 loss:0.2431175261735916 and acc: 0.8938053250312805\n",
      " 51/500 [==>...........................] - ETA: 1:23:59 - loss: 0.2431 - accuracy: 0.8938\n",
      " training set -> batch:552 loss:0.2355092614889145 and acc: 0.8963675498962402\n",
      " 52/500 [==>...........................] - ETA: 1:23:33 - loss: 0.2355 - accuracy: 0.8964\n",
      " training set -> batch:553 loss:0.24027658998966217 and acc: 0.89462810754776\n",
      " 53/500 [==>...........................] - ETA: 1:23:07 - loss: 0.2403 - accuracy: 0.8946\n",
      " training set -> batch:554 loss:0.2328103631734848 and acc: 0.8970000147819519\n",
      " 54/500 [==>...........................] - ETA: 1:22:44 - loss: 0.2328 - accuracy: 0.8970\n",
      " training set -> batch:555 loss:0.2326004058122635 and acc: 0.8982558250427246\n",
      " 55/500 [==>...........................] - ETA: 1:22:20 - loss: 0.2326 - accuracy: 0.8983\n",
      " training set -> batch:556 loss:0.23888686299324036 and acc: 0.8975563645362854\n",
      " 56/500 [==>...........................] - ETA: 1:21:57 - loss: 0.2389 - accuracy: 0.8976\n",
      " training set -> batch:557 loss:0.237036794424057 and acc: 0.8987226486206055\n",
      " 57/500 [==>...........................] - ETA: 1:21:34 - loss: 0.2370 - accuracy: 0.8987\n",
      " training set -> batch:558 loss:0.24479590356349945 and acc: 0.8971630930900574\n",
      " 58/500 [==>...........................] - ETA: 1:21:11 - loss: 0.2448 - accuracy: 0.8972\n",
      " training set -> batch:559 loss:0.24244466423988342 and acc: 0.8982758522033691\n",
      " 59/500 [==>...........................] - ETA: 1:20:49 - loss: 0.2424 - accuracy: 0.8983\n",
      " training set -> batch:560 loss:0.23784880340099335 and acc: 0.9001677632331848\n",
      " 60/500 [==>...........................] - ETA: 1:20:27 - loss: 0.2378 - accuracy: 0.9002\n",
      " training set -> batch:561 loss:0.2346539944410324 and acc: 0.9011437892913818\n",
      " 61/500 [==>...........................] - ETA: 1:20:06 - loss: 0.2347 - accuracy: 0.9011\n",
      " training set -> batch:562 loss:0.23499925434589386 and acc: 0.9004777073860168\n",
      " 62/500 [==>...........................] - ETA: 1:19:45 - loss: 0.2350 - accuracy: 0.9005\n",
      " training set -> batch:563 loss:0.23131681978702545 and acc: 0.9013975262641907\n",
      " 63/500 [==>...........................] - ETA: 1:19:23 - loss: 0.2313 - accuracy: 0.9014\n",
      " training set -> batch:564 loss:0.2318023443222046 and acc: 0.9015151262283325\n",
      " 64/500 [==>...........................] - ETA: 1:19:03 - loss: 0.2318 - accuracy: 0.9015\n",
      " training set -> batch:565 loss:0.23239801824092865 and acc: 0.9008875489234924\n",
      " 65/500 [==>...........................] - ETA: 1:18:42 - loss: 0.2324 - accuracy: 0.9009\n",
      " training set -> batch:566 loss:0.23221008479595184 and acc: 0.900288999080658\n",
      " 66/500 [==>...........................] - ETA: 1:18:22 - loss: 0.2322 - accuracy: 0.9003\n",
      " training set -> batch:567 loss:0.22683057188987732 and acc: 0.9025423526763916\n",
      " 67/500 [===>..........................] - ETA: 1:18:03 - loss: 0.2268 - accuracy: 0.9025\n",
      " training set -> batch:568 loss:0.22811628878116608 and acc: 0.9019337296485901\n",
      " 68/500 [===>..........................] - ETA: 1:17:44 - loss: 0.2281 - accuracy: 0.9019\n",
      " training set -> batch:569 loss:0.2298789769411087 and acc: 0.9013513326644897\n",
      " 69/500 [===>..........................] - ETA: 1:17:26 - loss: 0.2299 - accuracy: 0.9014\n",
      " training set -> batch:570 loss:0.2301403284072876 and acc: 0.9014550447463989\n",
      " 70/500 [===>..........................] - ETA: 1:17:07 - loss: 0.2301 - accuracy: 0.9015\n",
      " training set -> batch:571 loss:0.2296634465456009 and acc: 0.9002590775489807\n",
      " 71/500 [===>..........................] - ETA: 1:16:49 - loss: 0.2297 - accuracy: 0.9003\n",
      " training set -> batch:572 loss:0.2284591794013977 and acc: 0.9010152220726013\n",
      " 72/500 [===>..........................] - ETA: 1:16:32 - loss: 0.2285 - accuracy: 0.9010\n",
      " training set -> batch:573 loss:0.22660231590270996 and acc: 0.9023631811141968\n",
      " 73/500 [===>..........................] - ETA: 1:16:15 - loss: 0.2266 - accuracy: 0.9024\n",
      " training set -> batch:574 loss:0.22345761954784393 and acc: 0.9036585092544556\n",
      " 74/500 [===>..........................] - ETA: 1:15:57 - loss: 0.2235 - accuracy: 0.9037\n",
      " training set -> batch:575 loss:0.21970081329345703 and acc: 0.9055023789405823\n",
      " 75/500 [===>..........................] - ETA: 1:15:42 - loss: 0.2197 - accuracy: 0.9055\n",
      " training set -> batch:576 loss:0.22011491656303406 and acc: 0.9049295783042908\n",
      " 76/500 [===>..........................] - ETA: 1:15:26 - loss: 0.2201 - accuracy: 0.9049\n",
      " training set -> batch:577 loss:0.21529795229434967 and acc: 0.906682014465332\n",
      " 77/500 [===>..........................] - ETA: 1:15:09 - loss: 0.2153 - accuracy: 0.9067\n",
      " training set -> batch:578 loss:0.21364037692546844 and acc: 0.9072397947311401\n",
      " 78/500 [===>..........................] - ETA: 1:14:53 - loss: 0.2136 - accuracy: 0.9072\n",
      " training set -> batch:579 loss:0.21392416954040527 and acc: 0.9066666960716248\n",
      " 79/500 [===>..........................] - ETA: 1:14:37 - loss: 0.2139 - accuracy: 0.9067\n",
      " training set -> batch:580 loss:0.21942929923534393 and acc: 0.90447598695755\n",
      " 80/500 [===>..........................] - ETA: 1:14:21 - loss: 0.2194 - accuracy: 0.9045\n",
      " training set -> batch:581 loss:0.21681340038776398 and acc: 0.9055793881416321\n",
      " 81/500 [===>..........................] - ETA: 1:14:04 - loss: 0.2168 - accuracy: 0.9056\n",
      " training set -> batch:582 loss:0.2202555388212204 and acc: 0.905063271522522\n",
      " 82/500 [===>..........................] - ETA: 1:13:48 - loss: 0.2203 - accuracy: 0.9051\n",
      " training set -> batch:583 loss:0.21994410455226898 and acc: 0.9050830006599426\n",
      " 83/500 [===>..........................] - ETA: 1:13:31 - loss: 0.2199 - accuracy: 0.9051\n",
      " training set -> batch:584 loss:0.2239638715982437 and acc: 0.9040816426277161\n",
      " 84/500 [====>.........................] - ETA: 1:13:16 - loss: 0.2240 - accuracy: 0.9041\n",
      " training set -> batch:585 loss:0.22529101371765137 and acc: 0.9036144614219666\n",
      " 85/500 [====>.........................] - ETA: 1:13:00 - loss: 0.2253 - accuracy: 0.9036\n",
      " training set -> batch:586 loss:0.22272278368473053 and acc: 0.9041501879692078\n",
      " 86/500 [====>.........................] - ETA: 1:12:45 - loss: 0.2227 - accuracy: 0.9042\n",
      " training set -> batch:587 loss:0.22351858019828796 and acc: 0.9036964774131775\n",
      " 87/500 [====>.........................] - ETA: 1:12:30 - loss: 0.2235 - accuracy: 0.9037\n",
      " training set -> batch:588 loss:0.22565504908561707 and acc: 0.9018199443817139\n",
      " 88/500 [====>.........................] - ETA: 1:12:14 - loss: 0.2257 - accuracy: 0.9018\n",
      " training set -> batch:589 loss:0.2254781424999237 and acc: 0.900943398475647\n",
      " 89/500 [====>.........................] - ETA: 1:11:59 - loss: 0.2255 - accuracy: 0.9009\n",
      " training set -> batch:590 loss:0.22364871203899384 and acc: 0.9014869928359985\n",
      " 90/500 [====>.........................] - ETA: 1:11:44 - loss: 0.2236 - accuracy: 0.9015\n",
      " training set -> batch:591 loss:0.226288840174675 and acc: 0.9001831412315369\n",
      " 91/500 [====>.........................] - ETA: 1:11:30 - loss: 0.2263 - accuracy: 0.9002\n",
      " training set -> batch:592 loss:0.22383837401866913 and acc: 0.9016245603561401\n",
      " 92/500 [====>.........................] - ETA: 1:11:15 - loss: 0.2238 - accuracy: 0.9016\n",
      " training set -> batch:593 loss:0.22844816744327545 and acc: 0.900355875492096\n",
      " 93/500 [====>.........................] - ETA: 1:11:02 - loss: 0.2284 - accuracy: 0.9004\n",
      " training set -> batch:594 loss:0.22606632113456726 and acc: 0.9017543792724609\n",
      " 94/500 [====>.........................] - ETA: 1:10:47 - loss: 0.2261 - accuracy: 0.9018\n",
      " training set -> batch:595 loss:0.2248583436012268 and acc: 0.9022491574287415\n",
      " 95/500 [====>.........................] - ETA: 1:10:33 - loss: 0.2249 - accuracy: 0.9022\n",
      " training set -> batch:596 loss:0.22523480653762817 and acc: 0.9018771052360535\n",
      " 96/500 [====>.........................] - ETA: 1:10:18 - loss: 0.2252 - accuracy: 0.9019\n",
      " training set -> batch:597 loss:0.22656741738319397 and acc: 0.9006733894348145\n",
      " 97/500 [====>.........................] - ETA: 1:10:04 - loss: 0.2266 - accuracy: 0.9007\n",
      " training set -> batch:598 loss:0.2259075939655304 and acc: 0.900747537612915\n",
      " 98/500 [====>.........................] - ETA: 1:09:50 - loss: 0.2259 - accuracy: 0.9007\n",
      " training set -> batch:599 loss:0.22798453271389008 and acc: 0.9004098176956177\n",
      " 99/500 [====>.........................] - ETA: 1:09:36 - loss: 0.2280 - accuracy: 0.9004\n",
      " training set -> batch:600 loss:0.22600515186786652 and acc: 0.9008899927139282\n",
      "\n",
      " validation set -> batch:600 val loss:0.23967155814170837 and val acc: 0.8933486342430115\n",
      "100/500 [=====>........................] - ETA: 1:15:26 - loss: 0.2260 - accuracy: 0.9009\n",
      " training set -> batch:601 loss:0.2364494353532791 and acc: 0.894911527633667\n",
      "101/500 [=====>........................] - ETA: 1:15:07 - loss: 0.2364 - accuracy: 0.8949\n",
      " training set -> batch:602 loss:0.2380543202161789 and acc: 0.8952991366386414\n",
      "102/500 [=====>........................] - ETA: 1:14:49 - loss: 0.2381 - accuracy: 0.8953\n",
      " training set -> batch:603 loss:0.2366577833890915 and acc: 0.8956611752510071\n",
      "103/500 [=====>........................] - ETA: 1:14:32 - loss: 0.2367 - accuracy: 0.8957\n",
      " training set -> batch:604 loss:0.23029150068759918 and acc: 0.8980000019073486\n",
      "104/500 [=====>........................] - ETA: 1:14:14 - loss: 0.2303 - accuracy: 0.8980\n",
      " training set -> batch:605 loss:0.2246686965227127 and acc: 0.8992248177528381\n",
      "105/500 [=====>........................] - ETA: 1:13:56 - loss: 0.2247 - accuracy: 0.8992\n",
      " training set -> batch:606 loss:0.21867525577545166 and acc: 0.902255654335022\n",
      "106/500 [=====>........................] - ETA: 1:13:38 - loss: 0.2187 - accuracy: 0.9023\n",
      " training set -> batch:607 loss:0.22177627682685852 and acc: 0.9014598727226257\n",
      "107/500 [=====>........................] - ETA: 1:13:20 - loss: 0.2218 - accuracy: 0.9015\n",
      " training set -> batch:608 loss:0.22830289602279663 and acc: 0.8998227119445801\n",
      "108/500 [=====>........................] - ETA: 1:13:03 - loss: 0.2283 - accuracy: 0.8998\n",
      " training set -> batch:609 loss:0.22859017550945282 and acc: 0.8991379141807556\n",
      "109/500 [=====>........................] - ETA: 1:12:45 - loss: 0.2286 - accuracy: 0.8991\n",
      " training set -> batch:610 loss:0.22525258362293243 and acc: 0.9010066986083984\n",
      "110/500 [=====>........................] - ETA: 1:12:28 - loss: 0.2253 - accuracy: 0.9010\n",
      " training set -> batch:611 loss:0.22249239683151245 and acc: 0.9027777910232544\n",
      "111/500 [=====>........................] - ETA: 1:12:11 - loss: 0.2225 - accuracy: 0.9028\n",
      " training set -> batch:612 loss:0.21907179057598114 and acc: 0.9052547812461853\n",
      "112/500 [=====>........................] - ETA: 1:11:54 - loss: 0.2191 - accuracy: 0.9053\n",
      " training set -> batch:613 loss:0.21737918257713318 and acc: 0.9052795171737671\n",
      "113/500 [=====>........................] - ETA: 1:11:37 - loss: 0.2174 - accuracy: 0.9053\n",
      " training set -> batch:614 loss:0.21652862429618835 and acc: 0.9068182110786438\n",
      "114/500 [=====>........................] - ETA: 1:11:20 - loss: 0.2165 - accuracy: 0.9068\n",
      " training set -> batch:615 loss:0.21116235852241516 and acc: 0.909023642539978\n",
      "115/500 [=====>........................] - ETA: 1:11:04 - loss: 0.2112 - accuracy: 0.9090\n",
      " training set -> batch:616 loss:0.21061985194683075 and acc: 0.9096820950508118\n",
      "116/500 [=====>........................] - ETA: 1:10:47 - loss: 0.2106 - accuracy: 0.9097\n",
      " training set -> batch:617 loss:0.20641624927520752 and acc: 0.9110169410705566\n",
      "117/500 [======>.......................] - ETA: 1:10:31 - loss: 0.2064 - accuracy: 0.9110\n",
      " training set -> batch:618 loss:0.2051638513803482 and acc: 0.9122928380966187\n",
      "118/500 [======>.......................] - ETA: 1:10:14 - loss: 0.2052 - accuracy: 0.9123\n",
      " training set -> batch:619 loss:0.20338450372219086 and acc: 0.9135135412216187\n",
      "119/500 [======>.......................] - ETA: 1:09:58 - loss: 0.2034 - accuracy: 0.9135\n",
      " training set -> batch:620 loss:0.201335608959198 and acc: 0.9133597612380981\n",
      "120/500 [======>.......................] - ETA: 1:09:42 - loss: 0.2013 - accuracy: 0.9134\n",
      " training set -> batch:621 loss:0.19977541267871857 and acc: 0.9145077466964722\n",
      "121/500 [======>.......................] - ETA: 1:09:26 - loss: 0.1998 - accuracy: 0.9145\n",
      " training set -> batch:622 loss:0.20565344393253326 and acc: 0.9130710363388062\n",
      "122/500 [======>.......................] - ETA: 1:09:10 - loss: 0.2057 - accuracy: 0.9131\n",
      " training set -> batch:623 loss:0.20375406742095947 and acc: 0.913557231426239\n",
      "123/500 [======>.......................] - ETA: 1:08:55 - loss: 0.2038 - accuracy: 0.9136\n",
      " training set -> batch:624 loss:0.2016706019639969 and acc: 0.9146341681480408\n",
      "124/500 [======>.......................] - ETA: 1:08:39 - loss: 0.2017 - accuracy: 0.9146\n",
      " training set -> batch:625 loss:0.2068166434764862 and acc: 0.9138755798339844\n",
      "125/500 [======>.......................] - ETA: 1:08:24 - loss: 0.2068 - accuracy: 0.9139\n",
      " training set -> batch:626 loss:0.20742730796337128 and acc: 0.9131455421447754\n",
      "126/500 [======>.......................] - ETA: 1:08:08 - loss: 0.2074 - accuracy: 0.9131\n",
      " training set -> batch:627 loss:0.20874977111816406 and acc: 0.9135944843292236\n",
      "127/500 [======>.......................] - ETA: 1:07:53 - loss: 0.2087 - accuracy: 0.9136\n",
      " training set -> batch:628 loss:0.20604276657104492 and acc: 0.9145927429199219\n",
      "128/500 [======>.......................] - ETA: 1:07:37 - loss: 0.2060 - accuracy: 0.9146\n",
      " training set -> batch:629 loss:0.20486873388290405 and acc: 0.9150000214576721\n",
      "129/500 [======>.......................] - ETA: 1:07:22 - loss: 0.2049 - accuracy: 0.9150\n",
      " training set -> batch:630 loss:0.2058914601802826 and acc: 0.914301335811615\n",
      "130/500 [======>.......................] - ETA: 1:07:06 - loss: 0.2059 - accuracy: 0.9143\n",
      " training set -> batch:631 loss:0.20541618764400482 and acc: 0.9146995544433594\n",
      "131/500 [======>.......................] - ETA: 1:06:51 - loss: 0.2054 - accuracy: 0.9147\n",
      " training set -> batch:632 loss:0.20372368395328522 and acc: 0.9156118035316467\n",
      "132/500 [======>.......................] - ETA: 1:06:36 - loss: 0.2037 - accuracy: 0.9156\n",
      " training set -> batch:633 loss:0.20643597841262817 and acc: 0.9139004349708557\n",
      "133/500 [======>.......................] - ETA: 1:06:21 - loss: 0.2064 - accuracy: 0.9139\n",
      " training set -> batch:634 loss:0.2066531926393509 and acc: 0.9137755036354065\n",
      "134/500 [=======>......................] - ETA: 1:06:07 - loss: 0.2067 - accuracy: 0.9138\n",
      " training set -> batch:635 loss:0.207516148686409 and acc: 0.9141566157341003\n",
      "135/500 [=======>......................] - ETA: 1:05:52 - loss: 0.2075 - accuracy: 0.9142\n",
      " training set -> batch:636 loss:0.21032416820526123 and acc: 0.9135375618934631\n",
      "136/500 [=======>......................] - ETA: 1:05:38 - loss: 0.2103 - accuracy: 0.9135\n",
      " training set -> batch:637 loss:0.2093440741300583 and acc: 0.9134241342544556\n",
      "137/500 [=======>......................] - ETA: 1:05:23 - loss: 0.2093 - accuracy: 0.9134\n",
      " training set -> batch:638 loss:0.20860496163368225 and acc: 0.9137930870056152\n",
      "138/500 [=======>......................] - ETA: 1:05:09 - loss: 0.2086 - accuracy: 0.9138\n",
      " training set -> batch:639 loss:0.2092486321926117 and acc: 0.9141509532928467\n",
      "139/500 [=======>......................] - ETA: 1:04:55 - loss: 0.2092 - accuracy: 0.9142\n",
      " training set -> batch:640 loss:0.21056802570819855 and acc: 0.9135687947273254\n",
      "140/500 [=======>......................] - ETA: 1:04:40 - loss: 0.2106 - accuracy: 0.9136\n",
      " training set -> batch:641 loss:0.2080565243959427 and acc: 0.9148351550102234\n",
      "141/500 [=======>......................] - ETA: 1:04:26 - loss: 0.2081 - accuracy: 0.9148\n",
      " training set -> batch:642 loss:0.21062521636486053 and acc: 0.9133573770523071\n",
      "142/500 [=======>......................] - ETA: 1:04:12 - loss: 0.2106 - accuracy: 0.9134\n",
      " training set -> batch:643 loss:0.21088550984859467 and acc: 0.913701057434082\n",
      "143/500 [=======>......................] - ETA: 1:03:59 - loss: 0.2109 - accuracy: 0.9137\n",
      " training set -> batch:644 loss:0.2115236222743988 and acc: 0.9144737124443054\n",
      "144/500 [=======>......................] - ETA: 1:03:44 - loss: 0.2115 - accuracy: 0.9145\n",
      " training set -> batch:645 loss:0.21135826408863068 and acc: 0.9143598675727844\n",
      "145/500 [=======>......................] - ETA: 1:03:31 - loss: 0.2114 - accuracy: 0.9144\n",
      " training set -> batch:646 loss:0.2128036916255951 and acc: 0.9142491221427917\n",
      "146/500 [=======>......................] - ETA: 1:03:17 - loss: 0.2128 - accuracy: 0.9142\n",
      " training set -> batch:647 loss:0.21254760026931763 and acc: 0.9145622849464417\n",
      "147/500 [=======>......................] - ETA: 1:03:03 - loss: 0.2125 - accuracy: 0.9146\n",
      " training set -> batch:648 loss:0.21240971982479095 and acc: 0.9144518375396729\n",
      "148/500 [=======>......................] - ETA: 1:02:50 - loss: 0.2124 - accuracy: 0.9145\n",
      " training set -> batch:649 loss:0.21215488016605377 and acc: 0.9151639342308044\n",
      "149/500 [=======>......................] - ETA: 1:02:36 - loss: 0.2122 - accuracy: 0.9152\n",
      " training set -> batch:650 loss:0.21032550930976868 and acc: 0.9158576130867004\n",
      "\n",
      " validation set -> batch:650 val loss:0.2541274130344391 and val acc: 0.89449542760849\n",
      "150/500 [========>.....................] - ETA: 1:05:54 - loss: 0.2103 - accuracy: 0.9159\n",
      " training set -> batch:651 loss:0.2556920051574707 and acc: 0.8960176706314087\n",
      "151/500 [========>.....................] - ETA: 1:05:38 - loss: 0.2557 - accuracy: 0.8960\n",
      " training set -> batch:652 loss:0.25830715894699097 and acc: 0.8952991366386414\n",
      "152/500 [========>.....................] - ETA: 1:05:22 - loss: 0.2583 - accuracy: 0.8953\n",
      " training set -> batch:653 loss:0.2488187551498413 and acc: 0.8987603187561035\n",
      "153/500 [========>.....................] - ETA: 1:05:07 - loss: 0.2488 - accuracy: 0.8988\n",
      " training set -> batch:654 loss:0.2423228621482849 and acc: 0.8999999761581421\n",
      "154/500 [========>.....................] - ETA: 1:04:51 - loss: 0.2423 - accuracy: 0.9000\n",
      " training set -> batch:655 loss:0.23283056914806366 and acc: 0.9031007885932922\n",
      "155/500 [========>.....................] - ETA: 1:04:35 - loss: 0.2328 - accuracy: 0.9031\n",
      " training set -> batch:656 loss:0.2264385223388672 and acc: 0.9041353464126587\n",
      "156/500 [========>.....................] - ETA: 1:04:20 - loss: 0.2264 - accuracy: 0.9041\n",
      " training set -> batch:657 loss:0.23154662549495697 and acc: 0.9032846689224243\n",
      "157/500 [========>.....................] - ETA: 1:04:04 - loss: 0.2315 - accuracy: 0.9033\n",
      " training set -> batch:658 loss:0.2280111312866211 and acc: 0.9051418304443359\n",
      "158/500 [========>.....................] - ETA: 1:03:49 - loss: 0.2280 - accuracy: 0.9051\n",
      " training set -> batch:659 loss:0.22908572852611542 and acc: 0.9043103456497192\n",
      "159/500 [========>.....................] - ETA: 1:03:34 - loss: 0.2291 - accuracy: 0.9043\n",
      " training set -> batch:660 loss:0.22526629269123077 and acc: 0.9035235047340393\n",
      "160/500 [========>.....................] - ETA: 1:03:19 - loss: 0.2253 - accuracy: 0.9035\n",
      " training set -> batch:661 loss:0.22075265645980835 and acc: 0.904411792755127\n",
      "161/500 [========>.....................] - ETA: 1:03:04 - loss: 0.2208 - accuracy: 0.9044\n",
      " training set -> batch:662 loss:0.2232189029455185 and acc: 0.9036624431610107\n",
      "162/500 [========>.....................] - ETA: 1:02:49 - loss: 0.2232 - accuracy: 0.9037\n",
      " training set -> batch:663 loss:0.22088982164859772 and acc: 0.9045031070709229\n",
      "163/500 [========>.....................] - ETA: 1:02:35 - loss: 0.2209 - accuracy: 0.9045\n",
      " training set -> batch:664 loss:0.2235146313905716 and acc: 0.9037878513336182\n",
      "164/500 [========>.....................] - ETA: 1:02:20 - loss: 0.2235 - accuracy: 0.9038\n",
      " training set -> batch:665 loss:0.21869568526744843 and acc: 0.9053254723548889\n",
      "165/500 [========>.....................] - ETA: 1:02:05 - loss: 0.2187 - accuracy: 0.9053\n",
      " training set -> batch:666 loss:0.221161887049675 and acc: 0.9053468108177185\n",
      "166/500 [========>.....................] - ETA: 1:01:51 - loss: 0.2212 - accuracy: 0.9053\n",
      " training set -> batch:667 loss:0.2217874675989151 and acc: 0.9046609997749329\n",
      "167/500 [=========>....................] - ETA: 1:01:37 - loss: 0.2218 - accuracy: 0.9047\n",
      " training set -> batch:668 loss:0.22193825244903564 and acc: 0.905386745929718\n",
      "168/500 [=========>....................] - ETA: 1:01:22 - loss: 0.2219 - accuracy: 0.9054\n",
      " training set -> batch:669 loss:0.21796822547912598 and acc: 0.9067567586898804\n",
      "169/500 [=========>....................] - ETA: 1:01:08 - loss: 0.2180 - accuracy: 0.9068\n",
      " training set -> batch:670 loss:0.21563680469989777 and acc: 0.9067460298538208\n",
      "170/500 [=========>....................] - ETA: 1:00:54 - loss: 0.2156 - accuracy: 0.9067\n",
      " training set -> batch:671 loss:0.21905305981636047 and acc: 0.9060880541801453\n",
      "171/500 [=========>....................] - ETA: 1:00:39 - loss: 0.2191 - accuracy: 0.9061\n",
      " training set -> batch:672 loss:0.21824370324611664 and acc: 0.9060913920402527\n",
      "172/500 [=========>....................] - ETA: 1:00:25 - loss: 0.2182 - accuracy: 0.9061\n",
      " training set -> batch:673 loss:0.21437020599842072 and acc: 0.9079601764678955\n",
      "173/500 [=========>....................] - ETA: 1:00:11 - loss: 0.2144 - accuracy: 0.9080\n",
      " training set -> batch:674 loss:0.21014976501464844 and acc: 0.9097561240196228\n",
      "174/500 [=========>....................] - ETA: 59:57 - loss: 0.2101 - accuracy: 0.9098  \n",
      " training set -> batch:675 loss:0.21375298500061035 and acc: 0.9090909361839294\n",
      "175/500 [=========>....................] - ETA: 59:43 - loss: 0.2138 - accuracy: 0.9091\n",
      " training set -> batch:676 loss:0.21194800734519958 and acc: 0.9096243977546692\n",
      "176/500 [=========>....................] - ETA: 59:29 - loss: 0.2119 - accuracy: 0.9096\n",
      " training set -> batch:677 loss:0.2187059223651886 and acc: 0.9084101319313049\n",
      "177/500 [=========>....................] - ETA: 59:15 - loss: 0.2187 - accuracy: 0.9084\n",
      " training set -> batch:678 loss:0.21746304631233215 and acc: 0.9089366793632507\n",
      "178/500 [=========>....................] - ETA: 59:01 - loss: 0.2175 - accuracy: 0.9089\n",
      " training set -> batch:679 loss:0.21857115626335144 and acc: 0.9083333611488342\n",
      "179/500 [=========>....................] - ETA: 58:47 - loss: 0.2186 - accuracy: 0.9083\n",
      " training set -> batch:680 loss:0.21670059859752655 and acc: 0.9093886613845825\n",
      "180/500 [=========>....................] - ETA: 58:34 - loss: 0.2167 - accuracy: 0.9094\n",
      " training set -> batch:681 loss:0.21559181809425354 and acc: 0.9093347787857056\n",
      "181/500 [=========>....................] - ETA: 58:20 - loss: 0.2156 - accuracy: 0.9093\n",
      " training set -> batch:682 loss:0.21271011233329773 and acc: 0.9108649492263794\n",
      "182/500 [=========>....................] - ETA: 58:07 - loss: 0.2127 - accuracy: 0.9109\n",
      " training set -> batch:683 loss:0.2169402688741684 and acc: 0.9097510576248169\n",
      "183/500 [=========>....................] - ETA: 57:53 - loss: 0.2169 - accuracy: 0.9098\n",
      " training set -> batch:684 loss:0.21613603830337524 and acc: 0.9102040529251099\n",
      "184/500 [==========>...................] - ETA: 57:41 - loss: 0.2161 - accuracy: 0.9102\n",
      " training set -> batch:685 loss:0.21345533430576324 and acc: 0.9111445546150208\n",
      "185/500 [==========>...................] - ETA: 57:27 - loss: 0.2135 - accuracy: 0.9111\n",
      " training set -> batch:686 loss:0.21500834822654724 and acc: 0.9100790619850159\n",
      "186/500 [==========>...................] - ETA: 57:14 - loss: 0.2150 - accuracy: 0.9101\n",
      " training set -> batch:687 loss:0.21239961683750153 and acc: 0.911478579044342\n",
      "187/500 [==========>...................] - ETA: 57:00 - loss: 0.2124 - accuracy: 0.9115\n",
      " training set -> batch:688 loss:0.2133762687444687 and acc: 0.9113984704017639\n",
      "188/500 [==========>...................] - ETA: 56:47 - loss: 0.2134 - accuracy: 0.9114\n",
      " training set -> batch:689 loss:0.21497251093387604 and acc: 0.9108490347862244\n",
      "189/500 [==========>...................] - ETA: 56:33 - loss: 0.2150 - accuracy: 0.9108\n",
      " training set -> batch:690 loss:0.2172546535730362 and acc: 0.910315990447998\n",
      "190/500 [==========>...................] - ETA: 56:19 - loss: 0.2173 - accuracy: 0.9103\n",
      " training set -> batch:691 loss:0.21591421961784363 and acc: 0.9111721515655518\n",
      "191/500 [==========>...................] - ETA: 56:06 - loss: 0.2159 - accuracy: 0.9112\n",
      " training set -> batch:692 loss:0.21656130254268646 and acc: 0.910649836063385\n",
      "192/500 [==========>...................] - ETA: 55:53 - loss: 0.2166 - accuracy: 0.9106\n",
      " training set -> batch:693 loss:0.21539808809757233 and acc: 0.9110320210456848\n",
      "193/500 [==========>...................] - ETA: 55:40 - loss: 0.2154 - accuracy: 0.9110\n",
      " training set -> batch:694 loss:0.2135569155216217 and acc: 0.9122806787490845\n",
      "194/500 [==========>...................] - ETA: 55:27 - loss: 0.2136 - accuracy: 0.9123\n",
      " training set -> batch:695 loss:0.21394309401512146 and acc: 0.9126297831535339\n",
      "195/500 [==========>...................] - ETA: 55:14 - loss: 0.2139 - accuracy: 0.9126\n",
      " training set -> batch:696 loss:0.2149009108543396 and acc: 0.9129692912101746\n",
      "196/500 [==========>...................] - ETA: 55:00 - loss: 0.2149 - accuracy: 0.9130\n",
      " training set -> batch:697 loss:0.21348446607589722 and acc: 0.9137205481529236\n",
      "197/500 [==========>...................] - ETA: 54:47 - loss: 0.2135 - accuracy: 0.9137\n",
      " training set -> batch:698 loss:0.21407178044319153 and acc: 0.9140365719795227\n",
      "198/500 [==========>...................] - ETA: 54:34 - loss: 0.2141 - accuracy: 0.9140\n",
      " training set -> batch:699 loss:0.21311920881271362 and acc: 0.9139344096183777\n",
      "199/500 [==========>...................] - ETA: 54:21 - loss: 0.2131 - accuracy: 0.9139\n",
      " training set -> batch:700 loss:0.21526595950126648 and acc: 0.913430392742157\n",
      "\n",
      " validation set -> batch:700 val loss:0.22579559683799744 and val acc: 0.9094036817550659\n",
      "200/500 [===========>..................] - ETA: 56:22 - loss: 0.2153 - accuracy: 0.9134\n",
      " training set -> batch:701 loss:0.22416839003562927 and acc: 0.9092920422554016\n",
      "201/500 [===========>..................] - ETA: 56:08 - loss: 0.2242 - accuracy: 0.9093\n",
      " training set -> batch:702 loss:0.22743690013885498 and acc: 0.9091880321502686\n",
      "202/500 [===========>..................] - ETA: 55:54 - loss: 0.2274 - accuracy: 0.9092\n",
      " training set -> batch:703 loss:0.21857838332653046 and acc: 0.9111570119857788\n",
      "203/500 [===========>..................] - ETA: 55:41 - loss: 0.2186 - accuracy: 0.9112\n",
      " training set -> batch:704 loss:0.224822998046875 and acc: 0.9089999794960022\n",
      "204/500 [===========>..................] - ETA: 55:27 - loss: 0.2248 - accuracy: 0.9090\n",
      " training set -> batch:705 loss:0.2222350537776947 and acc: 0.9108527302742004\n",
      "205/500 [===========>..................] - ETA: 55:13 - loss: 0.2222 - accuracy: 0.9109\n",
      " training set -> batch:706 loss:0.23946306109428406 and acc: 0.9060150384902954\n",
      "206/500 [===========>..................] - ETA: 55:00 - loss: 0.2395 - accuracy: 0.9060\n",
      " training set -> batch:707 loss:0.23322409391403198 and acc: 0.9078466892242432\n",
      "207/500 [===========>..................] - ETA: 54:46 - loss: 0.2332 - accuracy: 0.9078\n",
      " training set -> batch:708 loss:0.2257051020860672 and acc: 0.9104610085487366\n",
      "208/500 [===========>..................] - ETA: 54:32 - loss: 0.2257 - accuracy: 0.9105\n",
      " training set -> batch:709 loss:0.22356829047203064 and acc: 0.9112069010734558\n",
      "209/500 [===========>..................] - ETA: 54:19 - loss: 0.2236 - accuracy: 0.9112\n",
      " training set -> batch:710 loss:0.22224067151546478 and acc: 0.911912739276886\n",
      "210/500 [===========>..................] - ETA: 54:05 - loss: 0.2222 - accuracy: 0.9119\n",
      " training set -> batch:711 loss:0.21925869584083557 and acc: 0.9125816822052002\n",
      "211/500 [===========>..................] - ETA: 53:51 - loss: 0.2193 - accuracy: 0.9126\n",
      " training set -> batch:712 loss:0.21756449341773987 and acc: 0.9132165312767029\n",
      "212/500 [===========>..................] - ETA: 53:38 - loss: 0.2176 - accuracy: 0.9132\n",
      " training set -> batch:713 loss:0.21798551082611084 and acc: 0.9122670888900757\n",
      "213/500 [===========>..................] - ETA: 53:24 - loss: 0.2180 - accuracy: 0.9123\n",
      " training set -> batch:714 loss:0.2198195457458496 and acc: 0.9128788113594055\n",
      "214/500 [===========>..................] - ETA: 53:11 - loss: 0.2198 - accuracy: 0.9129\n",
      " training set -> batch:715 loss:0.21865254640579224 and acc: 0.9127218723297119\n",
      "215/500 [===========>..................] - ETA: 52:57 - loss: 0.2187 - accuracy: 0.9127\n",
      " training set -> batch:716 loss:0.21398049592971802 and acc: 0.9140173196792603\n",
      "216/500 [===========>..................] - ETA: 52:44 - loss: 0.2140 - accuracy: 0.9140\n",
      " training set -> batch:717 loss:0.21895790100097656 and acc: 0.9131355881690979\n",
      "217/500 [============>.................] - ETA: 52:31 - loss: 0.2190 - accuracy: 0.9131\n",
      " training set -> batch:718 loss:0.2210380733013153 and acc: 0.9129834175109863\n",
      "218/500 [============>.................] - ETA: 52:17 - loss: 0.2210 - accuracy: 0.9130\n",
      " training set -> batch:719 loss:0.22232107818126678 and acc: 0.9114865064620972\n",
      "219/500 [============>.................] - ETA: 52:04 - loss: 0.2223 - accuracy: 0.9115\n",
      " training set -> batch:720 loss:0.22269022464752197 and acc: 0.9113756418228149\n",
      "220/500 [============>.................] - ETA: 51:51 - loss: 0.2227 - accuracy: 0.9114\n",
      " training set -> batch:721 loss:0.22094281017780304 and acc: 0.9112694263458252\n",
      "221/500 [============>.................] - ETA: 51:38 - loss: 0.2209 - accuracy: 0.9113\n",
      " training set -> batch:722 loss:0.21733108162879944 and acc: 0.9124365448951721\n",
      "222/500 [============>.................] - ETA: 51:25 - loss: 0.2173 - accuracy: 0.9124\n",
      " training set -> batch:723 loss:0.215240940451622 and acc: 0.913557231426239\n",
      "223/500 [============>.................] - ETA: 51:12 - loss: 0.2152 - accuracy: 0.9136\n",
      " training set -> batch:724 loss:0.21277384459972382 and acc: 0.9140244126319885\n",
      "224/500 [============>.................] - ETA: 50:59 - loss: 0.2128 - accuracy: 0.9140\n",
      " training set -> batch:725 loss:0.21942466497421265 and acc: 0.9126794338226318\n",
      "225/500 [============>.................] - ETA: 50:46 - loss: 0.2194 - accuracy: 0.9127\n",
      " training set -> batch:726 loss:0.21904811263084412 and acc: 0.9131455421447754\n",
      "226/500 [============>.................] - ETA: 50:33 - loss: 0.2190 - accuracy: 0.9131\n",
      " training set -> batch:727 loss:0.22097960114479065 and acc: 0.9118663668632507\n",
      "227/500 [============>.................] - ETA: 50:20 - loss: 0.2210 - accuracy: 0.9119\n",
      " training set -> batch:728 loss:0.22119057178497314 and acc: 0.9123303294181824\n",
      "228/500 [============>.................] - ETA: 50:07 - loss: 0.2212 - accuracy: 0.9123\n",
      " training set -> batch:729 loss:0.21989990770816803 and acc: 0.9127777814865112\n",
      "229/500 [============>.................] - ETA: 49:54 - loss: 0.2199 - accuracy: 0.9128\n",
      " training set -> batch:730 loss:0.22073151171207428 and acc: 0.9115720391273499\n",
      "230/500 [============>.................] - ETA: 49:41 - loss: 0.2207 - accuracy: 0.9116\n",
      " training set -> batch:731 loss:0.2219485640525818 and acc: 0.9114806652069092\n",
      "231/500 [============>.................] - ETA: 49:28 - loss: 0.2219 - accuracy: 0.9115\n",
      " training set -> batch:732 loss:0.22452421486377716 and acc: 0.9108649492263794\n",
      "232/500 [============>.................] - ETA: 49:15 - loss: 0.2245 - accuracy: 0.9109\n",
      " training set -> batch:733 loss:0.2228194922208786 and acc: 0.9118257164955139\n",
      "233/500 [============>.................] - ETA: 49:02 - loss: 0.2228 - accuracy: 0.9118\n",
      " training set -> batch:734 loss:0.22210299968719482 and acc: 0.9122449159622192\n",
      "234/500 [=============>................] - ETA: 48:49 - loss: 0.2221 - accuracy: 0.9122\n",
      " training set -> batch:735 loss:0.22480081021785736 and acc: 0.9116466045379639\n",
      "235/500 [=============>................] - ETA: 48:37 - loss: 0.2248 - accuracy: 0.9116\n",
      " training set -> batch:736 loss:0.22464591264724731 and acc: 0.9115612506866455\n",
      "236/500 [=============>................] - ETA: 48:24 - loss: 0.2246 - accuracy: 0.9116\n",
      " training set -> batch:737 loss:0.2224915772676468 and acc: 0.9119649529457092\n",
      "237/500 [=============>................] - ETA: 48:11 - loss: 0.2225 - accuracy: 0.9120\n",
      " training set -> batch:738 loss:0.22152145206928253 and acc: 0.9123563170433044\n",
      "238/500 [=============>................] - ETA: 47:59 - loss: 0.2215 - accuracy: 0.9124\n",
      " training set -> batch:739 loss:0.21925561130046844 and acc: 0.9132075309753418\n",
      "239/500 [=============>................] - ETA: 47:46 - loss: 0.2193 - accuracy: 0.9132\n",
      " training set -> batch:740 loss:0.21771354973316193 and acc: 0.9140334725379944\n",
      "240/500 [=============>................] - ETA: 47:33 - loss: 0.2177 - accuracy: 0.9140\n",
      " training set -> batch:741 loss:0.21620474755764008 and acc: 0.9148351550102234\n",
      "241/500 [=============>................] - ETA: 47:21 - loss: 0.2162 - accuracy: 0.9148\n",
      " training set -> batch:742 loss:0.21678273379802704 and acc: 0.9138086438179016\n",
      "242/500 [=============>................] - ETA: 47:08 - loss: 0.2168 - accuracy: 0.9138\n",
      " training set -> batch:743 loss:0.21897640824317932 and acc: 0.9128113985061646\n",
      "243/500 [=============>................] - ETA: 46:56 - loss: 0.2190 - accuracy: 0.9128\n",
      " training set -> batch:744 loss:0.21964122354984283 and acc: 0.9127193093299866\n",
      "244/500 [=============>................] - ETA: 46:43 - loss: 0.2196 - accuracy: 0.9127\n",
      " training set -> batch:745 loss:0.21879442036151886 and acc: 0.9130622744560242\n",
      "245/500 [=============>................] - ETA: 46:30 - loss: 0.2188 - accuracy: 0.9131\n",
      " training set -> batch:746 loss:0.21894101798534393 and acc: 0.913395881652832\n",
      "246/500 [=============>................] - ETA: 46:18 - loss: 0.2189 - accuracy: 0.9134\n",
      " training set -> batch:747 loss:0.21795283257961273 and acc: 0.9137205481529236\n",
      "247/500 [=============>................] - ETA: 46:06 - loss: 0.2180 - accuracy: 0.9137\n",
      " training set -> batch:748 loss:0.21838253736495972 and acc: 0.9136212468147278\n",
      "248/500 [=============>................] - ETA: 45:53 - loss: 0.2184 - accuracy: 0.9136\n",
      " training set -> batch:749 loss:0.2172604352235794 and acc: 0.9139344096183777\n",
      "249/500 [=============>................] - ETA: 45:41 - loss: 0.2173 - accuracy: 0.9139\n",
      " training set -> batch:750 loss:0.21525661647319794 and acc: 0.9146440029144287\n",
      "\n",
      " validation set -> batch:750 val loss:0.23936256766319275 and val acc: 0.8979358077049255\n",
      "250/500 [==============>...............] - ETA: 46:59 - loss: 0.2153 - accuracy: 0.9146\n",
      " training set -> batch:751 loss:0.23357076942920685 and acc: 0.9004424810409546\n",
      "251/500 [==============>...............] - ETA: 46:47 - loss: 0.2336 - accuracy: 0.9004\n",
      " training set -> batch:752 loss:0.2435893565416336 and acc: 0.8985042572021484\n",
      "252/500 [==============>...............] - ETA: 46:33 - loss: 0.2436 - accuracy: 0.8985\n",
      " training set -> batch:753 loss:0.2358076423406601 and acc: 0.8997933864593506\n",
      "253/500 [==============>...............] - ETA: 46:20 - loss: 0.2358 - accuracy: 0.8998\n",
      " training set -> batch:754 loss:0.23051714897155762 and acc: 0.9010000228881836\n",
      "254/500 [==============>...............] - ETA: 46:07 - loss: 0.2305 - accuracy: 0.9010\n",
      " training set -> batch:755 loss:0.23587262630462646 and acc: 0.9001938104629517\n",
      "255/500 [==============>...............] - ETA: 45:54 - loss: 0.2359 - accuracy: 0.9002\n",
      " training set -> batch:756 loss:0.2337111532688141 and acc: 0.8994361162185669\n",
      "256/500 [==============>...............] - ETA: 45:41 - loss: 0.2337 - accuracy: 0.8994\n",
      " training set -> batch:757 loss:0.22938735783100128 and acc: 0.900547444820404\n",
      "257/500 [==============>...............] - ETA: 45:28 - loss: 0.2294 - accuracy: 0.9005\n",
      " training set -> batch:758 loss:0.24539202451705933 and acc: 0.896276593208313\n",
      "258/500 [==============>...............] - ETA: 45:15 - loss: 0.2454 - accuracy: 0.8963\n",
      " training set -> batch:759 loss:0.24094857275485992 and acc: 0.8974137902259827\n",
      "259/500 [==============>...............] - ETA: 45:03 - loss: 0.2409 - accuracy: 0.8974\n",
      " training set -> batch:760 loss:0.2426316738128662 and acc: 0.8976510167121887\n",
      "260/500 [==============>...............] - ETA: 44:50 - loss: 0.2426 - accuracy: 0.8977\n",
      " training set -> batch:761 loss:0.23972319066524506 and acc: 0.8995097875595093\n",
      "261/500 [==============>...............] - ETA: 44:37 - loss: 0.2397 - accuracy: 0.8995\n",
      " training set -> batch:762 loss:0.24045394361019135 and acc: 0.9012739062309265\n",
      "262/500 [==============>...............] - ETA: 44:24 - loss: 0.2405 - accuracy: 0.9013\n",
      " training set -> batch:763 loss:0.241943359375 and acc: 0.9006211161613464\n",
      "263/500 [==============>...............] - ETA: 44:11 - loss: 0.2419 - accuracy: 0.9006\n",
      " training set -> batch:764 loss:0.23868776857852936 and acc: 0.9022727012634277\n",
      "264/500 [==============>...............] - ETA: 43:59 - loss: 0.2387 - accuracy: 0.9023\n",
      " training set -> batch:765 loss:0.24004103243350983 and acc: 0.9031065106391907\n",
      "265/500 [==============>...............] - ETA: 43:46 - loss: 0.2400 - accuracy: 0.9031\n",
      " training set -> batch:766 loss:0.23746734857559204 and acc: 0.9039017558097839\n",
      "266/500 [==============>...............] - ETA: 43:33 - loss: 0.2375 - accuracy: 0.9039\n",
      " training set -> batch:767 loss:0.232633575797081 and acc: 0.9053672552108765\n",
      "267/500 [===============>..............] - ETA: 43:21 - loss: 0.2326 - accuracy: 0.9054\n",
      " training set -> batch:768 loss:0.23077918589115143 and acc: 0.9060773253440857\n",
      "268/500 [===============>..............] - ETA: 43:08 - loss: 0.2308 - accuracy: 0.9061\n",
      " training set -> batch:769 loss:0.23763078451156616 and acc: 0.9040540456771851\n",
      "269/500 [===============>..............] - ETA: 42:55 - loss: 0.2376 - accuracy: 0.9041\n",
      " training set -> batch:770 loss:0.2350481003522873 and acc: 0.9047619104385376\n",
      "270/500 [===============>..............] - ETA: 42:42 - loss: 0.2350 - accuracy: 0.9048\n",
      " training set -> batch:771 loss:0.2340584546327591 and acc: 0.9054403901100159\n",
      "271/500 [===============>..............] - ETA: 42:30 - loss: 0.2341 - accuracy: 0.9054\n",
      " training set -> batch:772 loss:0.23574692010879517 and acc: 0.9048223495483398\n",
      "272/500 [===============>..............] - ETA: 42:17 - loss: 0.2357 - accuracy: 0.9048\n",
      " training set -> batch:773 loss:0.23676392436027527 and acc: 0.9042288661003113\n",
      "273/500 [===============>..............] - ETA: 42:05 - loss: 0.2368 - accuracy: 0.9042\n",
      " training set -> batch:774 loss:0.23297199606895447 and acc: 0.9054877758026123\n",
      "274/500 [===============>..............] - ETA: 41:52 - loss: 0.2330 - accuracy: 0.9055\n",
      " training set -> batch:775 loss:0.2326473891735077 and acc: 0.9055023789405823\n",
      "275/500 [===============>..............] - ETA: 41:40 - loss: 0.2326 - accuracy: 0.9055\n",
      " training set -> batch:776 loss:0.2303120642900467 and acc: 0.9061033129692078\n",
      "276/500 [===============>..............] - ETA: 41:27 - loss: 0.2303 - accuracy: 0.9061\n",
      " training set -> batch:777 loss:0.22733324766159058 and acc: 0.9072580933570862\n",
      "277/500 [===============>..............] - ETA: 41:15 - loss: 0.2273 - accuracy: 0.9073\n",
      " training set -> batch:778 loss:0.22762754559516907 and acc: 0.9061086177825928\n",
      "278/500 [===============>..............] - ETA: 41:03 - loss: 0.2276 - accuracy: 0.9061\n",
      " training set -> batch:779 loss:0.23030395805835724 and acc: 0.9061111211776733\n",
      "279/500 [===============>..............] - ETA: 40:50 - loss: 0.2303 - accuracy: 0.9061\n",
      " training set -> batch:780 loss:0.2283148616552353 and acc: 0.9066593647003174\n",
      "280/500 [===============>..............] - ETA: 40:38 - loss: 0.2283 - accuracy: 0.9067\n",
      " training set -> batch:781 loss:0.2254382073879242 and acc: 0.9077253341674805\n",
      "281/500 [===============>..............] - ETA: 40:26 - loss: 0.2254 - accuracy: 0.9077\n",
      " training set -> batch:782 loss:0.2231525480747223 and acc: 0.9087553024291992\n",
      "282/500 [===============>..............] - ETA: 40:13 - loss: 0.2232 - accuracy: 0.9088\n",
      " training set -> batch:783 loss:0.22069869935512543 and acc: 0.9097510576248169\n",
      "283/500 [===============>..............] - ETA: 40:01 - loss: 0.2207 - accuracy: 0.9098\n",
      " training set -> batch:784 loss:0.22161678969860077 and acc: 0.9086734652519226\n",
      "284/500 [================>.............] - ETA: 39:49 - loss: 0.2216 - accuracy: 0.9087\n",
      " training set -> batch:785 loss:0.22146746516227722 and acc: 0.9091365337371826\n",
      "285/500 [================>.............] - ETA: 39:37 - loss: 0.2215 - accuracy: 0.9091\n",
      " training set -> batch:786 loss:0.2187705934047699 and acc: 0.9100790619850159\n",
      "286/500 [================>.............] - ETA: 39:24 - loss: 0.2188 - accuracy: 0.9101\n",
      " training set -> batch:787 loss:0.21990592777729034 and acc: 0.9095330834388733\n",
      "287/500 [================>.............] - ETA: 39:12 - loss: 0.2199 - accuracy: 0.9095\n",
      " training set -> batch:788 loss:0.2192186415195465 and acc: 0.9104406237602234\n",
      "288/500 [================>.............] - ETA: 39:00 - loss: 0.2192 - accuracy: 0.9104\n",
      " training set -> batch:789 loss:0.2167777717113495 and acc: 0.9113207459449768\n",
      "289/500 [================>.............] - ETA: 38:48 - loss: 0.2168 - accuracy: 0.9113\n",
      " training set -> batch:790 loss:0.21478287875652313 and acc: 0.9121747016906738\n",
      "290/500 [================>.............] - ETA: 38:36 - loss: 0.2148 - accuracy: 0.9122\n",
      " training set -> batch:791 loss:0.21519504487514496 and acc: 0.9120879173278809\n",
      "291/500 [================>.............] - ETA: 38:24 - loss: 0.2152 - accuracy: 0.9121\n",
      " training set -> batch:792 loss:0.21898683905601501 and acc: 0.910649836063385\n",
      "292/500 [================>.............] - ETA: 38:12 - loss: 0.2190 - accuracy: 0.9106\n",
      " training set -> batch:793 loss:0.21718871593475342 and acc: 0.9110320210456848\n",
      "293/500 [================>.............] - ETA: 38:00 - loss: 0.2172 - accuracy: 0.9110\n",
      " training set -> batch:794 loss:0.2187952995300293 and acc: 0.9105263352394104\n",
      "294/500 [================>.............] - ETA: 37:48 - loss: 0.2188 - accuracy: 0.9105\n",
      " training set -> batch:795 loss:0.21758608520030975 and acc: 0.9113321900367737\n",
      "295/500 [================>.............] - ETA: 37:35 - loss: 0.2176 - accuracy: 0.9113\n",
      " training set -> batch:796 loss:0.21722479164600372 and acc: 0.9108361601829529\n",
      "296/500 [================>.............] - ETA: 37:23 - loss: 0.2172 - accuracy: 0.9108\n",
      " training set -> batch:797 loss:0.21861320734024048 and acc: 0.9103535413742065\n",
      "297/500 [================>.............] - ETA: 37:11 - loss: 0.2186 - accuracy: 0.9104\n",
      " training set -> batch:798 loss:0.21798041462898254 and acc: 0.9107142686843872\n",
      "298/500 [================>.............] - ETA: 36:59 - loss: 0.2180 - accuracy: 0.9107\n",
      " training set -> batch:799 loss:0.21775518357753754 and acc: 0.9110655784606934\n",
      "299/500 [================>.............] - ETA: 36:47 - loss: 0.2178 - accuracy: 0.9111\n",
      " training set -> batch:800 loss:0.218553826212883 and acc: 0.9110032320022583\n",
      "\n",
      " validation set -> batch:800 val loss:0.236238494515419 and val acc: 0.9094036817550659\n",
      "300/500 [=================>............] - ETA: 37:36 - loss: 0.2186 - accuracy: 0.9110\n",
      " training set -> batch:801 loss:0.22370286285877228 and acc: 0.9126105904579163\n",
      "301/500 [=================>............] - ETA: 37:23 - loss: 0.2237 - accuracy: 0.9126\n",
      " training set -> batch:802 loss:0.22077608108520508 and acc: 0.9145299196243286\n",
      "302/500 [=================>............] - ETA: 37:11 - loss: 0.2208 - accuracy: 0.9145\n",
      " training set -> batch:803 loss:0.212337464094162 and acc: 0.9163222908973694\n",
      "303/500 [=================>............] - ETA: 36:58 - loss: 0.2123 - accuracy: 0.9163\n",
      " training set -> batch:804 loss:0.21466536819934845 and acc: 0.9150000214576721\n",
      "304/500 [=================>............] - ETA: 36:46 - loss: 0.2147 - accuracy: 0.9150\n",
      " training set -> batch:805 loss:0.21113348007202148 and acc: 0.9156976938247681\n",
      "305/500 [=================>............] - ETA: 36:34 - loss: 0.2111 - accuracy: 0.9157\n",
      " training set -> batch:806 loss:0.20679333806037903 and acc: 0.9163534045219421\n",
      "306/500 [=================>............] - ETA: 36:21 - loss: 0.2068 - accuracy: 0.9164\n",
      " training set -> batch:807 loss:0.20786605775356293 and acc: 0.9160584211349487\n",
      "307/500 [=================>............] - ETA: 36:10 - loss: 0.2079 - accuracy: 0.9161\n",
      " training set -> batch:808 loss:0.2135288566350937 and acc: 0.914893627166748\n",
      "308/500 [=================>............] - ETA: 35:57 - loss: 0.2135 - accuracy: 0.9149\n",
      " training set -> batch:809 loss:0.21282926201820374 and acc: 0.9137930870056152\n",
      "309/500 [=================>............] - ETA: 35:45 - loss: 0.2128 - accuracy: 0.9138\n",
      " training set -> batch:810 loss:0.22324661910533905 and acc: 0.9102349281311035\n",
      "310/500 [=================>............] - ETA: 35:33 - loss: 0.2232 - accuracy: 0.9102\n",
      " training set -> batch:811 loss:0.22200408577919006 and acc: 0.9109477400779724\n",
      "311/500 [=================>............] - ETA: 35:21 - loss: 0.2220 - accuracy: 0.9109\n",
      " training set -> batch:812 loss:0.21961945295333862 and acc: 0.9116241931915283\n",
      "312/500 [=================>............] - ETA: 35:08 - loss: 0.2196 - accuracy: 0.9116\n",
      " training set -> batch:813 loss:0.22233134508132935 and acc: 0.9114906787872314\n",
      "313/500 [=================>............] - ETA: 34:56 - loss: 0.2223 - accuracy: 0.9115\n",
      " training set -> batch:814 loss:0.21847757697105408 and acc: 0.9128788113594055\n",
      "314/500 [=================>............] - ETA: 34:44 - loss: 0.2185 - accuracy: 0.9129\n",
      " training set -> batch:815 loss:0.2217613160610199 and acc: 0.9112426042556763\n",
      "315/500 [=================>............] - ETA: 34:32 - loss: 0.2218 - accuracy: 0.9112\n",
      " training set -> batch:816 loss:0.21613642573356628 and acc: 0.913294792175293\n",
      "316/500 [=================>............] - ETA: 34:20 - loss: 0.2161 - accuracy: 0.9133\n",
      " training set -> batch:817 loss:0.21469053626060486 and acc: 0.9138417840003967\n",
      "317/500 [==================>...........] - ETA: 34:08 - loss: 0.2147 - accuracy: 0.9138\n",
      " training set -> batch:818 loss:0.21771159768104553 and acc: 0.9129834175109863\n",
      "318/500 [==================>...........] - ETA: 33:56 - loss: 0.2177 - accuracy: 0.9130\n",
      " training set -> batch:819 loss:0.21924170851707458 and acc: 0.912162184715271\n",
      "319/500 [==================>...........] - ETA: 33:44 - loss: 0.2192 - accuracy: 0.9122\n",
      " training set -> batch:820 loss:0.22066351771354675 and acc: 0.9120370149612427\n",
      "320/500 [==================>...........] - ETA: 33:31 - loss: 0.2207 - accuracy: 0.9120\n",
      " training set -> batch:821 loss:0.22016866505146027 and acc: 0.912564754486084\n",
      "321/500 [==================>...........] - ETA: 33:19 - loss: 0.2202 - accuracy: 0.9126\n",
      " training set -> batch:822 loss:0.2245377153158188 and acc: 0.9118020534515381\n",
      "322/500 [==================>...........] - ETA: 33:07 - loss: 0.2245 - accuracy: 0.9118\n",
      " training set -> batch:823 loss:0.22600983083248138 and acc: 0.9104477763175964\n",
      "323/500 [==================>...........] - ETA: 32:55 - loss: 0.2260 - accuracy: 0.9104\n",
      " training set -> batch:824 loss:0.22554174065589905 and acc: 0.9109756350517273\n",
      "324/500 [==================>...........] - ETA: 32:43 - loss: 0.2255 - accuracy: 0.9110\n",
      " training set -> batch:825 loss:0.22428089380264282 and acc: 0.9114832282066345\n",
      "325/500 [==================>...........] - ETA: 32:31 - loss: 0.2243 - accuracy: 0.9115\n",
      " training set -> batch:826 loss:0.22027774155139923 and acc: 0.9131455421447754\n",
      "326/500 [==================>...........] - ETA: 32:19 - loss: 0.2203 - accuracy: 0.9131\n",
      " training set -> batch:827 loss:0.21826788783073425 and acc: 0.914170503616333\n",
      "327/500 [==================>...........] - ETA: 32:07 - loss: 0.2183 - accuracy: 0.9142\n",
      " training set -> batch:828 loss:0.2154516875743866 and acc: 0.9151583909988403\n",
      "328/500 [==================>...........] - ETA: 31:55 - loss: 0.2155 - accuracy: 0.9152\n",
      " training set -> batch:829 loss:0.2145053744316101 and acc: 0.9144444465637207\n",
      "329/500 [==================>...........] - ETA: 31:43 - loss: 0.2145 - accuracy: 0.9144\n",
      " training set -> batch:830 loss:0.22022920846939087 and acc: 0.9126637578010559\n",
      "330/500 [==================>...........] - ETA: 31:31 - loss: 0.2202 - accuracy: 0.9127\n",
      " training set -> batch:831 loss:0.21894480288028717 and acc: 0.9130901098251343\n",
      "331/500 [==================>...........] - ETA: 31:19 - loss: 0.2189 - accuracy: 0.9131\n",
      " training set -> batch:832 loss:0.2190830558538437 and acc: 0.9135020971298218\n",
      "332/500 [==================>...........] - ETA: 31:07 - loss: 0.2191 - accuracy: 0.9135\n",
      " training set -> batch:833 loss:0.2166219800710678 and acc: 0.9144191145896912\n",
      "333/500 [==================>...........] - ETA: 30:55 - loss: 0.2166 - accuracy: 0.9144\n",
      " training set -> batch:834 loss:0.21455778181552887 and acc: 0.9153061509132385\n",
      "334/500 [===================>..........] - ETA: 30:43 - loss: 0.2146 - accuracy: 0.9153\n",
      " training set -> batch:835 loss:0.21318091452121735 and acc: 0.9161646366119385\n",
      "335/500 [===================>..........] - ETA: 30:32 - loss: 0.2132 - accuracy: 0.9162\n",
      " training set -> batch:836 loss:0.21443133056163788 and acc: 0.915513813495636\n",
      "336/500 [===================>..........] - ETA: 30:20 - loss: 0.2144 - accuracy: 0.9155\n",
      " training set -> batch:837 loss:0.21218915283679962 and acc: 0.9163424372673035\n",
      "337/500 [===================>..........] - ETA: 30:08 - loss: 0.2122 - accuracy: 0.9163\n",
      " training set -> batch:838 loss:0.211141899228096 and acc: 0.9166666865348816\n",
      "338/500 [===================>..........] - ETA: 29:56 - loss: 0.2111 - accuracy: 0.9167\n",
      " training set -> batch:839 loss:0.20894502103328705 and acc: 0.9174528121948242\n",
      "339/500 [===================>..........] - ETA: 29:44 - loss: 0.2089 - accuracy: 0.9175\n",
      " training set -> batch:840 loss:0.20926664769649506 and acc: 0.917286217212677\n",
      "340/500 [===================>..........] - ETA: 29:32 - loss: 0.2093 - accuracy: 0.9173\n",
      " training set -> batch:841 loss:0.20883160829544067 and acc: 0.9171245694160461\n",
      "341/500 [===================>..........] - ETA: 29:21 - loss: 0.2088 - accuracy: 0.9171\n",
      " training set -> batch:842 loss:0.2093571573495865 and acc: 0.9174187779426575\n",
      "342/500 [===================>..........] - ETA: 29:09 - loss: 0.2094 - accuracy: 0.9174\n",
      " training set -> batch:843 loss:0.20985253155231476 and acc: 0.916814923286438\n",
      "343/500 [===================>..........] - ETA: 28:57 - loss: 0.2099 - accuracy: 0.9168\n",
      " training set -> batch:844 loss:0.21198081970214844 and acc: 0.9162280559539795\n",
      "344/500 [===================>..........] - ETA: 28:45 - loss: 0.2120 - accuracy: 0.9162\n",
      " training set -> batch:845 loss:0.21224172413349152 and acc: 0.9160899519920349\n",
      "345/500 [===================>..........] - ETA: 28:33 - loss: 0.2122 - accuracy: 0.9161\n",
      " training set -> batch:846 loss:0.2115592062473297 and acc: 0.9163822531700134\n",
      "346/500 [===================>..........] - ETA: 28:22 - loss: 0.2116 - accuracy: 0.9164\n",
      " training set -> batch:847 loss:0.20935703814029694 and acc: 0.9166666865348816\n",
      "347/500 [===================>..........] - ETA: 28:10 - loss: 0.2094 - accuracy: 0.9167\n",
      " training set -> batch:848 loss:0.21254383027553558 and acc: 0.9156976938247681\n",
      "348/500 [===================>..........] - ETA: 27:58 - loss: 0.2125 - accuracy: 0.9157\n",
      " training set -> batch:849 loss:0.21040765941143036 and acc: 0.9163934588432312\n",
      "349/500 [===================>..........] - ETA: 27:47 - loss: 0.2104 - accuracy: 0.9164\n",
      " training set -> batch:850 loss:0.2098202109336853 and acc: 0.9170712232589722\n",
      "\n",
      " validation set -> batch:850 val loss:0.22308865189552307 and val acc: 0.9094036817550659\n",
      "350/500 [====================>.........] - ETA: 28:15 - loss: 0.2098 - accuracy: 0.9171\n",
      " training set -> batch:851 loss:0.21342995762825012 and acc: 0.9115044474601746\n",
      "351/500 [====================>.........] - ETA: 28:02 - loss: 0.2134 - accuracy: 0.9115\n",
      " training set -> batch:852 loss:0.20931541919708252 and acc: 0.9134615659713745\n",
      "352/500 [====================>.........] - ETA: 27:50 - loss: 0.2093 - accuracy: 0.9135\n",
      " training set -> batch:853 loss:0.21637368202209473 and acc: 0.9121900796890259\n",
      "353/500 [====================>.........] - ETA: 27:38 - loss: 0.2164 - accuracy: 0.9122\n",
      " training set -> batch:854 loss:0.21265842020511627 and acc: 0.9120000004768372\n",
      "354/500 [====================>.........] - ETA: 27:26 - loss: 0.2127 - accuracy: 0.9120\n",
      " training set -> batch:855 loss:0.20948836207389832 and acc: 0.9127907156944275\n",
      "355/500 [====================>.........] - ETA: 27:14 - loss: 0.2095 - accuracy: 0.9128\n",
      " training set -> batch:856 loss:0.20955447852611542 and acc: 0.9125939607620239\n",
      "356/500 [====================>.........] - ETA: 27:02 - loss: 0.2096 - accuracy: 0.9126\n",
      " training set -> batch:857 loss:0.21257609128952026 and acc: 0.9096715450286865\n",
      "357/500 [====================>.........] - ETA: 26:50 - loss: 0.2126 - accuracy: 0.9097\n",
      " training set -> batch:858 loss:0.21170973777770996 and acc: 0.9104610085487366\n",
      "358/500 [====================>.........] - ETA: 26:39 - loss: 0.2117 - accuracy: 0.9105\n",
      " training set -> batch:859 loss:0.20877352356910706 and acc: 0.9112069010734558\n",
      "359/500 [====================>.........] - ETA: 26:27 - loss: 0.2088 - accuracy: 0.9112\n",
      " training set -> batch:860 loss:0.20992690324783325 and acc: 0.9110738039016724\n",
      "360/500 [====================>.........] - ETA: 26:15 - loss: 0.2099 - accuracy: 0.9111\n",
      " training set -> batch:861 loss:0.21326754987239838 and acc: 0.9109477400779724\n",
      "361/500 [====================>.........] - ETA: 26:03 - loss: 0.2133 - accuracy: 0.9109\n",
      " training set -> batch:862 loss:0.21590256690979004 and acc: 0.9108280539512634\n",
      "362/500 [====================>.........] - ETA: 25:51 - loss: 0.2159 - accuracy: 0.9108\n",
      " training set -> batch:863 loss:0.21516098082065582 and acc: 0.9114906787872314\n",
      "363/500 [====================>.........] - ETA: 25:39 - loss: 0.2152 - accuracy: 0.9115\n",
      " training set -> batch:864 loss:0.2137717753648758 and acc: 0.9113636612892151\n",
      "364/500 [====================>.........] - ETA: 25:27 - loss: 0.2138 - accuracy: 0.9114\n",
      " training set -> batch:865 loss:0.2115182876586914 and acc: 0.9127218723297119\n",
      "365/500 [====================>.........] - ETA: 25:15 - loss: 0.2115 - accuracy: 0.9127\n",
      " training set -> batch:866 loss:0.21043090522289276 and acc: 0.913294792175293\n",
      "366/500 [====================>.........] - ETA: 25:04 - loss: 0.2104 - accuracy: 0.9133\n",
      " training set -> batch:867 loss:0.2078389674425125 and acc: 0.9145480394363403\n",
      "367/500 [=====================>........] - ETA: 24:52 - loss: 0.2078 - accuracy: 0.9145\n",
      " training set -> batch:868 loss:0.20696069300174713 and acc: 0.9150552749633789\n",
      "368/500 [=====================>........] - ETA: 24:40 - loss: 0.2070 - accuracy: 0.9151\n",
      " training set -> batch:869 loss:0.20638880133628845 and acc: 0.9155405163764954\n",
      "369/500 [=====================>........] - ETA: 24:28 - loss: 0.2064 - accuracy: 0.9155\n",
      " training set -> batch:870 loss:0.2080325484275818 and acc: 0.9153439402580261\n",
      "370/500 [=====================>........] - ETA: 24:16 - loss: 0.2080 - accuracy: 0.9153\n",
      " training set -> batch:871 loss:0.2073258012533188 and acc: 0.9151554107666016\n",
      "371/500 [=====================>........] - ETA: 24:05 - loss: 0.2073 - accuracy: 0.9152\n",
      " training set -> batch:872 loss:0.20728959143161774 and acc: 0.9149746298789978\n",
      "372/500 [=====================>........] - ETA: 23:53 - loss: 0.2073 - accuracy: 0.9150\n",
      " training set -> batch:873 loss:0.204814612865448 and acc: 0.9160447716712952\n",
      "373/500 [=====================>........] - ETA: 23:41 - loss: 0.2048 - accuracy: 0.9160\n",
      " training set -> batch:874 loss:0.2061045914888382 and acc: 0.9170731902122498\n",
      "374/500 [=====================>........] - ETA: 23:29 - loss: 0.2061 - accuracy: 0.9171\n",
      " training set -> batch:875 loss:0.2061004340648651 and acc: 0.9168660044670105\n",
      "375/500 [=====================>........] - ETA: 23:18 - loss: 0.2061 - accuracy: 0.9169\n",
      " training set -> batch:876 loss:0.2068360149860382 and acc: 0.9166666865348816\n",
      "376/500 [=====================>........] - ETA: 23:06 - loss: 0.2068 - accuracy: 0.9167\n",
      " training set -> batch:877 loss:0.2044598013162613 and acc: 0.9176267385482788\n",
      "377/500 [=====================>........] - ETA: 22:54 - loss: 0.2045 - accuracy: 0.9176\n",
      " training set -> batch:878 loss:0.2056570053100586 and acc: 0.9168552160263062\n",
      "378/500 [=====================>........] - ETA: 22:43 - loss: 0.2057 - accuracy: 0.9169\n",
      " training set -> batch:879 loss:0.20364612340927124 and acc: 0.9172222018241882\n",
      "379/500 [=====================>........] - ETA: 22:31 - loss: 0.2036 - accuracy: 0.9172\n",
      " training set -> batch:880 loss:0.20577330887317657 and acc: 0.9181222915649414\n",
      "380/500 [=====================>........] - ETA: 22:19 - loss: 0.2058 - accuracy: 0.9181\n",
      " training set -> batch:881 loss:0.20688092708587646 and acc: 0.917382001876831\n",
      "381/500 [=====================>........] - ETA: 22:08 - loss: 0.2069 - accuracy: 0.9174\n",
      " training set -> batch:882 loss:0.20835012197494507 and acc: 0.9150843620300293\n",
      "382/500 [=====================>........] - ETA: 21:56 - loss: 0.2084 - accuracy: 0.9151\n",
      " training set -> batch:883 loss:0.20856718719005585 and acc: 0.9144191145896912\n",
      "383/500 [=====================>........] - ETA: 21:45 - loss: 0.2086 - accuracy: 0.9144\n",
      " training set -> batch:884 loss:0.20809060335159302 and acc: 0.9147959351539612\n",
      "384/500 [======================>.......] - ETA: 21:33 - loss: 0.2081 - accuracy: 0.9148\n",
      " training set -> batch:885 loss:0.20762628316879272 and acc: 0.9146586060523987\n",
      "385/500 [======================>.......] - ETA: 21:21 - loss: 0.2076 - accuracy: 0.9147\n",
      " training set -> batch:886 loss:0.20890679955482483 and acc: 0.9140316247940063\n",
      "386/500 [======================>.......] - ETA: 21:10 - loss: 0.2089 - accuracy: 0.9140\n",
      " training set -> batch:887 loss:0.20708851516246796 and acc: 0.9143968820571899\n",
      "387/500 [======================>.......] - ETA: 20:58 - loss: 0.2071 - accuracy: 0.9144\n",
      " training set -> batch:888 loss:0.20760758221149445 and acc: 0.913314163684845\n",
      "388/500 [======================>.......] - ETA: 20:46 - loss: 0.2076 - accuracy: 0.9133\n",
      " training set -> batch:889 loss:0.20637114346027374 and acc: 0.9136792421340942\n",
      "389/500 [======================>.......] - ETA: 20:35 - loss: 0.2064 - accuracy: 0.9137\n",
      " training set -> batch:890 loss:0.20663893222808838 and acc: 0.9144981503486633\n",
      "390/500 [======================>.......] - ETA: 20:23 - loss: 0.2066 - accuracy: 0.9145\n",
      " training set -> batch:891 loss:0.20466828346252441 and acc: 0.9152930378913879\n",
      "391/500 [======================>.......] - ETA: 20:12 - loss: 0.2047 - accuracy: 0.9153\n",
      " training set -> batch:892 loss:0.20326447486877441 and acc: 0.916064977645874\n",
      "392/500 [======================>.......] - ETA: 20:00 - loss: 0.2033 - accuracy: 0.9161\n",
      " training set -> batch:893 loss:0.20459412038326263 and acc: 0.9154804348945618\n",
      "393/500 [======================>.......] - ETA: 19:49 - loss: 0.2046 - accuracy: 0.9155\n",
      " training set -> batch:894 loss:0.20405709743499756 and acc: 0.9157894849777222\n",
      "394/500 [======================>.......] - ETA: 19:37 - loss: 0.2041 - accuracy: 0.9158\n",
      " training set -> batch:895 loss:0.20458224415779114 and acc: 0.9152249097824097\n",
      "395/500 [======================>.......] - ETA: 19:26 - loss: 0.2046 - accuracy: 0.9152\n",
      " training set -> batch:896 loss:0.20301960408687592 and acc: 0.9159556031227112\n",
      "396/500 [======================>.......] - ETA: 19:14 - loss: 0.2030 - accuracy: 0.9160\n",
      " training set -> batch:897 loss:0.2022344470024109 and acc: 0.9158248901367188\n",
      "397/500 [======================>.......] - ETA: 19:03 - loss: 0.2022 - accuracy: 0.9158\n",
      " training set -> batch:898 loss:0.2013990432024002 and acc: 0.9161129593849182\n",
      "398/500 [======================>.......] - ETA: 18:51 - loss: 0.2014 - accuracy: 0.9161\n",
      " training set -> batch:899 loss:0.20025697350502014 and acc: 0.9168033003807068\n",
      "399/500 [======================>.......] - ETA: 18:40 - loss: 0.2003 - accuracy: 0.9168\n",
      " training set -> batch:900 loss:0.20007111132144928 and acc: 0.9170712232589722\n",
      "\n",
      " validation set -> batch:900 val loss:0.24588905274868011 and val acc: 0.896789014339447\n",
      "400/500 [=======================>......] - ETA: 18:51 - loss: 0.2001 - accuracy: 0.9171\n",
      " training set -> batch:901 loss:0.2363480180501938 and acc: 0.8993362784385681\n",
      "401/500 [=======================>......] - ETA: 18:39 - loss: 0.2363 - accuracy: 0.8993\n",
      " training set -> batch:902 loss:0.23477427661418915 and acc: 0.8995726704597473\n",
      "402/500 [=======================>......] - ETA: 18:28 - loss: 0.2348 - accuracy: 0.8996\n",
      " training set -> batch:903 loss:0.23022431135177612 and acc: 0.9008264541625977\n",
      "403/500 [=======================>......] - ETA: 18:16 - loss: 0.2302 - accuracy: 0.9008\n",
      " training set -> batch:904 loss:0.23411686718463898 and acc: 0.8999999761581421\n",
      "404/500 [=======================>......] - ETA: 18:04 - loss: 0.2341 - accuracy: 0.9000\n",
      " training set -> batch:905 loss:0.22485189139842987 and acc: 0.9031007885932922\n",
      "405/500 [=======================>......] - ETA: 17:52 - loss: 0.2249 - accuracy: 0.9031\n",
      " training set -> batch:906 loss:0.2221977263689041 and acc: 0.9041353464126587\n",
      "406/500 [=======================>......] - ETA: 17:41 - loss: 0.2222 - accuracy: 0.9041\n",
      " training set -> batch:907 loss:0.23170198500156403 and acc: 0.9032846689224243\n",
      "407/500 [=======================>......] - ETA: 17:29 - loss: 0.2317 - accuracy: 0.9033\n",
      " training set -> batch:908 loss:0.22734814882278442 and acc: 0.9042553305625916\n",
      "408/500 [=======================>......] - ETA: 17:17 - loss: 0.2273 - accuracy: 0.9043\n",
      " training set -> batch:909 loss:0.22078464925289154 and acc: 0.9060344696044922\n",
      "409/500 [=======================>......] - ETA: 17:06 - loss: 0.2208 - accuracy: 0.9060\n",
      " training set -> batch:910 loss:0.21791915595531464 and acc: 0.9060402512550354\n",
      "410/500 [=======================>......] - ETA: 16:54 - loss: 0.2179 - accuracy: 0.9060\n",
      " training set -> batch:911 loss:0.21102818846702576 and acc: 0.9084967374801636\n",
      "411/500 [=======================>......] - ETA: 16:42 - loss: 0.2110 - accuracy: 0.9085\n",
      " training set -> batch:912 loss:0.21373340487480164 and acc: 0.9084395170211792\n",
      "412/500 [=======================>......] - ETA: 16:31 - loss: 0.2137 - accuracy: 0.9084\n",
      " training set -> batch:913 loss:0.21405550837516785 and acc: 0.9083850979804993\n",
      "413/500 [=======================>......] - ETA: 16:19 - loss: 0.2141 - accuracy: 0.9084\n",
      " training set -> batch:914 loss:0.20897971093654633 and acc: 0.9098485112190247\n",
      "414/500 [=======================>......] - ETA: 16:08 - loss: 0.2090 - accuracy: 0.9098\n",
      " training set -> batch:915 loss:0.20581187307834625 and acc: 0.9112426042556763\n",
      "415/500 [=======================>......] - ETA: 15:56 - loss: 0.2058 - accuracy: 0.9112\n",
      " training set -> batch:916 loss:0.20664431154727936 and acc: 0.9118497371673584\n",
      "416/500 [=======================>......] - ETA: 15:44 - loss: 0.2066 - accuracy: 0.9118\n",
      " training set -> batch:917 loss:0.20793560147285461 and acc: 0.9117231369018555\n",
      "417/500 [========================>.....] - ETA: 15:33 - loss: 0.2079 - accuracy: 0.9117\n",
      " training set -> batch:918 loss:0.2048046886920929 and acc: 0.9129834175109863\n",
      "418/500 [========================>.....] - ETA: 15:21 - loss: 0.2048 - accuracy: 0.9130\n",
      " training set -> batch:919 loss:0.20325921475887299 and acc: 0.9135135412216187\n",
      "419/500 [========================>.....] - ETA: 15:10 - loss: 0.2033 - accuracy: 0.9135\n",
      " training set -> batch:920 loss:0.2025907337665558 and acc: 0.9133597612380981\n",
      "420/500 [========================>.....] - ETA: 14:58 - loss: 0.2026 - accuracy: 0.9134\n",
      " training set -> batch:921 loss:0.2019074261188507 and acc: 0.9138600826263428\n",
      "421/500 [========================>.....] - ETA: 14:46 - loss: 0.2019 - accuracy: 0.9139\n",
      " training set -> batch:922 loss:0.20232024788856506 and acc: 0.913705587387085\n",
      "422/500 [========================>.....] - ETA: 14:35 - loss: 0.2023 - accuracy: 0.9137\n",
      " training set -> batch:923 loss:0.20578649640083313 and acc: 0.9129353165626526\n",
      "423/500 [========================>.....] - ETA: 14:23 - loss: 0.2058 - accuracy: 0.9129\n",
      " training set -> batch:924 loss:0.2050803154706955 and acc: 0.912804901599884\n",
      "424/500 [========================>.....] - ETA: 14:12 - loss: 0.2051 - accuracy: 0.9128\n",
      " training set -> batch:925 loss:0.20286236703395844 and acc: 0.9138755798339844\n",
      "425/500 [========================>.....] - ETA: 14:00 - loss: 0.2029 - accuracy: 0.9139\n",
      " training set -> batch:926 loss:0.1985255777835846 and acc: 0.9154929518699646\n",
      "426/500 [========================>.....] - ETA: 13:49 - loss: 0.1985 - accuracy: 0.9155\n",
      " training set -> batch:927 loss:0.19456912577152252 and acc: 0.9170507192611694\n",
      "427/500 [========================>.....] - ETA: 13:37 - loss: 0.1946 - accuracy: 0.9171\n",
      " training set -> batch:928 loss:0.19573548436164856 and acc: 0.9168552160263062\n",
      "428/500 [========================>.....] - ETA: 13:26 - loss: 0.1957 - accuracy: 0.9169\n",
      " training set -> batch:929 loss:0.19431427121162415 and acc: 0.9177777767181396\n",
      "429/500 [========================>.....] - ETA: 13:14 - loss: 0.1943 - accuracy: 0.9178\n",
      " training set -> batch:930 loss:0.1969783455133438 and acc: 0.9170305728912354\n",
      "430/500 [========================>.....] - ETA: 13:03 - loss: 0.1970 - accuracy: 0.9170\n",
      " training set -> batch:931 loss:0.1961139738559723 and acc: 0.917382001876831\n",
      "431/500 [========================>.....] - ETA: 12:52 - loss: 0.1961 - accuracy: 0.9174\n",
      " training set -> batch:932 loss:0.19423608481884003 and acc: 0.9177215099334717\n",
      "432/500 [========================>.....] - ETA: 12:40 - loss: 0.1942 - accuracy: 0.9177\n",
      " training set -> batch:933 loss:0.1938130259513855 and acc: 0.9180498123168945\n",
      "433/500 [========================>.....] - ETA: 12:29 - loss: 0.1938 - accuracy: 0.9180\n",
      " training set -> batch:934 loss:0.19177423417568207 and acc: 0.9188775420188904\n",
      "434/500 [=========================>....] - ETA: 12:17 - loss: 0.1918 - accuracy: 0.9189\n",
      " training set -> batch:935 loss:0.19101469218730927 and acc: 0.9196786880493164\n",
      "435/500 [=========================>....] - ETA: 12:06 - loss: 0.1910 - accuracy: 0.9197\n",
      " training set -> batch:936 loss:0.1970813125371933 and acc: 0.9189723134040833\n",
      "436/500 [=========================>....] - ETA: 11:54 - loss: 0.1971 - accuracy: 0.9190\n",
      " training set -> batch:937 loss:0.1998729705810547 and acc: 0.917801558971405\n",
      "437/500 [=========================>....] - ETA: 11:43 - loss: 0.1999 - accuracy: 0.9178\n",
      " training set -> batch:938 loss:0.1988416612148285 and acc: 0.9176245331764221\n",
      "438/500 [=========================>....] - ETA: 11:32 - loss: 0.1988 - accuracy: 0.9176\n",
      " training set -> batch:939 loss:0.20174337923526764 and acc: 0.9165094494819641\n",
      "439/500 [=========================>....] - ETA: 11:20 - loss: 0.2017 - accuracy: 0.9165\n",
      " training set -> batch:940 loss:0.2005470246076584 and acc: 0.917286217212677\n",
      "440/500 [=========================>....] - ETA: 11:09 - loss: 0.2005 - accuracy: 0.9173\n",
      " training set -> batch:941 loss:0.20149223506450653 and acc: 0.9171245694160461\n",
      "441/500 [=========================>....] - ETA: 10:57 - loss: 0.2015 - accuracy: 0.9171\n",
      " training set -> batch:942 loss:0.20609642565250397 and acc: 0.9156137108802795\n",
      "442/500 [=========================>....] - ETA: 10:46 - loss: 0.2061 - accuracy: 0.9156\n",
      " training set -> batch:943 loss:0.2060234397649765 and acc: 0.915035605430603\n",
      "443/500 [=========================>....] - ETA: 10:35 - loss: 0.2060 - accuracy: 0.9150\n",
      " training set -> batch:944 loss:0.20430338382720947 and acc: 0.9157894849777222\n",
      "444/500 [=========================>....] - ETA: 10:23 - loss: 0.2043 - accuracy: 0.9158\n",
      " training set -> batch:945 loss:0.2060985416173935 and acc: 0.9147923588752747\n",
      "445/500 [=========================>....] - ETA: 10:12 - loss: 0.2061 - accuracy: 0.9148\n",
      " training set -> batch:946 loss:0.2049088180065155 and acc: 0.9155290126800537\n",
      "446/500 [=========================>....] - ETA: 10:01 - loss: 0.2049 - accuracy: 0.9155\n",
      " training set -> batch:947 loss:0.20573605597019196 and acc: 0.9149831533432007\n",
      "447/500 [=========================>....] - ETA: 9:49 - loss: 0.2057 - accuracy: 0.9150 \n",
      " training set -> batch:948 loss:0.20433086156845093 and acc: 0.9156976938247681\n",
      "448/500 [=========================>....] - ETA: 9:38 - loss: 0.2043 - accuracy: 0.9157\n",
      " training set -> batch:949 loss:0.20549967885017395 and acc: 0.91557377576828\n",
      "449/500 [=========================>....] - ETA: 9:27 - loss: 0.2055 - accuracy: 0.9156\n",
      " training set -> batch:950 loss:0.20505371689796448 and acc: 0.9158576130867004\n",
      "\n",
      " validation set -> batch:950 val loss:0.2223077118396759 and val acc: 0.9059633016586304\n",
      "450/500 [==========================>...] - ETA: 9:26 - loss: 0.2051 - accuracy: 0.9159\n",
      " training set -> batch:951 loss:0.21248802542686462 and acc: 0.9092920422554016\n",
      "451/500 [==========================>...] - ETA: 9:14 - loss: 0.2125 - accuracy: 0.9093\n",
      " training set -> batch:952 loss:0.2030850499868393 and acc: 0.9113247990608215\n",
      "452/500 [==========================>...] - ETA: 9:02 - loss: 0.2031 - accuracy: 0.9113\n",
      " training set -> batch:953 loss:0.19625209271907806 and acc: 0.913223147392273\n",
      "453/500 [==========================>...] - ETA: 8:51 - loss: 0.1963 - accuracy: 0.9132\n",
      " training set -> batch:954 loss:0.19181080162525177 and acc: 0.9139999747276306\n",
      "454/500 [==========================>...] - ETA: 8:40 - loss: 0.1918 - accuracy: 0.9140\n",
      " training set -> batch:955 loss:0.1930704265832901 and acc: 0.9156976938247681\n",
      "455/500 [==========================>...] - ETA: 8:28 - loss: 0.1931 - accuracy: 0.9157\n",
      " training set -> batch:956 loss:0.19339466094970703 and acc: 0.9163534045219421\n",
      "456/500 [==========================>...] - ETA: 8:17 - loss: 0.1934 - accuracy: 0.9164\n",
      " training set -> batch:957 loss:0.1889413595199585 and acc: 0.9178832173347473\n",
      "457/500 [==========================>...] - ETA: 8:05 - loss: 0.1889 - accuracy: 0.9179\n",
      " training set -> batch:958 loss:0.18778105080127716 and acc: 0.9184397459030151\n",
      "458/500 [==========================>...] - ETA: 7:54 - loss: 0.1878 - accuracy: 0.9184\n",
      " training set -> batch:959 loss:0.19084171950817108 and acc: 0.9189655184745789\n",
      "459/500 [==========================>...] - ETA: 7:42 - loss: 0.1908 - accuracy: 0.9190\n",
      " training set -> batch:960 loss:0.19633112847805023 and acc: 0.9177852272987366\n",
      "460/500 [==========================>...] - ETA: 7:31 - loss: 0.1963 - accuracy: 0.9178\n",
      " training set -> batch:961 loss:0.19525155425071716 and acc: 0.9183006286621094\n",
      "461/500 [==========================>...] - ETA: 7:19 - loss: 0.1953 - accuracy: 0.9183\n",
      " training set -> batch:962 loss:0.1912117600440979 and acc: 0.9195860028266907\n",
      "462/500 [==========================>...] - ETA: 7:08 - loss: 0.1912 - accuracy: 0.9196\n",
      " training set -> batch:963 loss:0.1991109997034073 and acc: 0.91847825050354\n",
      "463/500 [==========================>...] - ETA: 6:56 - loss: 0.1991 - accuracy: 0.9185\n",
      " training set -> batch:964 loss:0.19557249546051025 and acc: 0.9196969866752625\n",
      "464/500 [==========================>...] - ETA: 6:45 - loss: 0.1956 - accuracy: 0.9197\n",
      " training set -> batch:965 loss:0.2013380378484726 and acc: 0.9171597361564636\n",
      "465/500 [==========================>...] - ETA: 6:34 - loss: 0.2013 - accuracy: 0.9172\n",
      " training set -> batch:966 loss:0.19804386794567108 and acc: 0.9183526039123535\n",
      "466/500 [==========================>...] - ETA: 6:22 - loss: 0.1980 - accuracy: 0.9184\n",
      " training set -> batch:967 loss:0.19696356356143951 and acc: 0.9194915294647217\n",
      "467/500 [===========================>..] - ETA: 6:11 - loss: 0.1970 - accuracy: 0.9195\n",
      " training set -> batch:968 loss:0.1961228996515274 and acc: 0.919889509677887\n",
      "468/500 [===========================>..] - ETA: 6:00 - loss: 0.1961 - accuracy: 0.9199\n",
      " training set -> batch:969 loss:0.19834952056407928 and acc: 0.9195945858955383\n",
      "469/500 [===========================>..] - ETA: 5:48 - loss: 0.1983 - accuracy: 0.9196\n",
      " training set -> batch:970 loss:0.19516387581825256 and acc: 0.920634925365448\n",
      "470/500 [===========================>..] - ETA: 5:37 - loss: 0.1952 - accuracy: 0.9206\n",
      " training set -> batch:971 loss:0.20253337919712067 and acc: 0.9203367829322815\n",
      "471/500 [===========================>..] - ETA: 5:25 - loss: 0.2025 - accuracy: 0.9203\n",
      " training set -> batch:972 loss:0.19999544322490692 and acc: 0.9213197827339172\n",
      "472/500 [===========================>..] - ETA: 5:14 - loss: 0.2000 - accuracy: 0.9213\n",
      " training set -> batch:973 loss:0.19625678658485413 and acc: 0.9228855967521667\n",
      "473/500 [===========================>..] - ETA: 5:03 - loss: 0.1963 - accuracy: 0.9229\n",
      " training set -> batch:974 loss:0.1948588788509369 and acc: 0.9237805008888245\n",
      "474/500 [===========================>..] - ETA: 4:51 - loss: 0.1949 - accuracy: 0.9238\n",
      " training set -> batch:975 loss:0.19359660148620605 and acc: 0.9246411323547363\n",
      "475/500 [===========================>..] - ETA: 4:40 - loss: 0.1936 - accuracy: 0.9246\n",
      " training set -> batch:976 loss:0.1915760338306427 and acc: 0.9254694581031799\n",
      "476/500 [===========================>..] - ETA: 4:29 - loss: 0.1916 - accuracy: 0.9255\n",
      " training set -> batch:977 loss:0.18910035490989685 and acc: 0.9262672662734985\n",
      "477/500 [===========================>..] - ETA: 4:18 - loss: 0.1891 - accuracy: 0.9263\n",
      " training set -> batch:978 loss:0.18687349557876587 and acc: 0.9270362257957458\n",
      "478/500 [===========================>..] - ETA: 4:06 - loss: 0.1869 - accuracy: 0.9270\n",
      " training set -> batch:979 loss:0.18994921445846558 and acc: 0.9266666769981384\n",
      "479/500 [===========================>..] - ETA: 3:55 - loss: 0.1899 - accuracy: 0.9267\n",
      " training set -> batch:980 loss:0.18841399252414703 and acc: 0.9274017214775085\n",
      "480/500 [===========================>..] - ETA: 3:44 - loss: 0.1884 - accuracy: 0.9274\n",
      " training set -> batch:981 loss:0.18889552354812622 and acc: 0.9281116127967834\n",
      "481/500 [===========================>..] - ETA: 3:32 - loss: 0.1889 - accuracy: 0.9281\n",
      " training set -> batch:982 loss:0.18802474439144135 and acc: 0.9282700419425964\n",
      "482/500 [===========================>..] - ETA: 3:21 - loss: 0.1880 - accuracy: 0.9283\n",
      " training set -> batch:983 loss:0.1867319494485855 and acc: 0.9289419054985046\n",
      "483/500 [===========================>..] - ETA: 3:10 - loss: 0.1867 - accuracy: 0.9289\n",
      " training set -> batch:984 loss:0.1856263428926468 and acc: 0.9295918345451355\n",
      "484/500 [============================>.] - ETA: 2:59 - loss: 0.1856 - accuracy: 0.9296\n",
      " training set -> batch:985 loss:0.1835891306400299 and acc: 0.930220901966095\n",
      "485/500 [============================>.] - ETA: 2:47 - loss: 0.1836 - accuracy: 0.9302\n",
      " training set -> batch:986 loss:0.1830993890762329 and acc: 0.9303359389305115\n",
      "486/500 [============================>.] - ETA: 2:36 - loss: 0.1831 - accuracy: 0.9303\n",
      " training set -> batch:987 loss:0.1833285540342331 and acc: 0.9304474592208862\n",
      "487/500 [============================>.] - ETA: 2:25 - loss: 0.1833 - accuracy: 0.9304\n",
      " training set -> batch:988 loss:0.18226505815982819 and acc: 0.9305555820465088\n",
      "488/500 [============================>.] - ETA: 2:14 - loss: 0.1823 - accuracy: 0.9306\n",
      " training set -> batch:989 loss:0.1825818121433258 and acc: 0.9306603670120239\n",
      "489/500 [============================>.] - ETA: 2:02 - loss: 0.1826 - accuracy: 0.9307\n",
      " training set -> batch:990 loss:0.1880238801240921 and acc: 0.9293680191040039\n",
      "490/500 [============================>.] - ETA: 1:51 - loss: 0.1880 - accuracy: 0.9294\n",
      " training set -> batch:991 loss:0.19177232682704926 and acc: 0.9285714030265808\n",
      "491/500 [============================>.] - ETA: 1:40 - loss: 0.1918 - accuracy: 0.9286\n",
      " training set -> batch:992 loss:0.19247552752494812 and acc: 0.9282491207122803\n",
      "492/500 [============================>.] - ETA: 1:29 - loss: 0.1925 - accuracy: 0.9282\n",
      " training set -> batch:993 loss:0.1916491538286209 and acc: 0.9279359579086304\n",
      "493/500 [============================>.] - ETA: 1:18 - loss: 0.1916 - accuracy: 0.9279\n",
      " training set -> batch:994 loss:0.19114674627780914 and acc: 0.9276315569877625\n",
      "494/500 [============================>.] - ETA: 1:06 - loss: 0.1911 - accuracy: 0.9276\n",
      " training set -> batch:995 loss:0.19292831420898438 and acc: 0.9269031286239624\n",
      "495/500 [============================>.] - ETA: 55s - loss: 0.1929 - accuracy: 0.9269 \n",
      " training set -> batch:996 loss:0.19265976548194885 and acc: 0.9270477890968323\n",
      "496/500 [============================>.] - ETA: 44s - loss: 0.1927 - accuracy: 0.9270\n",
      " training set -> batch:997 loss:0.1928708702325821 and acc: 0.9267676472663879\n",
      "497/500 [============================>.] - ETA: 33s - loss: 0.1929 - accuracy: 0.9268\n",
      " training set -> batch:998 loss:0.19523020088672638 and acc: 0.9256644248962402\n",
      "498/500 [============================>.] - ETA: 22s - loss: 0.1952 - accuracy: 0.9257\n",
      " training set -> batch:999 loss:0.19382193684577942 and acc: 0.9262295365333557\n",
      "499/500 [============================>.] - ETA: 11s - loss: 0.1938 - accuracy: 0.9262\n",
      " training set -> batch:1000 loss:0.19455385208129883 and acc: 0.9255663156509399\n",
      "\n",
      " validation set -> batch:1000 val loss:0.2384263575077057 and val acc: 0.9002293348312378\n",
      "500/500 [==============================] - 5710s 11s/step - loss: 0.1946 - accuracy: 0.9256 - val_loss: 0.2357 - val_accuracy: 0.9167\n",
      "\n",
      "execution time: 3:10:48\n"
     ]
    }
   ],
   "source": [
    "# time the function\n",
    "start_time = time.time()\n",
    "\n",
    "# making the transformation here since insude model.fit it create a lot of warnings\n",
    "data_train = data_feature_extraction(train_dataset, model.name)\n",
    "data_val = data_feature_extraction(valid_dataset, model.name)\n",
    "histories_per_step = History_per_step(data_val, 50)\n",
    "\n",
    "# train the model\n",
    "history = model.fit(data_train, \n",
    "                    epochs=2, \n",
    "                    steps_per_epoch=500,\n",
    "                    validation_data=data_val,\n",
    "                    validation_steps=3,\n",
    "                    callbacks=[tensorboard_callback,\n",
    "                               *checkpoint_callback,\n",
    "                               histories_per_step])\n",
    "\n",
    "# print execution time\n",
    "elapsed_time_secs = time.time() - start_time\n",
    "print('\\nexecution time: {}'.format(timedelta(seconds=round(elapsed_time_secs))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [15, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:\n",
      "  - loss [training dataset]: 0.195\n",
      "  - loss [validation dataset: 0.238\n",
      "\n",
      "Accuracy:\n",
      "  - accuracy [training dataset]: 92.56%\n",
      "  - accuracy [validation dataset: 90.02%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 900x300 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mm.plot_acc_loss(steps_loss_train=histories_per_step.steps, loss_train=histories_per_step.losses,\n",
    "                 steps_acc_train=histories_per_step.steps, accuracy_train=histories_per_step.accuracies,\n",
    "                 steps_loss_eval=histories_per_step.val_steps, loss_eval=histories_per_step.val_losses,\n",
    "                 steps_acc_eval=histories_per_step.val_steps, accuracy_eval=histories_per_step.val_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Get more information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tensorflow.python.keras.metrics.Mean object at 0x7f3eef1ca890>, <tensorflow.python.keras.metrics.SparseCategoricalAccuracy object at 0x7f3eecef6dd0>]\n",
      "['loss', 'accuracy']\n"
     ]
    }
   ],
   "source": [
    "print(model.metrics)\n",
    "print(model.metrics_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'verbose': 1, 'epochs': 2, 'steps': 500}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# dir(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Exploration of the model's structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model,\n",
    "                          'model.png',\n",
    "                          show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "model.inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "model.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<transformers.modeling_tf_bert.TFBertMainLayer at 0x7f3f70d6d590>,\n",
       " <tensorflow.python.keras.layers.core.Dropout at 0x7f3ebf81dd90>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7f3eef1ca110>]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert [] []\n",
      "dropout_37 [] []\n",
      "classifier [] []\n"
     ]
    }
   ],
   "source": [
    "# _inbound_nodes and inbound_nodes give the same !\n",
    "# to see method available: dir(model.layers[2])\n",
    "for layer in model.layers:\n",
    "    print(layer.name, layer._inbound_nodes, layer._outbound_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Validation of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### Making prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standard model: tf_bert_classification\n"
     ]
    }
   ],
   "source": [
    "# get probablility for each classes\n",
    "if model.name=='custom_tf_bert_classification':\n",
    "        print('custom model: {}'.format(model.name))\n",
    "        y_pred = tf.nn.softmax(model.predict(valid_dataset))\n",
    "elif model.name=='tf_bert_classification':\n",
    "        print('standard model: {}'.format(model.name))\n",
    "        y_pred = tf.squeeze(tf.nn.softmax(model.predict(valid_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([872, 2])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# get predicted classes\n",
    "y_pred_argmax = tf.math.argmax(y_pred, axis=1)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([872])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_pred_argmax).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### Extracting true classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# extracting and flatten true classes\n",
    "y_true_tf=valid_dataset.map(pp.label_extraction).flat_map(lambda x: valid_dataset.from_tensor_slices(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "y_true=list(y_true_tf.as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(872, 872)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_true), len(y_pred_argmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### Model performanes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.90      0.90       428\n",
      "    positive       0.90      0.90      0.90       444\n",
      "\n",
      "    accuracy                           0.90       872\n",
      "   macro avg       0.90      0.90      0.90       872\n",
      "weighted avg       0.90      0.90      0.90       872\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true, y_pred_argmax, target_names=info.features[\"label\"].names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance on the  dataset:\n",
      "   Metric             \n",
      "accuracy...........   0.9002\n",
      "recall.............   0.8986\n",
      "auc................   0.9003\n",
      "precision (p=0.5)..   0.9048\n",
      "precision (avg)....   0.8647\n",
      "precision (micro)..   0.9002\n",
      "precision (macro)..   0.9002\n",
      "f1.................    0.9017\n",
      "r2.................    0.6008\n"
     ]
    }
   ],
   "source": [
    "mm.print_metrics(y_true, y_pred_argmax, mode='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [10, 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mm.plot_confusion_matrix(confusion_matrix(y_true, y_pred_argmax), info.features[\"label\"].names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### ROC curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mm.roc_curves(to_categorical(y_true), y_pred.numpy(), info.features[\"label\"].names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:env_test]",
   "language": "python",
   "name": "conda-env-env_test-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
