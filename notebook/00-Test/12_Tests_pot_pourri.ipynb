{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets\n",
    "from transformers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Load dataset, tokenizer, model from pretrained model/vocabulary\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "model = TFBertForSequenceClassification.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "data = tensorflow_datasets.load('glue/mrpc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test': <DatasetV1Adapter shapes: {idx: (), label: (), sentence1: (), sentence2: ()}, types: {idx: tf.int32, label: tf.int64, sentence1: tf.string, sentence2: tf.string}>,\n",
       " 'train': <DatasetV1Adapter shapes: {idx: (), label: (), sentence1: (), sentence2: ()}, types: {idx: tf.int32, label: tf.int64, sentence1: tf.string, sentence2: tf.string}>,\n",
       " 'validation': <DatasetV1Adapter shapes: {idx: (), label: (), sentence1: (), sentence2: ()}, types: {idx: tf.int32, label: tf.int64, sentence1: tf.string, sentence2: tf.string}>}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['test', 'train', 'validation'])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DatasetV1Adapter shapes: {idx: (), label: (), sentence1: (), sentence2: ()}, types: {idx: tf.int32, label: tf.int64, sentence1: tf.string, sentence2: tf.string}>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'idx': TensorShape([]),\n",
       " 'label': TensorShape([]),\n",
       " 'sentence1': TensorShape([]),\n",
       " 'sentence2': TensorShape([])}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.data.ops import dataset_ops\n",
    "dataset_ops.get_legacy_output_shapes(data['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'idx': tf.int32,\n",
       " 'label': tf.int64,\n",
       " 'sentence1': tf.string,\n",
       " 'sentence2': tf.string}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_ops.get_legacy_output_types(data['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'idx': tensorflow.python.framework.ops.Tensor,\n",
       " 'label': tensorflow.python.framework.ops.Tensor,\n",
       " 'sentence1': tensorflow.python.framework.ops.Tensor,\n",
       " 'sentence2': tensorflow.python.framework.ops.Tensor}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_ops.get_legacy_output_classes(data['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['idx', 'label', 'sentence1', 'sentence2'])\n",
      "{'idx': <tf.Tensor: shape=(), dtype=int32, numpy=1680>, 'label': <tf.Tensor: shape=(), dtype=int64, numpy=0>, 'sentence1': <tf.Tensor: shape=(), dtype=string, numpy=b'The identical rovers will act as robotic geologists , searching for evidence of past water .'>, 'sentence2': <tf.Tensor: shape=(), dtype=string, numpy=b'The rovers act as robotic geologists , moving on six wheels .'>}\n",
      "tf.Tensor(1680, shape=(), dtype=int32)\n",
      "tf.Tensor(0, shape=(), dtype=int64)\n",
      "tf.Tensor(b'The identical rovers will act as robotic geologists , searching for evidence of past water .', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "for l in data['train']:\n",
    "    print(l.keys())\n",
    "    print(l)\n",
    "    print(l['idx'])\n",
    "    print(l['label'])\n",
    "    print(l['sentence1'])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'idx': 1680, 'label': 0, 'sentence1': b'The identical rovers will act as robotic geologists , searching for evidence of past water .', 'sentence2': b'The rovers act as robotic geologists , moving on six wheels .'}\n"
     ]
    }
   ],
   "source": [
    "# get numpy array\n",
    "for element in data['train'].as_numpy_iterator(): \n",
    "    print(element) \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3668,)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.shape(list(data['train'].as_numpy_iterator()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3668"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(data['train'].as_numpy_iterator()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'idx': 1680,\n",
       "  'label': 0,\n",
       "  'sentence1': b'The identical rovers will act as robotic geologists , searching for evidence of past water .',\n",
       "  'sentence2': b'The rovers act as robotic geologists , moving on six wheels .'}]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data['train'].take(1).as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Prepare dataset for GLUE as a tf.data.Dataset instance\n",
    "train_dataset = glue_convert_examples_to_features(data['train'], tokenizer, max_length=128, task='mrpc')\n",
    "valid_dataset = glue_convert_examples_to_features(data['validation'], tokenizer, max_length=128, task='mrpc')\n",
    "train_dataset = train_dataset.shuffle(100).batch(32).repeat(2)\n",
    "valid_dataset = valid_dataset.batch(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask', 'token_type_ids'])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(train_dataset.take(1).as_numpy_iterator())[0][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  101,  1258, 12421, ...,     0,     0,     0],\n",
       "       [  101,  1124,  1163, ...,     0,     0,     0],\n",
       "       [  101,  1573,  5567, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [  101,  4673,  1108, ...,     0,     0,     0],\n",
       "       [  101, 10789,  2142, ...,     0,     0,     0],\n",
       "       [  101, 23306,  1163, ...,     0,     0,     0]], dtype=int32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(train_dataset.take(1).as_numpy_iterator())[0][0]['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 128)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(train_dataset.take(1).as_numpy_iterator())[0][0]['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0]], dtype=int32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(train_dataset.take(1).as_numpy_iterator())[0][0]['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 128)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(train_dataset.take(1).as_numpy_iterator())[0][0]['attention_mask'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(train_dataset.take(1).as_numpy_iterator())[0][0]['token_type_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 128)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(train_dataset.take(1).as_numpy_iterator())[0][0]['token_type_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded string: [101, 1188, 1110, 170, 3014, 7758, 1106, 1129, 22559, 2200, 102]\n"
     ]
    }
   ],
   "source": [
    "encoding = tokenizer.encode(\"This is a simple input to be tokenized\")\n",
    "\n",
    "print(\"Encoded string: {}\".format(encoding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The identical rovers will act as robotic geologists , searching for evidence of past water .'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data['train'].take(1).as_numpy_iterator())[0]['sentence1'].decode(\"utf-8\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101,\n",
       " 1109,\n",
       " 6742,\n",
       " 187,\n",
       " 24985,\n",
       " 1209,\n",
       " 2496,\n",
       " 1112,\n",
       " 24628,\n",
       " 25166,\n",
       " 1116,\n",
       " 117,\n",
       " 6205,\n",
       " 1111,\n",
       " 2554,\n",
       " 1104,\n",
       " 1763,\n",
       " 1447,\n",
       " 119,\n",
       " 102]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(list(data['train'].take(1).as_numpy_iterator())[0]['sentence1'].decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101,\n",
       " 1109,\n",
       " 187,\n",
       " 24985,\n",
       " 2496,\n",
       " 1112,\n",
       " 24628,\n",
       " 25166,\n",
       " 1116,\n",
       " 117,\n",
       " 2232,\n",
       " 1113,\n",
       " 1565,\n",
       " 8089,\n",
       " 119,\n",
       " 102]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(list(data['train'].take(1).as_numpy_iterator())[0]['sentence2'].decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Prepare training: Compile tf.keras model with optimizer, loss and learning rate schedule\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5, epsilon=1e-08, clipnorm=1.0)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=[metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_for_sequence_classification\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bert (TFBertMainLayer)       multiple                  108310272 \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "classifier (Dense)           multiple                  1538      \n",
      "=================================================================\n",
      "Total params: 108,311,810\n",
      "Trainable params: 108,311,810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Train and evaluate using tf.keras.Model.fit()\n",
    "history = model.fit(train_dataset, epochs=2, steps_per_epoch=115,\n",
    "                    validation_data=valid_dataset, validation_steps=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Load the TensorFlow model in PyTorch for inspection\n",
    "model.save_pretrained('./save/')\n",
    "pytorch_model = BertForSequenceClassification.from_pretrained('./save/', from_tf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Quickly test a few predictions - MRPC is a paraphrasing task, let's see if our model learned the task\n",
    "sentence_0 = \"This research was consistent with his findings.\"\n",
    "sentence_1 = \"His findings were compatible with this research.\"\n",
    "sentence_2 = \"His findings were not compatible with this research.\"\n",
    "inputs_1 = tokenizer.encode_plus(sentence_0, sentence_1, add_special_tokens=True, return_tensors='pt')\n",
    "inputs_2 = tokenizer.encode_plus(sentence_0, sentence_2, add_special_tokens=True, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "pred_1 = pytorch_model(inputs_1['input_ids'], token_type_ids=inputs_1['token_type_ids'])[0].argmax().item()\n",
    "pred_2 = pytorch_model(inputs_2['input_ids'], token_type_ids=inputs_2['token_type_ids'])[0].argmax().item()\n",
    "\n",
    "print(\"sentence_1 is\", \"a paraphrase\" if pred_1 else \"not a paraphrase\", \"of sentence_0\")\n",
    "print(\"sentence_2 is\", \"a paraphrase\" if pred_2 else \"not a paraphrase\", \"of sentence_0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## TF_Config env variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from tensorboard.plugins.hparams import api as hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "os.environ['TF_CONFIG']='{\"cluster\": {\"chief\": [\"127.0.0.1:2222\"]}, \"task\": {\"type\": \"chief\", \"index\": 0, \"trial\": \"2\", \"cloud\": \"cxxx-ml\"}, \"job\": {\"package_uris\": [\"gs://xxx/tf_bert_classification_2020_05_12_141041/b0d287bd012da97a62f662b2e9df291e899c2e9705ca751a5a0f7dcaf2849765/bert_model-0.1.tar.gz\"], \"python_module\": \"model.tf_bert_classification.task\", \"args\": [\"--epochs=1\", \"--steps_per_epoch_train=5\", \"--batch_size_train=32\", \"--steps_per_epoch_eval=1\", \"--batch_size_eval=64\", \"--input_eval_tfrecords=gs://multilingual_text_classification/tfrecord/sst2/bert-base-multilingual-uncased/valid\", \"--input_train_tfrecords=gs://xxx/tfrecord/sst2/bert-base-multilingual-uncased/train\", \"--output_dir=gs://xxx/training_model_gcp/tf_bert_classification_2020_05_12_141041\", \"--pretrained_model_dir=gs://xxx/pretrained_model/bert-base-multilingual-uncased\", \"--verbosity_level=INFO\", \"--epsilon\", \"1.7788921050163616e-06\", \"--learning_rate\", \"0.0007763625134788308\"], \"hyperparameters\": {\"goal\": \"MAXIMIZE\", \"params\": [{\"parameter_name\": \"learning_rate\", \"min_value\": 1e-08, \"max_value\": 1.0, \"type\": \"DOUBLE\", \"scale_type\": \"UNIT_LOG_SCALE\"}, {\"parameter_name\": \"epsilon\", \"min_value\": 1e-09, \"max_value\": 1.0, \"type\": \"DOUBLE\", \"scale_type\": \"UNIT_LOG_SCALE\"}], \"max_trials\": 3, \"max_parallel_trials\": 2, \"hyperparameter_metric_tag\": \"accuracy_train\", \"enable_trial_early_stopping\": true, \"max_failed_trials\": 1}, \"region\": \"europe-west4\", \"runtime_version\": \"2.1\", \"run_on_raw_vm\": true, \"python_version\": \"3.7\"}, \"environment\": \"cloud\"}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"cluster\": {\"chief\": [\"127.0.0.1:2222\"]}, \"task\": {\"type\": \"chief\", \"index\": 0, \"trial\": \"2\", \"cloud\": \"cxxx-ml\"}, \"job\": {\"package_uris\": [\"gs://xxx/tf_bert_classification_2020_05_12_141041/b0d287bd012da97a62f662b2e9df291e899c2e9705ca751a5a0f7dcaf2849765/bert_model-0.1.tar.gz\"], \"python_module\": \"model.tf_bert_classification.task\", \"args\": [\"--epochs=1\", \"--steps_per_epoch_train=5\", \"--batch_size_train=32\", \"--steps_per_epoch_eval=1\", \"--batch_size_eval=64\", \"--input_eval_tfrecords=gs://multilingual_text_classification/tfrecord/sst2/bert-base-multilingual-uncased/valid\", \"--input_train_tfrecords=gs://xxx/tfrecord/sst2/bert-base-multilingual-uncased/train\", \"--output_dir=gs://xxx/training_model_gcp/tf_bert_classification_2020_05_12_141041\", \"--pretrained_model_dir=gs://xxx/pretrained_model/bert-base-multilingual-uncased\", \"--verbosity_level=INFO\", \"--epsilon\", \"1.7788921050163616e-06\", \"--learning_rate\", \"0.0007763625134788308\"], \"hyperparameters\": {\"goal\": \"MAXIMIZE\", \"params\": [{\"parameter_name\": \"learning_rate\", \"min_value\": 1e-08, \"max_value\": 1.0, \"type\": \"DOUBLE\", \"scale_type\": \"UNIT_LOG_SCALE\"}, {\"parameter_name\": \"epsilon\", \"min_value\": 1e-09, \"max_value\": 1.0, \"type\": \"DOUBLE\", \"scale_type\": \"UNIT_LOG_SCALE\"}], \"max_trials\": 3, \"max_parallel_trials\": 2, \"hyperparameter_metric_tag\": \"accuracy_train\", \"enable_trial_early_stopping\": true, \"max_failed_trials\": 1}, \"region\": \"europe-west4\", \"runtime_version\": \"2.1\", \"run_on_raw_vm\": true, \"python_version\": \"3.7\"}, \"environment\": \"cloud\"}'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['TF_CONFIG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'package_uris': ['gs://xxx/tf_bert_classification_2020_05_12_141041/b0d287bd012da97a62f662b2e9df291e899c2e9705ca751a5a0f7dcaf2849765/bert_model-0.1.tar.gz'],\n",
       " 'python_module': 'model.tf_bert_classification.task',\n",
       " 'args': ['--epochs=1',\n",
       "  '--steps_per_epoch_train=5',\n",
       "  '--batch_size_train=32',\n",
       "  '--steps_per_epoch_eval=1',\n",
       "  '--batch_size_eval=64',\n",
       "  '--input_eval_tfrecords=gs://multilingual_text_classification/tfrecord/sst2/bert-base-multilingual-uncased/valid',\n",
       "  '--input_train_tfrecords=gs://xxx/tfrecord/sst2/bert-base-multilingual-uncased/train',\n",
       "  '--output_dir=gs://xxx/training_model_gcp/tf_bert_classification_2020_05_12_141041',\n",
       "  '--pretrained_model_dir=gs://xxx/pretrained_model/bert-base-multilingual-uncased',\n",
       "  '--verbosity_level=INFO',\n",
       "  '--epsilon',\n",
       "  '1.7788921050163616e-06',\n",
       "  '--learning_rate',\n",
       "  '0.0007763625134788308'],\n",
       " 'hyperparameters': {'goal': 'MAXIMIZE',\n",
       "  'params': [{'parameter_name': 'learning_rate',\n",
       "    'min_value': 1e-08,\n",
       "    'max_value': 1.0,\n",
       "    'type': 'DOUBLE',\n",
       "    'scale_type': 'UNIT_LOG_SCALE'},\n",
       "   {'parameter_name': 'epsilon',\n",
       "    'min_value': 1e-09,\n",
       "    'max_value': 1.0,\n",
       "    'type': 'DOUBLE',\n",
       "    'scale_type': 'UNIT_LOG_SCALE'}],\n",
       "  'max_trials': 3,\n",
       "  'max_parallel_trials': 2,\n",
       "  'hyperparameter_metric_tag': 'accuracy_train',\n",
       "  'enable_trial_early_stopping': True,\n",
       "  'max_failed_trials': 1},\n",
       " 'region': 'europe-west4',\n",
       " 'runtime_version': '2.1',\n",
       " 'run_on_raw_vm': True,\n",
       " 'python_version': '3.7'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(os.environ.get(\"TF_CONFIG\", \"{}\")).get(\"job\",{}) #.get(\"args\",{})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "params=json.loads(os.environ.get(\"TF_CONFIG\", \"{}\")).get(\"job\",{}).get(\"hyperparameters\",{}).get(\"params\",{})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HParam(name='learning_rate', domain=RealInterval(1e-08, 1.0), display_name=None, description=None), HParam(name='epsilon', domain=RealInterval(1e-09, 1.0), display_name=None, description=None)]\n"
     ]
    }
   ],
   "source": [
    "list_hp=[]\n",
    "for el in params:\n",
    "    hp_dict=dict(el)\n",
    "    if hp_dict.get('type')=='DOUBLE':\n",
    "        list_hp.append(hp.HParam(hp_dict.get('parameter_name'), hp.RealInterval(hp_dict.get('min_value'), hp_dict.get('max_value'))))\n",
    "\n",
    "print(list_hp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from absl import flags\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "FLAGS = flags.FLAGS\n",
    "\n",
    "def del_all_flags(FLAGS):\n",
    "    flags_dict = FLAGS._flags()    \n",
    "    keys_list = [keys for keys in flags_dict]    \n",
    "    for keys in keys_list:\n",
    "        FLAGS.__delattr__(keys)\n",
    "    \n",
    "del_all_flags(flags.FLAGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "flags.DEFINE_string('f', '', 'kernel') # just for jupyter notebook and avoir : \"UnrecognizedFlagError: Unknown command line flag 'f'\"\n",
    "flags.DEFINE_float('float', 3.14, 'using floats')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "FLAGS(sys.argv);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key doesn t exist\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    FLAGS['float2'].value\n",
    "except KeyError:\n",
    "    print('key doesn t exist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## TF.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==2.1.0\n",
      "  Using cached tensorflow-2.1.0-cp37-cp37m-macosx_10_11_x86_64.whl (120.8 MB)\n",
      "Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n",
      "  Using cached tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448 kB)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /Users/tarrade/anaconda-release/conda-env/env_test/lib/python3.7/site-packages (from tensorflow==2.1.0) (3.11.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/tarrade/anaconda-release/conda-env/env_test/lib/python3.7/site-packages (from tensorflow==2.1.0) (1.1.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /Users/tarrade/anaconda-release/conda-env/env_test/lib/python3.7/site-packages (from tensorflow==2.1.0) (1.24.3)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /Users/tarrade/anaconda-release/conda-env/env_test/lib/python3.7/site-packages (from tensorflow==2.1.0) (0.9.0)\n",
      "Processing /Users/tarrade/Library/Caches/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd/gast-0.2.2-cp37-none-any.whl\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/tarrade/anaconda-release/conda-env/env_test/lib/python3.7/site-packages (from tensorflow==2.1.0) (3.2.0)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /Users/tarrade/anaconda-release/conda-env/env_test/lib/python3.7/site-packages (from tensorflow==2.1.0) (0.34.2)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.0 in /Users/tarrade/anaconda-release/conda-env/env_test/lib/python3.7/site-packages (from tensorflow==2.1.0) (1.1.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /Users/tarrade/anaconda-release/conda-env/env_test/lib/python3.7/site-packages (from tensorflow==2.1.0) (0.2.0)\n",
      "Collecting astor>=0.6.0\n",
      "  Using cached astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
      "Collecting keras-applications>=1.0.8\n",
      "  Using cached Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /Users/tarrade/anaconda-release/conda-env/env_test/lib/python3.7/site-packages (from tensorflow==2.1.0) (1.12.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/tarrade/anaconda-release/conda-env/env_test/lib/python3.7/site-packages (from tensorflow==2.1.0) (1.14.0)\n",
      "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /Users/tarrade/anaconda-release/conda-env/env_test/lib/python3.7/site-packages (from tensorflow==2.1.0) (1.4.1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /Users/tarrade/anaconda-release/conda-env/env_test/lib/python3.7/site-packages (from tensorflow==2.1.0) (1.18.1)\n",
      "Collecting tensorboard<2.2.0,>=2.1.0\n",
      "  Using cached tensorboard-2.1.1-py3-none-any.whl (3.8 MB)\n",
      "Requirement already satisfied: setuptools in /Users/tarrade/anaconda-release/conda-env/env_test/lib/python3.7/site-packages (from protobuf>=3.8.0->tensorflow==2.1.0) (46.1.3.post20200330)\n",
      "Requirement already satisfied: h5py in /Users/tarrade/anaconda-release/conda-env/env_test/lib/python3.7/site-packages (from keras-applications>=1.0.8->tensorflow==2.1.0) (2.10.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/tarrade/anaconda-release/conda-env/env_test/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2.23.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /Users/tarrade/anaconda-release/conda-env/env_test/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.0.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Users/tarrade/anaconda-release/conda-env/env_test/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.4.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /Users/tarrade/anaconda-release/conda-env/env_test/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.11.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/tarrade/anaconda-release/conda-env/env_test/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/tarrade/anaconda-release/conda-env/env_test/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2020.4.5.1)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/tarrade/anaconda-release/conda-env/env_test/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.25.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/tarrade/anaconda-release/conda-env/env_test/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/tarrade/anaconda-release/conda-env/env_test/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/tarrade/anaconda-release/conda-env/env_test/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.3.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/tarrade/anaconda-release/conda-env/env_test/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.2.7)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /Users/tarrade/anaconda-release/conda-env/env_test/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.1.1)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in /Users/tarrade/anaconda-release/conda-env/env_test/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (4.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/tarrade/anaconda-release/conda-env/env_test/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.1.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/tarrade/anaconda-release/conda-env/env_test/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.4.8)\n",
      "\u001b[31mERROR: bert-model 0.1 requires cloud-tpu-client==0.8, which is not installed.\u001b[0m\n",
      "\u001b[31mERROR: bert-model 0.1 requires google-cloud-logging==1.15.0, which is not installed.\u001b[0m\n",
      "\u001b[31mERROR: bert-model 0.1 has requirement google-cloud-bigquery==1.24.0, but you'll have google-cloud-bigquery 1.17.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: bert-model 0.1 has requirement pip==20.1, but you'll have pip 20.0.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: bert-model 0.1 has requirement tensorboard==2.2.1, but you'll have tensorboard 2.1.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: bert-model 0.1 has requirement tensorflow==2.2.0, but you'll have tensorflow 2.1.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: bert-model 0.1 has requirement transformers==2.9.0, but you'll have transformers 2.8.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tfx 0.21.2 has requirement absl-py<0.9,>=0.1.6, but you'll have absl-py 0.9.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tfx 0.21.2 has requirement apache-beam[gcp]<2.18,>=2.17, but you'll have apache-beam 2.18.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tfx 0.21.2 has requirement grpcio!=1.27.2,<2,>=1.25, but you'll have grpcio 1.24.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tfx-bsl 0.21.4 has requirement absl-py<0.9,>=0.7, but you'll have absl-py 0.9.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tensorflow-transform 0.21.2 has requirement absl-py<0.9,>=0.7, but you'll have absl-py 0.9.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tensorflow-model-analysis 0.21.6 has requirement absl-py<0.9,>=0.7, but you'll have absl-py 0.9.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tensorflow-data-validation 0.21.5 has requirement absl-py<0.9,>=0.7, but you'll have absl-py 0.9.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tensorflow-data-validation 0.21.5 has requirement pandas<1,>=0.24, but you'll have pandas 1.0.1 which is incompatible.\u001b[0m\n",
      "Installing collected packages: tensorflow-estimator, gast, astor, keras-applications, tensorboard, tensorflow\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.2.0\n",
      "    Uninstalling tensorflow-estimator-2.2.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.2.0\n",
      "  Attempting uninstall: gast\n",
      "    Found existing installation: gast 0.3.3\n",
      "    Uninstalling gast-0.3.3:\n",
      "      Successfully uninstalled gast-0.3.3\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.2.0\n",
      "    Uninstalling tensorboard-2.2.0:\n",
      "      Successfully uninstalled tensorboard-2.2.0\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.2.0rc4\n",
      "    Uninstalling tensorflow-2.2.0rc4:\n",
      "      Successfully uninstalled tensorflow-2.2.0rc4\n",
      "Successfully installed astor-0.8.1 gast-0.2.2 keras-applications-1.0.8 tensorboard-2.1.1 tensorflow-2.1.0 tensorflow-estimator-2.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "a = tf.constant([2, 2], name=\"vector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "b = tf.constant(2.0, name=\"scalar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([2, 2], dtype=int32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=2.0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    writer = tf.summary.create_file_writer(\"mylogs\")\n",
    "    with writer.as_default():\n",
    "        tf.summary.scalar('metric_accuracy', data=1.0, step=1)\n",
    "        tf.summary.scalar('metric_accuracy_2', data=3.0, step=1)\n",
    "        tf.summary.scalar('test', data=b, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from tensorboard.backend.event_processing import event_accumulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorboard.backend.event_processing.event_accumulator.EventAccumulator at 0x635e1a290>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_acc = event_accumulator.EventAccumulator(\"mylogs\")\n",
    "event_acc.Reload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'images': [],\n",
       " 'audio': [],\n",
       " 'histograms': [],\n",
       " 'scalars': [],\n",
       " 'distributions': [],\n",
       " 'tensors': ['metric_accuracy', 'metric_accuracy_2', 'test'],\n",
       " 'graph': False,\n",
       " 'meta_graph': False,\n",
       " 'run_metadata': []}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_acc.Tags()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: metric_accuracy value: 1.0 step: 1\n",
      "name: metric_accuracy_2 value: 3.0 step: 1\n",
      "name: test value: 2.0 step: 1\n"
     ]
    }
   ],
   "source": [
    "for tag in sorted(event_acc.Tags()['tensors']):\n",
    "    for scalar_event in event_acc.Tensors(tag):\n",
    "        print('name: {} value: {} step: {}'.format(tag, tf.make_ndarray(scalar_event.tensor_proto), scalar_event.step))\n",
    "        #print(scalar_event.step)\n",
    "        #print(tf.make_ndarray(scalar_event.tensor_proto))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'images': [], 'audio': [], 'histograms': [], 'scalars': ['epoch_loss', 'epoch_accuracy'], 'distributions': [], 'tensors': ['testtesttest_1'], 'graph': False, 'meta_graph': False, 'run_metadata': []}\n"
     ]
    }
   ],
   "source": [
    "from tensorboard.backend.event_processing import event_accumulator\n",
    "event_acc = event_accumulator.EventAccumulator('gs://'+os.environ['BUCKET_NAME']+'/training_model_gcp/tf_bert_classification_hp_tuning_cpu_2020_06_10_095311/tensorboard/trial_id_1/validation')\n",
    "event_acc.Reload()\n",
    "print(event_acc.Tags())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'images': [], 'audio': [], 'histograms': [], 'scalars': ['epoch_loss', 'epoch_accuracy'], 'distributions': [], 'tensors': ['testtesttest_1'], 'graph': False, 'meta_graph': False, 'run_metadata': []}\n"
     ]
    }
   ],
   "source": [
    "from tensorboard.backend.event_processing import event_accumulator\n",
    "event_acc = event_accumulator.EventAccumulator('gs://'+os.environ['BUCKET_NAME']+'/training_model_gcp/tf_bert_classification_hp_tuning_cpu_2020_06_10_095311/tensorboard/trial_id_1/validation')\n",
    "event_acc.Reload()\n",
    "print(event_acc.Tags())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'images': [], 'audio': [], 'histograms': [], 'scalars': ['epoch_accuracy', 'epoch_loss'], 'distributions': [], 'tensors': ['metric_accuracy_train_epoch', 'testtesttest_1'], 'graph': False, 'meta_graph': False, 'run_metadata': []}\n"
     ]
    }
   ],
   "source": [
    "from tensorboard.backend.event_processing import event_accumulator\n",
    "event_acc = event_accumulator.EventAccumulator('gs://'+os.environ['BUCKET_NAME']+'/training_model_gcp/tf_bert_classification_hp_tuning_cpu_2020_06_10_134028/tensorboard/trial_id_1/validation')\n",
    "event_acc.Reload()\n",
    "print(event_acc.Tags())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'images': [], 'audio': [], 'histograms': [], 'scalars': [], 'distributions': [], 'tensors': [], 'graph': False, 'meta_graph': False, 'run_metadata': []}\n"
     ]
    }
   ],
   "source": [
    "from tensorboard.backend.event_processing import event_accumulator\n",
    "event_acc = event_accumulator.EventAccumulator('gs://'+os.environ['BUCKET_NAME']+'/training_model_gcp/tf_bert_classification_hp_tuning_cpu_2020_06_10_134028/tensorboard/trial_id_1/train')\n",
    "print(event_acc.Tags())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "2020_06_10_113245"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'images': [], 'audio': [], 'histograms': ['dense/kernel_0', 'dense/bias_0', 'dense_1/kernel_0', 'dense_1/bias_0', 'dense_2/kernel_0', 'dense_2/bias_0', 'dense_3/kernel_0', 'dense_3/bias_0', 'dense_4/kernel_0', 'dense_4/bias_0'], 'scalars': ['batch_accuracy', 'batch_loss', 'epoch_accuracy', 'epoch_loss', 'epoch_lr'], 'distributions': ['dense/kernel_0', 'dense/bias_0', 'dense_1/kernel_0', 'dense_1/bias_0', 'dense_2/kernel_0', 'dense_2/bias_0', 'dense_3/kernel_0', 'dense_3/bias_0', 'dense_4/kernel_0', 'dense_4/bias_0'], 'tensors': ['keras', 'batch_20'], 'graph': True, 'meta_graph': False, 'run_metadata': []}\n"
     ]
    }
   ],
   "source": [
    "from tensorboard.backend.event_processing import event_accumulator\n",
    "event_acc = event_accumulator.EventAccumulator('gs://'+os.environ['BUCKET_NAME']+'/census_20200713_170403/keras-job-dir/2/train/')\n",
    "event_acc.Reload()\n",
    "print(event_acc.Tags())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: batch_20 value: b'' step: 20\n",
      "name: keras value: b'{\"class_name\": \"Sequential\", \"config\": {\"name\": \"sequential\", \"layers\": [{\"class_name\": \"Dense\", \"config\": {\"name\": \"dense\", \"trainable\": true, \"batch_input_shape\": [null, 11], \"dtype\": \"float32\", \"units\": 100, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"RandomUniform\", \"config\": {\"minval\": -0.05, \"maxval\": 0.05, \"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_1\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 75, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_2\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 50, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_3\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 25, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_4\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 1, \"activation\": \"sigmoid\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}], \"build_input_shape\": [null, 11]}, \"keras_version\": \"2.3.0-tf\", \"backend\": \"tensorflow\"}' step: 0\n"
     ]
    }
   ],
   "source": [
    "for tag in sorted(event_acc.Tags()['tensors']):\n",
    "    for scalar_event in event_acc.Tensors(tag):\n",
    "        print('name: {} value: {} step: {}'.format(tag, tf.make_ndarray(scalar_event.tensor_proto), scalar_event.step))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_accuracy\n",
      "0 0.703125\n",
      "1 0.7109375\n",
      "2 0.5494791865348816\n",
      "3 0.48046875\n",
      "4 0.5390625\n",
      "5 0.5872395634651184\n",
      "6 0.6138392686843872\n",
      "7 0.6240234375\n",
      "8 0.6371527910232544\n",
      "9 0.6507812738418579\n",
      "10 0.6647727489471436\n",
      "11 0.6256510615348816\n",
      "12 0.6370192170143127\n",
      "13 0.6473214030265808\n",
      "14 0.6536458134651184\n",
      "15 0.6328125\n",
      "16 0.640625\n",
      "17 0.6462673544883728\n",
      "18 0.6504934430122375\n",
      "19 0.632031261920929\n",
      "20 0.6361607313156128\n",
      "21 0.6441761255264282\n",
      "22 0.647078812122345\n",
      "23 0.6510416865348816\n",
      "24 0.6365625262260437\n",
      "25 0.641526460647583\n",
      "26 0.6443865895271301\n",
      "27 0.6297432780265808\n",
      "28 0.634428858757019\n",
      "29 0.6372395753860474\n",
      "30 0.640625\n",
      "31 0.625732421875\n",
      "32 0.6271306872367859\n",
      "33 0.6282169222831726\n",
      "34 0.6334821581840515\n",
      "35 0.6375868320465088\n",
      "36 0.642525315284729\n",
      "37 0.6336348652839661\n",
      "38 0.637620210647583\n",
      "39 0.6421874761581421\n",
      "40 0.6444360017776489\n",
      "41 0.6473214030265808\n",
      "42 0.6495276093482971\n",
      "43 0.6519886255264282\n",
      "44 0.6538194417953491\n",
      "45 0.6564198136329651\n",
      "46 0.6587433218955994\n",
      "47 0.6604817509651184\n",
      "48 0.6626275777816772\n",
      "49 0.6656249761581421\n",
      "50 0.6683517098426819\n",
      "51 0.6693209409713745\n",
      "52 0.6702535152435303\n",
      "53 0.6731770634651184\n",
      "54 0.6738636493682861\n",
      "55 0.6767578125\n",
      "56 0.6787280440330505\n",
      "57 0.6808997988700867\n",
      "58 0.6828654408454895\n",
      "59 0.684374988079071\n",
      "60 0.6853227615356445\n",
      "61 0.6862398982048035\n",
      "62 0.6867559552192688\n",
      "63 0.6868896484375\n",
      "64 0.689182698726654\n",
      "65 0.6899858117103577\n",
      "66 0.6908815503120422\n",
      "67 0.6920955777168274\n",
      "68 0.6947463750839233\n",
      "69 0.696093738079071\n",
      "70 0.697513222694397\n",
      "71 0.6935763955116272\n",
      "72 0.6946703791618347\n",
      "73 0.6943623423576355\n",
      "74 0.6952083110809326\n",
      "75 0.6959292888641357\n",
      "76 0.6967329382896423\n",
      "77 0.6969150900840759\n",
      "78 0.6972903609275818\n",
      "79 0.6983398199081421\n",
      "80 0.698688268661499\n",
      "81 0.6996951103210449\n",
      "82 0.7003012299537659\n",
      "83 0.7010788917541504\n",
      "84 0.7022058963775635\n",
      "85 0.703125\n",
      "86 0.7033944129943848\n",
      "87 0.7037464380264282\n",
      "88 0.7041783928871155\n",
      "89 0.7046874761581421\n",
      "90 0.7042410969734192\n",
      "91 0.7043987512588501\n",
      "92 0.7050571441650391\n",
      "93 0.7050365805625916\n",
      "94 0.7052631378173828\n",
      "95 0.7058919072151184\n",
      "96 0.7063466310501099\n",
      "97 0.7071109414100647\n",
      "98 0.7077020406723022\n",
      "99 0.7082812786102295\n",
      "100 0.7088490128517151\n",
      "101 0.7100183963775635\n",
      "102 0.7105582356452942\n",
      "103 0.7111628651618958\n",
      "104 0.7118303775787354\n",
      "105 0.7125589847564697\n",
      "106 0.7129818797111511\n",
      "107 0.7139033675193787\n",
      "108 0.7142345309257507\n",
      "109 0.714062511920929\n",
      "110 0.7141751050949097\n",
      "111 0.7141461968421936\n",
      "112 0.714463472366333\n",
      "113 0.7150493264198303\n",
      "114 0.715692937374115\n",
      "115 0.7159213423728943\n",
      "116 0.7168135643005371\n",
      "117 0.7172272205352783\n",
      "118 0.7176995873451233\n",
      "119 0.7182291746139526\n",
      "120 0.7184271812438965\n",
      "121 0.7193263173103333\n",
      "122 0.7189405560493469\n",
      "123 0.7196320295333862\n",
      "124 0.7200000286102295\n",
      "125 0.7206721305847168\n",
      "126 0.7212106585502625\n",
      "127 0.72125244140625\n",
      "128 0.7218992114067078\n",
      "129 0.7220553159713745\n",
      "130 0.7228053212165833\n",
      "131 0.7231889367103577\n",
      "132 0.7232730388641357\n",
      "133 0.7233558893203735\n",
      "134 0.7235532402992249\n",
      "135 0.7234604954719543\n",
      "136 0.7236542105674744\n",
      "137 0.724014937877655\n",
      "138 0.7247639298439026\n",
      "139 0.7252232432365417\n",
      "140 0.7247340679168701\n",
      "141 0.7255721688270569\n",
      "142 0.7257976531982422\n",
      "143 0.7253146767616272\n",
      "144 0.7255926728248596\n",
      "145 0.7259203791618347\n",
      "146 0.7258184552192688\n",
      "147 0.7259818315505981\n",
      "148 0.725933313369751\n",
      "149 0.7261458039283752\n",
      "150 0.7260968685150146\n",
      "151 0.7263569235801697\n",
      "152 0.7268688678741455\n",
      "153 0.7273741960525513\n",
      "154 0.7277217507362366\n",
      "155 0.7280648946762085\n",
      "156 0.7284036874771118\n",
      "157 0.7289358973503113\n",
      "158 0.7289701104164124\n",
      "159 0.7293456792831421\n",
      "160 0.729619562625885\n",
      "161 0.7296006679534912\n",
      "162 0.7298696041107178\n",
      "163 0.7298494577407837\n",
      "164 0.7299715876579285\n",
      "165 0.7299039959907532\n",
      "166 0.730305016040802\n",
      "167 0.7301897406578064\n",
      "168 0.7299833297729492\n",
      "169 0.7299172878265381\n",
      "170 0.730217456817627\n",
      "171 0.7302870750427246\n",
      "172 0.7307623028755188\n",
      "173 0.7309626340866089\n",
      "174 0.7307589054107666\n",
      "175 0.7310901880264282\n",
      "176 0.7311087846755981\n",
      "177 0.7313026785850525\n",
      "178 0.7317126393318176\n",
      "179 0.7318576574325562\n",
      "180 0.7318715453147888\n",
      "181 0.7318853139877319\n",
      "182 0.7318989038467407\n",
      "183 0.732039749622345\n",
      "184 0.7319256663322449\n",
      "185 0.7322748899459839\n",
      "186 0.732536792755127\n",
      "187 0.7322556376457214\n",
      "188 0.7328042387962341\n",
      "189 0.7328535914421082\n",
      "190 0.7324934601783752\n",
      "191 0.7327067255973816\n",
      "192 0.7325938940048218\n",
      "193 0.7325628399848938\n",
      "194 0.7329326868057251\n",
      "195 0.733378529548645\n",
      "196 0.7335025668144226\n",
      "197 0.7335069179534912\n",
      "198 0.7335898280143738\n",
      "199 0.7334765791893005\n",
      "200 0.7337530851364136\n",
      "201 0.7341429591178894\n",
      "202 0.734182596206665\n",
      "203 0.7347579598426819\n",
      "204 0.7347179651260376\n",
      "205 0.7347162961959839\n",
      "206 0.7347901463508606\n",
      "207 0.7351637482643127\n",
      "208 0.7352721095085144\n",
      "209 0.7354166507720947\n",
      "210 0.735633909702301\n",
      "211 0.7358490824699402\n",
      "212 0.7359521985054016\n",
      "213 0.7363098859786987\n",
      "214 0.7365552186965942\n",
      "215 0.7362919449806213\n",
      "216 0.7363551259040833\n",
      "217 0.7362743616104126\n",
      "218 0.7365867495536804\n",
      "219 0.7366477251052856\n",
      "220 0.7369909286499023\n",
      "221 0.7370847463607788\n",
      "222 0.7369675040245056\n",
      "223 0.73681640625\n",
      "224 0.7370138764381409\n",
      "225 0.737244188785553\n",
      "226 0.7372315526008606\n",
      "227 0.7373560667037964\n",
      "228 0.7374795079231262\n",
      "229 0.7373641133308411\n",
      "230 0.737182080745697\n",
      "231 0.7373720407485962\n",
      "232 0.7375268340110779\n",
      "233 0.7374799847602844\n",
      "234 0.737500011920929\n",
      "235 0.737619161605835\n",
      "236 0.7378692030906677\n",
      "237 0.7381170988082886\n",
      "238 0.7382649183273315\n",
      "239 0.738574206829071\n",
      "240 0.7386540174484253\n",
      "241 0.73857182264328\n",
      "242 0.7384259104728699\n",
      "243 0.7386014461517334\n",
      "244 0.7387754917144775\n",
      "245 0.7387893795967102\n",
      "246 0.7387399077415466\n",
      "247 0.7389112710952759\n",
      "248 0.7388930916786194\n",
      "249 0.738937497138977\n",
      "250 0.7393239736557007\n",
      "251 0.739180326461792\n",
      "252 0.7391921877861023\n",
      "253 0.739265501499176\n",
      "batch_loss\n",
      "0 0.679649829864502\n",
      "1 3386.113037109375\n",
      "2 2952.514892578125\n",
      "3 2334.933837890625\n",
      "4 1891.7701416015625\n",
      "5 1580.21533203125\n",
      "6 1359.6402587890625\n",
      "7 1190.3563232421875\n",
      "8 1059.7958984375\n",
      "9 954.3115234375\n",
      "10 867.9946899414062\n",
      "11 796.5632934570312\n",
      "12 735.6235961914062\n",
      "13 683.1724243164062\n",
      "14 637.6707763671875\n",
      "15 597.8877563476562\n",
      "16 563.0602416992188\n",
      "17 531.8258056640625\n",
      "18 503.873779296875\n",
      "19 478.7449645996094\n",
      "20 456.10076904296875\n",
      "21 435.39532470703125\n",
      "22 416.494384765625\n",
      "23 399.1849670410156\n",
      "24 383.266357421875\n",
      "25 368.61676025390625\n",
      "26 354.9990234375\n",
      "27 342.47991943359375\n",
      "28 330.7239074707031\n",
      "29 319.7279357910156\n",
      "30 309.4340515136719\n",
      "31 299.78741455078125\n",
      "32 290.736328125\n",
      "33 282.2051086425781\n",
      "34 274.1585693359375\n",
      "35 266.5588073730469\n",
      "36 259.4578857421875\n",
      "37 252.6536865234375\n",
      "38 246.18569946289062\n",
      "39 240.0456085205078\n",
      "40 234.20486450195312\n",
      "41 228.6415557861328\n",
      "42 223.33761596679688\n",
      "43 218.2739715576172\n",
      "44 213.4362030029297\n",
      "45 208.8076629638672\n",
      "46 204.37657165527344\n",
      "47 200.1302490234375\n",
      "48 196.05670166015625\n",
      "49 192.14630126953125\n",
      "50 188.38845825195312\n",
      "51 184.77719116210938\n",
      "52 181.3017578125\n",
      "53 177.95355224609375\n",
      "54 174.7284698486328\n",
      "55 171.6170654296875\n",
      "56 168.61468505859375\n",
      "57 165.71522521972656\n",
      "58 162.91502380371094\n",
      "59 160.20904541015625\n",
      "60 157.5924835205078\n",
      "61 155.06008911132812\n",
      "62 152.60845947265625\n",
      "63 150.2338104248047\n",
      "64 147.9294891357422\n",
      "65 145.69677734375\n",
      "66 143.53021240234375\n",
      "67 141.4273681640625\n",
      "68 139.3834228515625\n",
      "69 137.3992919921875\n",
      "70 135.47010803222656\n",
      "71 133.6032257080078\n",
      "72 131.7810516357422\n",
      "73 130.21836853027344\n",
      "74 128.50250244140625\n",
      "75 126.81910705566406\n",
      "76 125.17930603027344\n",
      "77 123.58228302001953\n",
      "78 122.0254135131836\n",
      "79 120.5066909790039\n",
      "80 119.02623748779297\n",
      "81 117.58112335205078\n",
      "82 116.1712646484375\n",
      "83 114.79476165771484\n",
      "84 113.4502182006836\n",
      "85 112.13713836669922\n",
      "86 110.85501098632812\n",
      "87 109.60189819335938\n",
      "88 108.3768310546875\n",
      "89 107.17889404296875\n",
      "90 106.00833129882812\n",
      "91 104.86251831054688\n",
      "92 103.7408676147461\n",
      "93 102.64374542236328\n",
      "94 101.5694580078125\n",
      "95 100.51715850830078\n",
      "96 99.48670196533203\n",
      "97 98.4769287109375\n",
      "98 97.48771667480469\n",
      "99 96.5182876586914\n",
      "100 95.56806182861328\n",
      "101 94.6357421875\n",
      "102 93.72225189208984\n",
      "103 92.82621765136719\n",
      "104 91.9471664428711\n",
      "105 91.08460235595703\n",
      "106 90.23853302001953\n",
      "107 89.40750885009766\n",
      "108 88.59246063232422\n",
      "109 87.79280090332031\n",
      "110 87.00716400146484\n",
      "111 86.2356948852539\n",
      "112 85.4775390625\n",
      "113 84.73239135742188\n",
      "114 84.00008392333984\n",
      "115 83.28089904785156\n",
      "116 82.5732192993164\n",
      "117 81.87806701660156\n",
      "118 81.19451904296875\n",
      "119 80.52227020263672\n",
      "120 79.8615493774414\n",
      "121 79.21082305908203\n",
      "122 78.57230377197266\n",
      "123 77.94271850585938\n",
      "124 77.32353973388672\n",
      "125 76.71381378173828\n",
      "126 76.11383056640625\n",
      "127 75.52384948730469\n",
      "128 74.94226837158203\n",
      "129 74.37020874023438\n",
      "130 73.80615997314453\n",
      "131 73.25109100341797\n",
      "132 72.70472717285156\n",
      "133 72.1664810180664\n",
      "134 71.6360855102539\n",
      "135 71.1137924194336\n",
      "136 70.59882354736328\n",
      "137 70.09114074707031\n",
      "138 69.59028625488281\n",
      "139 69.09689331054688\n",
      "140 68.61175537109375\n",
      "141 68.1318588256836\n",
      "142 67.65928649902344\n",
      "143 67.19412231445312\n",
      "144 66.7344970703125\n",
      "145 66.28109741210938\n",
      "146 65.8343276977539\n",
      "147 65.39330291748047\n",
      "148 64.95841979980469\n",
      "149 64.52906799316406\n",
      "150 64.10566711425781\n",
      "151 63.68752670288086\n",
      "152 63.27455520629883\n",
      "153 62.86690902709961\n",
      "154 62.46470642089844\n",
      "155 62.067657470703125\n",
      "156 61.6756706237793\n",
      "157 61.288387298583984\n",
      "158 60.90664291381836\n",
      "159 60.529205322265625\n",
      "160 60.15657043457031\n",
      "161 59.78889465332031\n",
      "162 59.425384521484375\n",
      "163 59.06663131713867\n",
      "164 58.71206283569336\n",
      "165 58.36196517944336\n",
      "166 58.01559066772461\n",
      "167 57.673885345458984\n",
      "168 57.33628463745117\n",
      "169 57.002506256103516\n",
      "170 56.67229080200195\n",
      "171 56.34612274169922\n",
      "172 56.023284912109375\n",
      "173 55.704444885253906\n",
      "174 55.38973617553711\n",
      "175 55.077999114990234\n",
      "176 54.77009963989258\n",
      "177 54.46546936035156\n",
      "178 54.16399002075195\n",
      "179 53.86616134643555\n",
      "180 53.571773529052734\n",
      "181 53.28060531616211\n",
      "182 52.992618560791016\n",
      "183 52.7076301574707\n",
      "184 52.42599868774414\n",
      "185 52.14692687988281\n",
      "186 51.870880126953125\n",
      "187 51.59843063354492\n",
      "188 51.32795333862305\n",
      "189 51.06081771850586\n",
      "190 50.79694747924805\n",
      "191 50.53519821166992\n",
      "192 50.276485443115234\n",
      "193 50.02035140991211\n",
      "194 49.76644515991211\n",
      "195 49.51499557495117\n",
      "196 49.2664680480957\n",
      "197 49.020591735839844\n",
      "198 48.77708435058594\n",
      "199 48.536231994628906\n",
      "200 48.29735565185547\n",
      "201 48.060691833496094\n",
      "202 47.82676696777344\n",
      "203 47.59449768066406\n",
      "204 47.36525344848633\n",
      "205 47.13815689086914\n",
      "206 46.913150787353516\n",
      "207 46.68997573852539\n",
      "208 46.46923065185547\n",
      "209 46.250545501708984\n",
      "210 46.033836364746094\n",
      "211 45.819175720214844\n",
      "212 45.606666564941406\n",
      "213 45.39583206176758\n",
      "214 45.18708801269531\n",
      "215 44.98094940185547\n",
      "216 44.7762565612793\n",
      "217 44.5735969543457\n",
      "218 44.372379302978516\n",
      "219 44.173240661621094\n",
      "220 43.9755859375\n",
      "221 43.77999496459961\n",
      "222 43.5864143371582\n",
      "223 43.394569396972656\n",
      "224 43.20407485961914\n",
      "225 43.01520538330078\n",
      "226 42.82827377319336\n",
      "227 42.642822265625\n",
      "228 42.458988189697266\n",
      "229 42.27703094482422\n",
      "230 42.0966911315918\n",
      "231 41.91755294799805\n",
      "232 41.739952087402344\n",
      "233 41.5640983581543\n",
      "234 41.38965606689453\n",
      "235 41.216590881347656\n",
      "236 41.044830322265625\n",
      "237 40.8745002746582\n",
      "238 40.70571517944336\n",
      "239 40.53813552856445\n",
      "240 40.37224197387695\n",
      "241 40.207908630371094\n",
      "242 40.04496765136719\n",
      "243 39.88303756713867\n",
      "244 39.7224006652832\n",
      "245 39.563255310058594\n",
      "246 39.40546417236328\n",
      "247 39.24870681762695\n",
      "248 39.09341812133789\n",
      "249 38.939292907714844\n",
      "250 38.7860221862793\n",
      "251 38.63460159301758\n",
      "252 38.484153747558594\n",
      "253 38.33482360839844\n",
      "epoch_accuracy\n",
      "0 0.739265501499176\n",
      "epoch_loss\n",
      "0 38.33482360839844\n",
      "epoch_lr\n",
      "0 0.10762669891119003\n"
     ]
    }
   ],
   "source": [
    "for tag in sorted(event_acc.Tags()['scalars']):\n",
    "    print(tag)\n",
    "    for scalar_event in event_acc.Scalars(tag):\n",
    "        print(scalar_event.step, scalar_event.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'images': [], 'audio': [], 'histograms': [], 'scalars': ['epoch_accuracy', 'epoch_loss'], 'distributions': [], 'tensors': ['epoch_accuracy'], 'graph': False, 'meta_graph': False, 'run_metadata': []}\n"
     ]
    }
   ],
   "source": [
    "from tensorboard.backend.event_processing import event_accumulator\n",
    "event_acc = event_accumulator.EventAccumulator('gs://'+os.environ['BUCKET_NAME']+'/census_20200713_183548/keras-job-dir/1/validation/')\n",
    "event_acc.Reload()\n",
    "print(event_acc.Tags())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: epoch_accuracy value: 0.7518762350082397 step: 0\n"
     ]
    }
   ],
   "source": [
    "for tag in sorted(event_acc.Tags()['tensors']):\n",
    "    for scalar_event in event_acc.Tensors(tag):\n",
    "        print('name: {} value: {} step: {}'.format(tag, tf.make_ndarray(scalar_event.tensor_proto), scalar_event.step))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_accuracy\n",
      "0 0.7637916207313538\n",
      "epoch_loss\n",
      "0 0.5468340516090393\n"
     ]
    }
   ],
   "source": [
    "for tag in sorted(event_acc.Tags()['scalars']):\n",
    "    print(tag)\n",
    "    for scalar_event in event_acc.Scalars(tag):\n",
    "        print(scalar_event.step, scalar_event.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'images': [], 'audio': [], 'histograms': [], 'scalars': ['epoch_loss', 'epoch_accuracy'], 'distributions': [], 'tensors': ['epoch_accuracy'], 'graph': False, 'meta_graph': False, 'run_metadata': []}\n"
     ]
    }
   ],
   "source": [
    "from tensorboard.backend.event_processing import event_accumulator\n",
    "event_acc = event_accumulator.EventAccumulator('gs://'+os.environ['BUCKET_NAME']+'/census_20200713_185846/keras-job-dir/1/validation/')\n",
    "event_acc.Reload()\n",
    "print(event_acc.Tags())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: epoch_accuracy value: 0.777651309967041 step: 0\n",
      "name: epoch_accuracy value: 0.8282172679901123 step: 1\n"
     ]
    }
   ],
   "source": [
    "for tag in sorted(event_acc.Tags()['tensors']):\n",
    "    for scalar_event in event_acc.Tensors(tag):\n",
    "        print('name: {} value: {} step: {}'.format(tag, tf.make_ndarray(scalar_event.tensor_proto), scalar_event.step))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_accuracy\n",
      "0 0.7719007134437561\n",
      "1 0.8222754597663879\n",
      "epoch_loss\n",
      "0 0.4879953861236572\n",
      "1 0.34947270154953003\n"
     ]
    }
   ],
   "source": [
    "for tag in sorted(event_acc.Tags()['scalars']):\n",
    "    print(tag)\n",
    "    for scalar_event in event_acc.Scalars(tag):\n",
    "        print(scalar_event.step, scalar_event.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:env_multilingual_class]",
   "language": "python",
   "name": "conda-env-env_multilingual_class-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
