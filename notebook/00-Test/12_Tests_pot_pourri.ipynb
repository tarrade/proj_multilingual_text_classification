{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets\n",
    "from transformers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Load dataset, tokenizer, model from pretrained model/vocabulary\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "model = TFBertForSequenceClassification.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "data = tensorflow_datasets.load('glue/mrpc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test': <DatasetV1Adapter shapes: {idx: (), label: (), sentence1: (), sentence2: ()}, types: {idx: tf.int32, label: tf.int64, sentence1: tf.string, sentence2: tf.string}>,\n",
       " 'train': <DatasetV1Adapter shapes: {idx: (), label: (), sentence1: (), sentence2: ()}, types: {idx: tf.int32, label: tf.int64, sentence1: tf.string, sentence2: tf.string}>,\n",
       " 'validation': <DatasetV1Adapter shapes: {idx: (), label: (), sentence1: (), sentence2: ()}, types: {idx: tf.int32, label: tf.int64, sentence1: tf.string, sentence2: tf.string}>}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['test', 'train', 'validation'])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DatasetV1Adapter shapes: {idx: (), label: (), sentence1: (), sentence2: ()}, types: {idx: tf.int32, label: tf.int64, sentence1: tf.string, sentence2: tf.string}>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'idx': TensorShape([]),\n",
       " 'label': TensorShape([]),\n",
       " 'sentence1': TensorShape([]),\n",
       " 'sentence2': TensorShape([])}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.data.ops import dataset_ops\n",
    "dataset_ops.get_legacy_output_shapes(data['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'idx': tf.int32,\n",
       " 'label': tf.int64,\n",
       " 'sentence1': tf.string,\n",
       " 'sentence2': tf.string}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_ops.get_legacy_output_types(data['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'idx': tensorflow.python.framework.ops.Tensor,\n",
       " 'label': tensorflow.python.framework.ops.Tensor,\n",
       " 'sentence1': tensorflow.python.framework.ops.Tensor,\n",
       " 'sentence2': tensorflow.python.framework.ops.Tensor}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_ops.get_legacy_output_classes(data['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['idx', 'label', 'sentence1', 'sentence2'])\n",
      "{'idx': <tf.Tensor: shape=(), dtype=int32, numpy=1680>, 'label': <tf.Tensor: shape=(), dtype=int64, numpy=0>, 'sentence1': <tf.Tensor: shape=(), dtype=string, numpy=b'The identical rovers will act as robotic geologists , searching for evidence of past water .'>, 'sentence2': <tf.Tensor: shape=(), dtype=string, numpy=b'The rovers act as robotic geologists , moving on six wheels .'>}\n",
      "tf.Tensor(1680, shape=(), dtype=int32)\n",
      "tf.Tensor(0, shape=(), dtype=int64)\n",
      "tf.Tensor(b'The identical rovers will act as robotic geologists , searching for evidence of past water .', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "for l in data['train']:\n",
    "    print(l.keys())\n",
    "    print(l)\n",
    "    print(l['idx'])\n",
    "    print(l['label'])\n",
    "    print(l['sentence1'])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'idx': 1680, 'label': 0, 'sentence1': b'The identical rovers will act as robotic geologists , searching for evidence of past water .', 'sentence2': b'The rovers act as robotic geologists , moving on six wheels .'}\n"
     ]
    }
   ],
   "source": [
    "# get numpy array\n",
    "for element in data['train'].as_numpy_iterator(): \n",
    "    print(element) \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3668,)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.shape(list(data['train'].as_numpy_iterator()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3668"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(data['train'].as_numpy_iterator()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'idx': 1680,\n",
       "  'label': 0,\n",
       "  'sentence1': b'The identical rovers will act as robotic geologists , searching for evidence of past water .',\n",
       "  'sentence2': b'The rovers act as robotic geologists , moving on six wheels .'}]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data['train'].take(1).as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Prepare dataset for GLUE as a tf.data.Dataset instance\n",
    "train_dataset = glue_convert_examples_to_features(data['train'], tokenizer, max_length=128, task='mrpc')\n",
    "valid_dataset = glue_convert_examples_to_features(data['validation'], tokenizer, max_length=128, task='mrpc')\n",
    "train_dataset = train_dataset.shuffle(100).batch(32).repeat(2)\n",
    "valid_dataset = valid_dataset.batch(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask', 'token_type_ids'])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(train_dataset.take(1).as_numpy_iterator())[0][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  101,  1258, 12421, ...,     0,     0,     0],\n",
       "       [  101,  1124,  1163, ...,     0,     0,     0],\n",
       "       [  101,  1573,  5567, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [  101,  4673,  1108, ...,     0,     0,     0],\n",
       "       [  101, 10789,  2142, ...,     0,     0,     0],\n",
       "       [  101, 23306,  1163, ...,     0,     0,     0]], dtype=int32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(train_dataset.take(1).as_numpy_iterator())[0][0]['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 128)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(train_dataset.take(1).as_numpy_iterator())[0][0]['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0]], dtype=int32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(train_dataset.take(1).as_numpy_iterator())[0][0]['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 128)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(train_dataset.take(1).as_numpy_iterator())[0][0]['attention_mask'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(train_dataset.take(1).as_numpy_iterator())[0][0]['token_type_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 128)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(train_dataset.take(1).as_numpy_iterator())[0][0]['token_type_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded string: [101, 1188, 1110, 170, 3014, 7758, 1106, 1129, 22559, 2200, 102]\n"
     ]
    }
   ],
   "source": [
    "encoding = tokenizer.encode(\"This is a simple input to be tokenized\")\n",
    "\n",
    "print(\"Encoded string: {}\".format(encoding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The identical rovers will act as robotic geologists , searching for evidence of past water .'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data['train'].take(1).as_numpy_iterator())[0]['sentence1'].decode(\"utf-8\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101,\n",
       " 1109,\n",
       " 6742,\n",
       " 187,\n",
       " 24985,\n",
       " 1209,\n",
       " 2496,\n",
       " 1112,\n",
       " 24628,\n",
       " 25166,\n",
       " 1116,\n",
       " 117,\n",
       " 6205,\n",
       " 1111,\n",
       " 2554,\n",
       " 1104,\n",
       " 1763,\n",
       " 1447,\n",
       " 119,\n",
       " 102]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(list(data['train'].take(1).as_numpy_iterator())[0]['sentence1'].decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101,\n",
       " 1109,\n",
       " 187,\n",
       " 24985,\n",
       " 2496,\n",
       " 1112,\n",
       " 24628,\n",
       " 25166,\n",
       " 1116,\n",
       " 117,\n",
       " 2232,\n",
       " 1113,\n",
       " 1565,\n",
       " 8089,\n",
       " 119,\n",
       " 102]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(list(data['train'].take(1).as_numpy_iterator())[0]['sentence2'].decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Prepare training: Compile tf.keras model with optimizer, loss and learning rate schedule\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5, epsilon=1e-08, clipnorm=1.0)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=[metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_for_sequence_classification\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bert (TFBertMainLayer)       multiple                  108310272 \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "classifier (Dense)           multiple                  1538      \n",
      "=================================================================\n",
      "Total params: 108,311,810\n",
      "Trainable params: 108,311,810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Train and evaluate using tf.keras.Model.fit()\n",
    "history = model.fit(train_dataset, epochs=2, steps_per_epoch=115,\n",
    "                    validation_data=valid_dataset, validation_steps=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Load the TensorFlow model in PyTorch for inspection\n",
    "model.save_pretrained('./save/')\n",
    "pytorch_model = BertForSequenceClassification.from_pretrained('./save/', from_tf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Quickly test a few predictions - MRPC is a paraphrasing task, let's see if our model learned the task\n",
    "sentence_0 = \"This research was consistent with his findings.\"\n",
    "sentence_1 = \"His findings were compatible with this research.\"\n",
    "sentence_2 = \"His findings were not compatible with this research.\"\n",
    "inputs_1 = tokenizer.encode_plus(sentence_0, sentence_1, add_special_tokens=True, return_tensors='pt')\n",
    "inputs_2 = tokenizer.encode_plus(sentence_0, sentence_2, add_special_tokens=True, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "pred_1 = pytorch_model(inputs_1['input_ids'], token_type_ids=inputs_1['token_type_ids'])[0].argmax().item()\n",
    "pred_2 = pytorch_model(inputs_2['input_ids'], token_type_ids=inputs_2['token_type_ids'])[0].argmax().item()\n",
    "\n",
    "print(\"sentence_1 is\", \"a paraphrase\" if pred_1 else \"not a paraphrase\", \"of sentence_0\")\n",
    "print(\"sentence_2 is\", \"a paraphrase\" if pred_2 else \"not a paraphrase\", \"of sentence_0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## TF_Config env variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from tensorboard.plugins.hparams import api as hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "os.environ['TF_CONFIG']='{\"cluster\": {\"chief\": [\"127.0.0.1:2222\"]}, \"task\": {\"type\": \"chief\", \"index\": 0, \"trial\": \"2\", \"cloud\": \"cxxx-ml\"}, \"job\": {\"package_uris\": [\"gs://xxx/tf_bert_classification_2020_05_12_141041/b0d287bd012da97a62f662b2e9df291e899c2e9705ca751a5a0f7dcaf2849765/bert_model-0.1.tar.gz\"], \"python_module\": \"model.tf_bert_classification.task\", \"args\": [\"--epochs=1\", \"--steps_per_epoch_train=5\", \"--batch_size_train=32\", \"--steps_per_epoch_eval=1\", \"--batch_size_eval=64\", \"--input_eval_tfrecords=gs://multilingual_text_classification/tfrecord/sst2/bert-base-multilingual-uncased/valid\", \"--input_train_tfrecords=gs://xxx/tfrecord/sst2/bert-base-multilingual-uncased/train\", \"--output_dir=gs://xxx/training_model_gcp/tf_bert_classification_2020_05_12_141041\", \"--pretrained_model_dir=gs://xxx/pretrained_model/bert-base-multilingual-uncased\", \"--verbosity_level=INFO\", \"--epsilon\", \"1.7788921050163616e-06\", \"--learning_rate\", \"0.0007763625134788308\"], \"hyperparameters\": {\"goal\": \"MAXIMIZE\", \"params\": [{\"parameter_name\": \"learning_rate\", \"min_value\": 1e-08, \"max_value\": 1.0, \"type\": \"DOUBLE\", \"scale_type\": \"UNIT_LOG_SCALE\"}, {\"parameter_name\": \"epsilon\", \"min_value\": 1e-09, \"max_value\": 1.0, \"type\": \"DOUBLE\", \"scale_type\": \"UNIT_LOG_SCALE\"}], \"max_trials\": 3, \"max_parallel_trials\": 2, \"hyperparameter_metric_tag\": \"accuracy_train\", \"enable_trial_early_stopping\": true, \"max_failed_trials\": 1}, \"region\": \"europe-west4\", \"runtime_version\": \"2.1\", \"run_on_raw_vm\": true, \"python_version\": \"3.7\"}, \"environment\": \"cloud\"}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"cluster\": {\"chief\": [\"127.0.0.1:2222\"]}, \"task\": {\"type\": \"chief\", \"index\": 0, \"trial\": \"2\", \"cloud\": \"cxxx-ml\"}, \"job\": {\"package_uris\": [\"gs://xxx/tf_bert_classification_2020_05_12_141041/b0d287bd012da97a62f662b2e9df291e899c2e9705ca751a5a0f7dcaf2849765/bert_model-0.1.tar.gz\"], \"python_module\": \"model.tf_bert_classification.task\", \"args\": [\"--epochs=1\", \"--steps_per_epoch_train=5\", \"--batch_size_train=32\", \"--steps_per_epoch_eval=1\", \"--batch_size_eval=64\", \"--input_eval_tfrecords=gs://multilingual_text_classification/tfrecord/sst2/bert-base-multilingual-uncased/valid\", \"--input_train_tfrecords=gs://xxx/tfrecord/sst2/bert-base-multilingual-uncased/train\", \"--output_dir=gs://xxx/training_model_gcp/tf_bert_classification_2020_05_12_141041\", \"--pretrained_model_dir=gs://xxx/pretrained_model/bert-base-multilingual-uncased\", \"--verbosity_level=INFO\", \"--epsilon\", \"1.7788921050163616e-06\", \"--learning_rate\", \"0.0007763625134788308\"], \"hyperparameters\": {\"goal\": \"MAXIMIZE\", \"params\": [{\"parameter_name\": \"learning_rate\", \"min_value\": 1e-08, \"max_value\": 1.0, \"type\": \"DOUBLE\", \"scale_type\": \"UNIT_LOG_SCALE\"}, {\"parameter_name\": \"epsilon\", \"min_value\": 1e-09, \"max_value\": 1.0, \"type\": \"DOUBLE\", \"scale_type\": \"UNIT_LOG_SCALE\"}], \"max_trials\": 3, \"max_parallel_trials\": 2, \"hyperparameter_metric_tag\": \"accuracy_train\", \"enable_trial_early_stopping\": true, \"max_failed_trials\": 1}, \"region\": \"europe-west4\", \"runtime_version\": \"2.1\", \"run_on_raw_vm\": true, \"python_version\": \"3.7\"}, \"environment\": \"cloud\"}'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['TF_CONFIG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'package_uris': ['gs://xxx/tf_bert_classification_2020_05_12_141041/b0d287bd012da97a62f662b2e9df291e899c2e9705ca751a5a0f7dcaf2849765/bert_model-0.1.tar.gz'],\n",
       " 'python_module': 'model.tf_bert_classification.task',\n",
       " 'args': ['--epochs=1',\n",
       "  '--steps_per_epoch_train=5',\n",
       "  '--batch_size_train=32',\n",
       "  '--steps_per_epoch_eval=1',\n",
       "  '--batch_size_eval=64',\n",
       "  '--input_eval_tfrecords=gs://multilingual_text_classification/tfrecord/sst2/bert-base-multilingual-uncased/valid',\n",
       "  '--input_train_tfrecords=gs://xxx/tfrecord/sst2/bert-base-multilingual-uncased/train',\n",
       "  '--output_dir=gs://xxx/training_model_gcp/tf_bert_classification_2020_05_12_141041',\n",
       "  '--pretrained_model_dir=gs://xxx/pretrained_model/bert-base-multilingual-uncased',\n",
       "  '--verbosity_level=INFO',\n",
       "  '--epsilon',\n",
       "  '1.7788921050163616e-06',\n",
       "  '--learning_rate',\n",
       "  '0.0007763625134788308'],\n",
       " 'hyperparameters': {'goal': 'MAXIMIZE',\n",
       "  'params': [{'parameter_name': 'learning_rate',\n",
       "    'min_value': 1e-08,\n",
       "    'max_value': 1.0,\n",
       "    'type': 'DOUBLE',\n",
       "    'scale_type': 'UNIT_LOG_SCALE'},\n",
       "   {'parameter_name': 'epsilon',\n",
       "    'min_value': 1e-09,\n",
       "    'max_value': 1.0,\n",
       "    'type': 'DOUBLE',\n",
       "    'scale_type': 'UNIT_LOG_SCALE'}],\n",
       "  'max_trials': 3,\n",
       "  'max_parallel_trials': 2,\n",
       "  'hyperparameter_metric_tag': 'accuracy_train',\n",
       "  'enable_trial_early_stopping': True,\n",
       "  'max_failed_trials': 1},\n",
       " 'region': 'europe-west4',\n",
       " 'runtime_version': '2.1',\n",
       " 'run_on_raw_vm': True,\n",
       " 'python_version': '3.7'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(os.environ.get(\"TF_CONFIG\", \"{}\")).get(\"job\",{}) #.get(\"args\",{})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "params=json.loads(os.environ.get(\"TF_CONFIG\", \"{}\")).get(\"job\",{}).get(\"hyperparameters\",{}).get(\"params\",{})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HParam(name='learning_rate', domain=RealInterval(1e-08, 1.0), display_name=None, description=None), HParam(name='epsilon', domain=RealInterval(1e-09, 1.0), display_name=None, description=None)]\n"
     ]
    }
   ],
   "source": [
    "list_hp=[]\n",
    "for el in params:\n",
    "    hp_dict=dict(el)\n",
    "    if hp_dict.get('type')=='DOUBLE':\n",
    "        list_hp.append(hp.HParam(hp_dict.get('parameter_name'), hp.RealInterval(hp_dict.get('min_value'), hp_dict.get('max_value'))))\n",
    "\n",
    "print(list_hp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from absl import flags\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "FLAGS = flags.FLAGS\n",
    "\n",
    "def del_all_flags(FLAGS):\n",
    "    flags_dict = FLAGS._flags()    \n",
    "    keys_list = [keys for keys in flags_dict]    \n",
    "    for keys in keys_list:\n",
    "        FLAGS.__delattr__(keys)\n",
    "    \n",
    "del_all_flags(flags.FLAGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "flags.DEFINE_string('f', '', 'kernel') # just for jupyter notebook and avoir : \"UnrecognizedFlagError: Unknown command line flag 'f'\"\n",
    "flags.DEFINE_float('float', 3.14, 'using floats')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "FLAGS(sys.argv);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key doesn t exist\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    FLAGS['float2'].value\n",
    "except KeyError:\n",
    "    print('key doesn t exist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## TF.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "writer = tf.summary.create_file_writer(\"mylogs\")\n",
    "with writer.as_default():\n",
    "    tf.summary.scalar('metric_accuracy', 1.0, step=1)\n",
    "    tf.summary.scalar('metric_accuracy', 3.0, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from tensorboard.backend.event_processing import event_accumulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorboard.backend.event_processing.event_accumulator.EventAccumulator at 0x639fa0d90>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_acc = event_accumulator.EventAccumulator(\"mylogs\")\n",
    "event_acc.Reload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'images': [],\n",
       " 'audio': [],\n",
       " 'histograms': [],\n",
       " 'scalars': [],\n",
       " 'distributions': [],\n",
       " 'tensors': ['metric_accuracy'],\n",
       " 'graph': False,\n",
       " 'meta_graph': False,\n",
       " 'run_metadata': []}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_acc.Tags()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric_accuracy\n",
      "TensorEvent(wall_time=1591375231.698866, step=1, tensor_proto=dtype: DT_FLOAT\n",
      "tensor_shape {\n",
      "}\n",
      "tensor_content: \"\\000\\000\\200?\"\n",
      ")\n",
      "TensorEvent(wall_time=1591375768.306123, step=1, tensor_proto=dtype: DT_FLOAT\n",
      "tensor_shape {\n",
      "}\n",
      "tensor_content: \"\\000\\000\\200?\"\n",
      ")\n",
      "TensorEvent(wall_time=1591375939.109795, step=1, tensor_proto=dtype: DT_FLOAT\n",
      "tensor_shape {\n",
      "}\n",
      "tensor_content: \"\\000\\000\\200?\"\n",
      ")\n",
      "TensorEvent(wall_time=1591375939.111349, step=1, tensor_proto=dtype: DT_FLOAT\n",
      "tensor_shape {\n",
      "}\n",
      "tensor_content: \"\\000\\000@@\"\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "for tag in sorted(event_acc.Tags()['tensors']):\n",
    "    print(tag)\n",
    "    #print(dir(event_acc))\n",
    "    for scalar_event in event_acc.Tensors(tag):\n",
    "        print(scalar_event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:env_multilingual_class]",
   "language": "python",
   "name": "conda-env-env_multilingual_class-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
