{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# The Stanford Sentiment Treebank \n",
    "The Stanford Sentiment Treebank consists of sentences from movie reviews and human annotations of their sentiment. The task is to predict the sentiment of a given sentence. We use the two-way (positive/negative) class split, and use only sentence-level labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Environment variables that need to be defined:   \n",
       "`export DIR_PROJ=your_path_git_repository`  \n",
       "`export PYTHONPATH=$DIR_PROJ/src`  \n",
       "`export PATH_TENSORBOARD=your_path_tensorboard`  \n",
       "`export PATH_DATASETS=your_path_datasets`  \n",
       "`export PROJECT_ID=your_gcp_project_id`  \n",
       "`export BUCKET_NAME=your_gcp_gs_bucket_name`  \n",
       "`export BUCKET_TRANSLATION_NAME=your_gcp_gs_bucket_translation_name`  \n",
       "`export REGION=your_region`  \n",
       "`export PATH_SAVE_MODEL=your_path_to_save_model`  \n",
       "`export CLOUDSDK_PYTHON=your_path/conda-env/env_gcp_sdk/bin/python`  \n",
       "`export CLOUDSDK_GSUTIL_PYTHON=your_path/conda-env/env_gcp_sdk/bin/python`  \n",
       "\n",
       "- Use local Jupyter Lab \n",
       "    - you need to have the `jupyter-notebook` Anaconda python environment created [link](local_jupyter_lab_installation.md) \n",
       "    - you need to have the `jupyter-notebook` Anaconda python environment activated [link](local_jupyter_lab_installation.md) \n",
       "    - then define the environment variables above (copy and paste) \n",
       "    - you need to have the `env_multilingual_class` Anaconda python environment created [link](local_jupyter_lab_installation.md)  \n",
       "    - start Jupyter Lab:  `jupyter lab` \n",
       "    - open a Jupyter Lab notebook from `notebook/` \n",
       "     - clone this repositiory: `git clone https://github.com/tarrade/proj_multilingual_text_classification.git`\n",
       "    - choose the proper Anaconda python environment:  `Python [conda env:env_multilingual_class]` [link](conda_env.md) \n",
       "    - clone this repositiory: `git clone https://github.com/tarrade/proj_multilingual_text_classification.git`\n",
       "\n",
       "\n",
       "- Use GCP Jupyter Lab \n",
       "    - Go on GCP\n",
       "    - open a Cloud Shell\n",
       "    - `ssh-keygen -t rsa -b 4096 -C firstName_lastName`\n",
       "    - `cp .ssh/id_rsa.pub .`\n",
       "    - use Cloud Editor to edit this file `id_rsa.pub` and copy the full content\n",
       "    - Go on Compute Engine -> Metadata\n",
       "    - Click SSH Keys\n",
       "    - Click Edit\n",
       "    - Click + Add item, copy the content of `id_rsa.pub`\n",
       "    - You should see firstName_lastName of the left\n",
       "    - Click Save\n",
       "    - you need to start a AI Platform instance \n",
       "    - open a Jupyter Lab terminal and got to `/home/gcp_user_name/`\n",
       "    - clone this repositiory: `git clone https://github.com/tarrade/proj_multilingual_text_classification.git`\n",
       "    - then `cd proj_multilingual_text_classification/`\n",
       "    - create the Anacond Python environment `conda env create -f env/environment.yml`\n",
       "    - create a file `config.sh` in `/home` with the following information: \n",
       "    ```\n",
       "    #!/bin/bash\n",
       "    \n",
       "    echo \"applying some configuration ...\"\n",
       "    git config --global user.email user_email\n",
       "    git config --global user.name user_name\n",
       "    git config --global credential.helper store\n",
       "        \n",
       "    # Add here the enviroment variables from above below\n",
       "    # [EDIT ME]\n",
       "    export DIR_PROJ=your_path_git_repository\n",
       "    export PYTHONPATH=$DIR_PROJ/src\n",
       "  \n",
       "    cd /home/gcp_user_name/\n",
       "    \n",
       "    conda activate env_multilingual_class\n",
       "\n",
       "    export PS1='\\[\\e[91m\\]\\u@:\\[\\e[32m\\]\\w\\[\\e[0m\\]$'\n",
       "    ```\n",
       "    - Got to AI Platform Notebook, select your instance and click \"Reset\".\n",
       "    - Wait and reshreh you Web browser with the Notebook\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "with open('../../doc/env_variables_setup.md', 'r') as fh:\n",
    "    content = fh.read()\n",
    "display(Markdown(content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import (\n",
    "    BertConfig,\n",
    "    BertTokenizer,\n",
    "    XLMRobertaTokenizer,\n",
    "    TFBertModel,\n",
    "    TFXLMRobertaModel,\n",
    ")\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Import local packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarrade/anaconda-release/conda-env/env_multilingual_class/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import preprocessing.preprocessing as pp\n",
    "import utils.model_metrics as mm\n",
    "import utils.model_utils as mu\n",
    "import model.tf_custom_bert_classification.model as tf_custom_bert\n",
    "import model.tf_bert_classification.model as tf_bert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Check configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v2.1.0-rc2-17-ge5bf8de410 2.1.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.version.GIT_VERSION, tf.version.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "print(tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available !!!!\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if len(gpus)>0:\n",
    "    for gpu in gpus:\n",
    "        print('Name:', gpu.name, '  Type:', gpu.device_type)\n",
    "else:\n",
    "    print('No GPU available !!!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Define Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    data_dir=os.environ['PATH_DATASETS']\n",
    "except KeyError:\n",
    "    print('missing PATH_DATASETS')\n",
    "try:   \n",
    "    tensorboard_dir=os.environ['PATH_TENSORBOARD']\n",
    "except KeyError:\n",
    "    print('missing PATH_TENSORBOARD')\n",
    "try:   \n",
    "    savemodel_dir=os.environ['PATH_SAVE_MODEL']\n",
    "except KeyError:\n",
    "    print('missing PATH_SAVE_MODEL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Read data from TFRecord files [local training of the model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Path of the directory with TFRecord files\n",
    "tfrecord_data_dir=data_dir+'/tfrecord/sst2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Define parameters of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# models\n",
    "MODELS = [(TFBertModel,         BertTokenizer,       'bert-base-multilingual-uncased'),\n",
    "          (TFXLMRobertaModel,   XLMRobertaTokenizer, 'jplu/tf-xlm-roberta-base')]\n",
    "model_index = 0 # BERT\n",
    "model_class        = MODELS[model_index][0] # i.e TFBertModel\n",
    "tokenizer_class    = MODELS[model_index][1] # i.e BertTokenizer\n",
    "pretrained_weights = MODELS[model_index][2] #'i.e bert-base-multilingual-uncased'\n",
    "number_label = 2                                                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Train the model locally with AI Platform Training (for tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "savemodel_path = os.path.join(savemodel_dir, 'saved_model')\n",
    "pretrained_model_dir=savemodel_dir+'/pretrained_model/'+pretrained_weights\n",
    "model_name='tf_bert_classification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# train locally\n",
    "os.environ['EPOCH'] = '1' \n",
    "os.environ['STEPS_PER_EPOCH_TRAIN'] = '1' \n",
    "os.environ['BATCH_SIZE_TRAIN'] = '32' \n",
    "os.environ['STEPS_PER_EPOCH_EVAL'] = '1' \n",
    "os.environ['BATCH_SIZE_EVAL'] = '64'\n",
    "os.environ['TRAINER_PACKAGE_PATH'] = os.environ['PYTHONPATH']\n",
    "os.environ['MAIN_TRAINER_MODULE'] = 'model.'+model_name+'.task'\n",
    "os.environ['INPUT_EVAL_TFRECORDS'] = tfrecord_data_dir\n",
    "os.environ['INPUT_TRAIN_TFRECORDS'] = tfrecord_data_dir\n",
    "os.environ['OUTPUT_DIR'] = savemodel_path\n",
    "os.environ['PRETRAINED_MODEL_DIR']= pretrained_model_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 1 steps, validate for 1 steps\n",
      "\n",
      " training set -> batch:1 loss:0.6951441168785095 and acc: 0.5\n",
      "\n",
      "Epoch 00001: saving model to /Users/tarrade/tensorflow_model/saved_model/checkpoint_model/ckpt_01\n",
      "accuracy_train 0.5 epoch 0 \n",
      "\n",
      "1/1 [==============================] - 81s 81s/step - loss: 0.6951 - accuracy: 0.5000 - val_loss: 0.7058 - val_accuracy: 0.4531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarrade/anaconda-release/conda-env/env_multilingual_class/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "[INFO 2020-05-06 11:39:38,945 task.py:71] 2.1.0\n",
      "[INFO 2020-05-06 11:39:38,945 task.py:72] 2.2.4-tf\n",
      "[INFO 2020-05-06 11:39:38,945 task.py:73] ['logtostderr', 'alsologtostderr', 'log_dir', 'v', 'verbosity', 'stderrthreshold', 'showprefixforinfo', 'run_with_pdb', 'pdb_post_mortem', 'run_with_profiling', 'profile_file', 'use_cprofile_for_profiling', 'only_check_args', 'op_conversion_fallback_to_while_loop', 'test_random_seed', 'test_srcdir', 'test_tmpdir', 'test_randomize_ordering_seed', 'xml_output_file', 'learning_rate', 'epsilon', 'epochs', 'steps_per_epoch_train', 'batch_size_train', 'steps_per_epoch_eval', 'batch_size_eval', 'num_classes', 'n_steps_history', 'input_train_tfrecords', 'input_eval_tfrecords', 'output_dir', 'pretrained_model_dir', 'verbosity_level', 'use_tpu', '?', 'help', 'helpshort', 'helpfull', 'helpxml']\n",
      "[INFO 2020-05-06 11:39:38,947 task.py:86] downloading pretrained model!\n",
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "[INFO 2020-05-06 11:39:39,245 task.py:127] Number of devices: 1\n",
      "[INFO 2020-05-06 11:39:39,922 configuration_utils.py:283] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-uncased-config.json from cache at /Users/tarrade/tensorflow_model/pretrained_model/bert-base-multilingual-uncased/33b56ce0f312e47e4d77a57791a4fc6233ae4a560dd2bdd186107058294e58ab.fcb1786f49c279f0e0f158c9972b9bd9f6c0edb5d893dcb9b530d714d86f0edc\n",
      "[INFO 2020-05-06 11:39:39,923 configuration_utils.py:319] Model config BertConfig {\n",
      "  \"_num_labels\": 2,\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bad_words_ids\": null,\n",
      "  \"bos_token_id\": null,\n",
      "  \"decoder_start_token_id\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"do_sample\": false,\n",
      "  \"early_stopping\": false,\n",
      "  \"eos_token_id\": null,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"is_encoder_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"min_length\": 0,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"no_repeat_ngram_size\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"prefix\": null,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"task_specific_params\": null,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n",
      "[INFO 2020-05-06 11:39:40,524 modeling_tf_utils.py:390] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-uncased-tf_model.h5 from cache at /Users/tarrade/tensorflow_model/pretrained_model/bert-base-multilingual-uncased/7efc9507bca9e880aea7a38a849d8e16fcd54f2071f8f8143afa5815d00a16f4.25728a4fd7ddaafee2965f5821a206f237b83c672e0bb092881f9b1f5eea2b2f.h5\n",
      "[INFO 2020-05-06 11:39:44,502 modeling_tf_utils.py:428] Layers of TFBertForSequenceClassification not initialized from pretrained model: ['classifier', 'dropout_37']\n",
      "[INFO 2020-05-06 11:39:44,502 modeling_tf_utils.py:432] Layers from pretrained model not used in TFBertForSequenceClassification: ['mlm___cls', 'nsp___cls']\n",
      "[INFO 2020-05-06 11:39:44,507 model.py:54] training the model ...\n",
      "[INFO 2020-05-06 11:41:10,223 model.py:102] \n",
      "execution time: 0:01:26\n",
      "[INFO 2020-05-06 11:41:10,223 model.py:104] timing per epoch:\n",
      "['0:01:21']\n",
      "[INFO 2020-05-06 11:41:10,223 model.py:105] sum timing over all epochs:\n",
      "0:01:21\n",
      "WARNING:tensorflow:From /Users/tarrade/anaconda-release/conda-env/env_multilingual_class/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: /Users/tarrade/tensorflow_model/saved_model/saved_model/tf_bert_classification/assets\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# Use Cloud Machine Learning Engine to train the model in local file system\n",
    "gcloud ai-platform local train \\\n",
    "   --module-name=$MAIN_TRAINER_MODULE \\\n",
    "   --package-path=$TRAINER_PACKAGE_PATH \\\n",
    "   -- \\\n",
    "   --epochs=$EPOCH \\\n",
    "   --steps_per_epoch_train=$STEPS_PER_EPOCH_TRAIN \\\n",
    "   --batch_size_train=$BATCH_SIZE_TRAIN \\\n",
    "   --steps_per_epoch_eval=$STEPS_PER_EPOCH_EVAL \\\n",
    "   --batch_size_eval=$BATCH_SIZE_EVAL \\\n",
    "   --input_eval_tfrecords=$INPUT_EVAL_TFRECORDS \\\n",
    "   --input_train_tfrecords=$INPUT_TRAIN_TFRECORDS \\\n",
    "   --output_dir=$OUTPUT_DIR \\\n",
    "   --pretrained_model_dir=$PRETRAINED_MODEL_DIR \\\n",
    "   --verbosity_level='INFO'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "## Debug model's function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "Number of devices: 1\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print('Number of devices: {}'.format(strategy.num_replicas_in_sync))\n",
    "\n",
    "# create and compile the Keras model in the context of strategy.scope\n",
    "with strategy.scope():\n",
    "    model=tf_bert.create_model(pretrained_weights, \n",
    "                               pretrained_model_dir=pretrained_model_dir,\n",
    "                               num_labels=number_label,\n",
    "                               learning_rate=3e-5,\n",
    "                               epsilon=1e-08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# TFRecords encode and store data\n",
    "#train_files = tf.data.TFRecordDataset(tfrecord_data_dir+'/train_dataset.tfrecord')\n",
    "#test_files = tf.data.TFRecordDataset(tfrecord_data_dir+'/test_dataset.tfrecord')\n",
    "#valid_files = tf.data.TFRecordDataset(tfrecord_data_dir+'/valid_dataset.tfrecord')\n",
    "\n",
    "train_files = tf.data.TFRecordDataset(tf.io.gfile.glob(tfrecord_data_dir+'/'+model.name+'/train/*.tfrecord'))\n",
    "test_files = tf.data.TFRecordDataset(tf.io.gfile.glob(tfrecord_data_dir+'/'+model.name+'/test/*.tfrecord'))\n",
    "valid_files = tf.data.TFRecordDataset(tf.io.gfile.glob(tfrecord_data_dir+'/'+model.name+'/valid/*.tfrecord'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "train_dataset = train_files.map(pp.parse_tfrecord_glue_files)\n",
    "test_dataset = test_files.map(pp.parse_tfrecord_glue_files)\n",
    "valid_dataset = valid_files.map(pp.parse_tfrecord_glue_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# define parameters\n",
    "BATCH_SIZE_TRAIN = 32\n",
    "BATCH_SIZE_TEST = 32\n",
    "BATCH_SIZE_VALID = 64\n",
    "EPOCH = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# set shuffle and batch size\n",
    "train_dataset = train_dataset.shuffle(100).batch(BATCH_SIZE_TRAIN).repeat(EPOCH+1)\n",
    "test_dataset = test_dataset.shuffle(100).batch(BATCH_SIZE_TEST).repeat(EPOCH+1)\n",
    "valid_dataset = valid_dataset.batch(BATCH_SIZE_VALID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:training the model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 1 steps, validate for 1 steps\n",
      "\n",
      " training set -> batch:1 loss:0.6993996500968933 and acc: 0.5\n",
      "\n",
      " validation set -> batch:1 val loss:0.6954854258469173 and val acc: 0.5091742873191833\n",
      "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (162.407600). Check your callbacks.\n",
      "\n",
      "Epoch 00001: saving model to /Users/tarrade/tensorflow_model/saved_model/checkpoint_model/ckpt_01\n",
      "accuracy_train 0.5 epoch 0 \n",
      "\n",
      "1/1 [==============================] - 245s 245s/step - loss: 0.6994 - accuracy: 0.5000 - val_loss: 0.7118 - val_accuracy: 0.4531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:\n",
      "execution time: 0:04:07\n",
      "INFO:absl:timing per epoch:\n",
      "['0:04:05']\n",
      "INFO:absl:sum timing over all epochs:\n",
      "0:04:05\n",
      "INFO:absl:env variables: \n",
      "environ({'BUCKET_NAME_STAGING': 'ai-platform-training-package-staging', 'TERM_PROGRAM': 'Apple_Terminal', 'PATH_TENSORBOARD': '/Users/tarrade/tensorboard', 'SHELL': '/bin/bash', 'TERM': 'xterm-color', 'CLOUDSDK_GSUTIL_PYTHON': '/Users/tarrade/anaconda-release/conda-env/env_gcp_sdk/bin/python', 'TMPDIR': '/var/folders/l7/00kxfwvs0vbbqxtrp3rpf3yh0000gn/T/', 'Apple_PubSub_Socket_Render': '/private/tmp/com.apple.launchd.3b9hENPCVa/Render', 'CONDA_SHLVL': '3', 'DIR_PROJ': '/Users/tarrade/Desktop/Work/Data_Science/Tutorials_Codes/Python/proj_multilingual_text_classification/src', 'TERM_PROGRAM_VERSION': '421.2', 'CONDA_PROMPT_MODIFIER': '(/Users/tarrade/anaconda-release/conda-env/env_multilingual_class) ', 'TERM_SESSION_ID': '9A9F31A5-24E4-468C-9323-3B89F0AE8F4D', 'LC_ALL': 'en_US.UTF-8', 'USER': 'tarrade', 'BUCKET_STAGING_NAME': 'ai-platform-training-package-staging', 'PATH_DATASETS': '/Users/tarrade/tensorflow_datasets', 'CONDA_EXE': '/Users/tarrade/anaconda-release/anaconda3/bin/conda', 'SSH_AUTH_SOCK': '/private/tmp/com.apple.launchd.8xxt0Ec8iq/Listeners', 'KERNEL_LAUNCH_TIMEOUT': '40', 'JPY_PARENT_PID': '19704', '_CE_CONDA': '', 'CONDA_PREFIX_1': '/Users/tarrade/anaconda-release/anaconda3', 'BUCKET_TRANSLATION_NAME': 'multilingual_text_classification_translation', 'PATH': '/Users/tarrade/gcp-gcloud/google-cloud-sdk/bin:/Users/tarrade/.cargo/bin:/Users/tarrade/anaconda-release/conda-env/env_multilingual_class/bin:/Users/tarrade/anaconda-release/anaconda3/condabin:/opt/local/bin:/opt/local/sbin:/usr/local/bin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/Library/TeX/texbin:/opt/X11/bin', 'CONDA_PREFIX_2': '/Users/tarrade/anaconda-release/conda-env/jupyter-notebook', 'CONDA_PREFIX': '/Users/tarrade/anaconda-release/conda-env/env_multilingual_class', 'PWD': '/Users/tarrade/Desktop/Work/Data_Science/Tutorials_Codes/Python/proj_multilingual_text_classification/notebook/03-Models', 'PROJECT_ID': 'axarevvicnonprod', 'LANG': 'en_US.UTF-8', 'CLOUDSDK_PYTHON': '/Users/tarrade/anaconda-release/conda-env/env_gcp_sdk/bin/python', 'XPC_FLAGS': '0x0', 'BUCKET_NAME': 'multilingual_text_classification', 'XPC_SERVICE_NAME': '0', '_CE_M': '', 'REGION': 'europe-west1', 'SHLVL': '1', 'HOME': '/Users/tarrade', 'LOGNAME': 'tarrade', 'CONDA_PYTHON_EXE': '/Users/tarrade/anaconda-release/anaconda3/bin/python', 'PYTHONPATH': '/Users/tarrade/Desktop/Work/Data_Science/Tutorials_Codes/Python/proj_multilingual_text_classification/src', 'LC_CTYPE': 'UTF-8', 'CONDA_DEFAULT_ENV': '/Users/tarrade/anaconda-release/conda-env/env_multilingual_class', 'GIT_PYTHON_REFRESH': 'quiet', 'PATH_SAVE_MODEL': '/Users/tarrade/tensorflow_model', 'DISPLAY': '/private/tmp/com.apple.launchd.vQX8t00eKr/org.macosforge.xquartz:0', 'SECURITYSESSIONID': '186a8', 'CLICOLOR': '1', 'PAGER': 'cat', 'GIT_PAGER': 'cat', 'MPLBACKEND': 'module://ipykernel.pylab.backend_inline', 'NO_GCE_CHECK': 'False', 'GCE_METADATA_TIMEOUT': '3', 'KMP_DUPLICATE_LIB_OK': 'True', 'KMP_INIT_AT_FORK': 'FALSE', 'EPOCH': '1', 'STEPS_PER_EPOCH_TRAIN': '1', 'BATCH_SIZE_TRAIN': '32', 'STEPS_PER_EPOCH_EVAL': '1', 'BATCH_SIZE_EVAL': '64', 'TRAINER_PACKAGE_PATH': '/Users/tarrade/Desktop/Work/Data_Science/Tutorials_Codes/Python/proj_multilingual_text_classification/src', 'MAIN_TRAINER_MODULE': 'model.tf_bert_classification.task', 'INPUT_EVAL_TFRECORDS': '/Users/tarrade/tensorflow_datasets/tfrecord/sst2', 'INPUT_TRAIN_TFRECORDS': '/Users/tarrade/tensorflow_datasets/tfrecord/sst2', 'OUTPUT_DIR': '/Users/tarrade/tensorflow_model/saved_model', 'PRETRAINED_MODEL_DIR': '/Users/tarrade/tensorflow_model/pretrained_model/bert-base-multilingual-uncased'})\n",
      "INFO:absl:hyperparameter tuning \"accuracy_train\": [0.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/tarrade/tensorflow_model/saved_model/saved_model/tf_bert_classification/assets\n"
     ]
    }
   ],
   "source": [
    "tf.get_logger().propagate = False\n",
    "from absl import logging\n",
    "logging.set_verbosity(logging.INFO)\n",
    "history_test=tf_bert.train_and_evaluate(model, \n",
    "                                        num_epochs=1, \n",
    "                                        steps_per_epoch=1, \n",
    "                                        train_data=train_dataset, \n",
    "                                        validation_steps=1, \n",
    "                                        eval_data=valid_dataset, \n",
    "                                        n_steps_history=1,\n",
    "                                        output_dir=savemodel_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:env_multilingual_class]",
   "language": "python",
   "name": "conda-env-env_multilingual_class-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
