{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# The IMDb Dataset\n",
    "The IMDb dataset consists of sentences from movie reviews and human annotations of their sentiment. The task is to predict the sentiment of a given sentence. We use the two-way (positive/negative) class split, and use only sentence-level labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Environment variables that need to be defined:   \n",
       "`export DIR_PROJ=your_path_git_repository`  \n",
       "`export PYTHONPATH=$DIR_PROJ/src`  \n",
       "`export PATH_TENSORBOARD=your_path_tensorboard`  \n",
       "`export PATH_DATASETS=your_path_datasets`  \n",
       "`export PROJECT_ID=your_gcp_project_id`  \n",
       "`export BUCKET_NAME=your_gcp_gs_bucket_name`  \n",
       "`export BUCKET_TRANSLATION_NAME=your_gcp_gs_bucket_translation_name`  \n",
       "`export BUCKET_STAGING_NAME=your_gcp_gs_bucket_staging_name` \n",
       "`export REGION=your_region`  \n",
       "`export PATH_SAVE_MODEL=your_path_to_save_model`  \n",
       "`export CLOUDSDK_PYTHON=your_path/conda-env/env_gcp_sdk/bin/python`  \n",
       "`export CLOUDSDK_GSUTIL_PYTHON=your_path/conda-env/env_gcp_sdk/bin/python`  \n",
       "\n",
       "- Use local Jupyter Lab \n",
       "    - you need to have the `jupyter-notebook` Anaconda python environment created [link](local_jupyter_lab_installation.md) \n",
       "    - you need to have the `jupyter-notebook` Anaconda python environment activated [link](local_jupyter_lab_installation.md) \n",
       "    - then define the environment variables above (copy and paste) \n",
       "    - you need to have the `env_multilingual_class` Anaconda python environment created [link](local_jupyter_lab_installation.md)  \n",
       "    - start Jupyter Lab:  `jupyter lab` \n",
       "    - open a Jupyter Lab notebook from `notebook/` \n",
       "     - clone this repositiory: `git clone https://github.com/tarrade/proj_multilingual_text_classification.git`\n",
       "    - choose the proper Anaconda python environment:  `Python [conda env:env_multilingual_class]` [link](conda_env.md) \n",
       "    - clone this repositiory: `git clone https://github.com/tarrade/proj_multilingual_text_classification.git`\n",
       "\n",
       "\n",
       "- Use GCP Jupyter Lab \n",
       "    - Go on GCP\n",
       "    - open a Cloud Shell\n",
       "    - `ssh-keygen -t rsa -b 4096 -C firstName_lastName`\n",
       "    - `cp .ssh/id_rsa.pub .`\n",
       "    - use Cloud Editor to edit this file `id_rsa.pub` and copy the full content\n",
       "    - Go on Compute Engine -> Metadata\n",
       "    - Click SSH Keys\n",
       "    - Click Edit\n",
       "    - Click + Add item, copy the content of `id_rsa.pub`\n",
       "    - You should see firstName_lastName of the left\n",
       "    - Click Save\n",
       "    - you need to start a AI Platform instance \n",
       "    - open a Jupyter Lab terminal and got to `/home/gcp_user_name/`\n",
       "    - clone this repositiory: `git clone https://github.com/tarrade/proj_multilingual_text_classification.git`\n",
       "    - then `cd proj_multilingual_text_classification/`\n",
       "    - create the Anacond Python environment `conda env create -f env/environment.yml`\n",
       "    - create a file `config.sh` in `/home` with the following information: \n",
       "    ```\n",
       "    #!/bin/bash\n",
       "    \n",
       "    echo \"applying some configuration ...\"\n",
       "    git config --global user.email user_email\n",
       "    git config --global user.name user_name\n",
       "    git config --global credential.helper store\n",
       "        \n",
       "    # Add here the enviroment variables from above below\n",
       "    # [EDIT ME]\n",
       "    export DIR_PROJ=your_path_git_repository\n",
       "    export PYTHONPATH=$DIR_PROJ/src\n",
       "  \n",
       "    cd /home/gcp_user_name/\n",
       "    \n",
       "    conda activate env_multilingual_class\n",
       "\n",
       "    export PS1='\\[\\e[91m\\]\\u@:\\[\\e[32m\\]\\w\\[\\e[0m\\]$'\n",
       "    ```\n",
       "    - Got to AI Platform Notebook, select your instance and click \"Reset\".\n",
       "    - Wait and reshreh you Web browser with the Notebook\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "with open('../../doc/env_variables_setup.md', 'r') as fh:\n",
    "    content = fh.read()\n",
    "display(Markdown(content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import (\n",
    "    BertConfig,\n",
    "    BertTokenizer,\n",
    "    XLMRobertaTokenizer,\n",
    "    TFBertModel,\n",
    "    TFXLMRobertaModel,\n",
    ")\n",
    "import os\n",
    "from datetime import datetime\n",
    "import tensorflow_datasets\n",
    "from tensorboard import notebook\n",
    "import math\n",
    "from google.cloud import storage\n",
    "from googleapiclient import discovery\n",
    "from googleapiclient import errors\n",
    "import logging\n",
    "import subprocess\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Check configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v2.2.0-rc4-8-g2b96f3662b 2.2.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.version.GIT_VERSION, tf.version.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0-tf\n"
     ]
    }
   ],
   "source": [
    "print(tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available !!!!\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if len(gpus)>0:\n",
    "    for gpu in gpus:\n",
    "        print('Name:', gpu.name, '  Type:', gpu.device_type)\n",
    "else:\n",
    "    print('No GPU available !!!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Define Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    data_dir=os.environ['PATH_DATASETS']\n",
    "except KeyError:\n",
    "    print('missing PATH_DATASETS')\n",
    "try:   \n",
    "    tensorboard_dir=os.environ['PATH_TENSORBOARD']\n",
    "except KeyError:\n",
    "    print('missing PATH_TENSORBOARD')\n",
    "try:   \n",
    "    savemodel_dir=os.environ['PATH_SAVE_MODEL']\n",
    "except KeyError:\n",
    "    print('missing PATH_SAVE_MODEL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Train the model on AI Platform Training (for production)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "model_name = 'tf_bert_classification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/vera_luechinger/proj_multilingual_text_classification'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['DIR_PROJ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: sdist: standard file not found: should have one of README, README.rst, README.txt, README.md\n",
      "\n",
      "warning: check: missing required meta-data: url\n",
      "\n",
      "running sdist\n",
      "running egg_info\n",
      "writing bert_model.egg-info/PKG-INFO\n",
      "writing dependency_links to bert_model.egg-info/dependency_links.txt\n",
      "writing requirements to bert_model.egg-info/requires.txt\n",
      "writing top-level names to bert_model.egg-info/top_level.txt\n",
      "reading manifest file 'bert_model.egg-info/SOURCES.txt'\n",
      "writing manifest file 'bert_model.egg-info/SOURCES.txt'\n",
      "running check\n",
      "creating bert_model-0.1\n",
      "creating bert_model-0.1/analysis\n",
      "creating bert_model-0.1/bert_model.egg-info\n",
      "creating bert_model-0.1/model\n",
      "creating bert_model-0.1/model/sklearn_naive_bayes\n",
      "creating bert_model-0.1/model/test\n",
      "creating bert_model-0.1/model/tf_bert_classification\n",
      "creating bert_model-0.1/model/tf_custom_bert_classification\n",
      "creating bert_model-0.1/preprocessing\n",
      "creating bert_model-0.1/utils\n",
      "copying files to bert_model-0.1...\n",
      "copying setup.py -> bert_model-0.1\n",
      "copying analysis/__init__.py -> bert_model-0.1/analysis\n",
      "copying analysis/get_data.py -> bert_model-0.1/analysis\n",
      "copying bert_model.egg-info/PKG-INFO -> bert_model-0.1/bert_model.egg-info\n",
      "copying bert_model.egg-info/SOURCES.txt -> bert_model-0.1/bert_model.egg-info\n",
      "copying bert_model.egg-info/dependency_links.txt -> bert_model-0.1/bert_model.egg-info\n",
      "copying bert_model.egg-info/requires.txt -> bert_model-0.1/bert_model.egg-info\n",
      "copying bert_model.egg-info/top_level.txt -> bert_model-0.1/bert_model.egg-info\n",
      "copying model/__init__.py -> bert_model-0.1/model\n",
      "copying model/sklearn_naive_bayes/__init__.py -> bert_model-0.1/model/sklearn_naive_bayes\n",
      "copying model/sklearn_naive_bayes/model.py -> bert_model-0.1/model/sklearn_naive_bayes\n",
      "copying model/sklearn_naive_bayes/task.py -> bert_model-0.1/model/sklearn_naive_bayes\n",
      "copying model/test/__init__.py -> bert_model-0.1/model/test\n",
      "copying model/test/task.py -> bert_model-0.1/model/test\n",
      "copying model/tf_bert_classification/__init__.py -> bert_model-0.1/model/tf_bert_classification\n",
      "copying model/tf_bert_classification/model.py -> bert_model-0.1/model/tf_bert_classification\n",
      "copying model/tf_bert_classification/task.py -> bert_model-0.1/model/tf_bert_classification\n",
      "copying model/tf_custom_bert_classification/__init__.py -> bert_model-0.1/model/tf_custom_bert_classification\n",
      "copying model/tf_custom_bert_classification/model.py -> bert_model-0.1/model/tf_custom_bert_classification\n",
      "copying model/tf_custom_bert_classification/task.py -> bert_model-0.1/model/tf_custom_bert_classification\n",
      "copying preprocessing/__init__.py -> bert_model-0.1/preprocessing\n",
      "copying preprocessing/preprocessing.py -> bert_model-0.1/preprocessing\n",
      "copying utils/__init__.py -> bert_model-0.1/utils\n",
      "copying utils/model_metrics.py -> bert_model-0.1/utils\n",
      "copying utils/model_tests.py -> bert_model-0.1/utils\n",
      "copying utils/model_utils.py -> bert_model-0.1/utils\n",
      "copying utils/ressources_utils.py -> bert_model-0.1/utils\n",
      "Writing bert_model-0.1/setup.cfg\n",
      "Creating tar archive\n",
      "removing 'bert_model-0.1' (and everything under it)\n"
     ]
    }
   ],
   "source": [
    "# create the package\n",
    "process=subprocess.Popen(['python','setup.py', 'sdist'], cwd=os.environ['DIR_PROJ']+'/src', shell=False, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "# wait for the process to terminate\n",
    "for line in process.stderr:\n",
    "    print(line.decode('utf8').replace('\\n',''))\n",
    "for line in process.stdout:\n",
    "    print(line.decode('utf8').replace('\\n',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proj_multilingual_text_classification/bert_model-0.1.tar.gz\n",
      "Last modified: Thu May 28 08:35:06 2020\n",
      "Created: Thu May 28 08:35:06 2020\n"
     ]
    }
   ],
   "source": [
    "path_package=''\n",
    "name_package=''\n",
    "for root, dirs, files in os.walk(os.environ['DIR_PROJ']+'/src/dist/'):\n",
    "    for filename in files:\n",
    "        print(root.split('/')[-4]+'/'+filename)\n",
    "        print('Last modified: {}'.format(time.ctime(os.path.getmtime(root+'/'+filename))))\n",
    "        print('Created: {}'.format(time.ctime(os.path.getctime(root+'/'+filename))))\n",
    "        path_package = root+'/'+filename\n",
    "        name_package = filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "bucket_name = os.environ['BUCKET_STAGING_NAME']\n",
    "output_folder = model_name +'_'+datetime.now().strftime(\"%Y_%m_%d_%H%M%S\")\n",
    "\n",
    "storage_client = storage.Client()\n",
    "bucket = storage_client.bucket(bucket_name)\n",
    "blob = bucket.blob(output_folder+'/'+filename)\n",
    "blob.upload_from_filename(path_package)\n",
    "\n",
    "path_package_gcs='gs://'+os.environ['BUCKET_STAGING_NAME']+'/'+output_folder+'/'+filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "project_name = os.environ['PROJECT_ID']\n",
    "project_id = 'projects/{}'.format(project_name)\n",
    "ai_platform_training = discovery.build('ml', 'v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tf_bert_classification_2020_05_28_083506'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# variable used to build some variable's name\n",
    "type_production = 'test' #'test', 'production'\n",
    "hardware = 'gpu' #'cpu', 'gpu', 'tpu'\n",
    "owner = os.environ['OWNER']\n",
    "tier = 'custom' #'basic', 'custom'\n",
    "hp_tuning= False\n",
    "\n",
    "# define parameters for ai platform training\n",
    "package_gcs = path_package_gcs\n",
    "\n",
    "job_name = model_name+'_lr_3e5_1_600_'+datetime.now().strftime(\"%Y_%m_%d_%H%M%S\")\n",
    "module_name = 'model.'+model_name+'.task'\n",
    "if tier=='basic' and hardware=='cpu':\n",
    "    # CPU\n",
    "    region = 'europe-west1'\n",
    "    \n",
    "elif tier=='basic' and hardware=='gpu':\n",
    "    # GPU\n",
    "    region = 'europe-west1'\n",
    "    \n",
    "elif tier=='custom' and hardware=='gpu':\n",
    "    # Custom GPU\n",
    "    region = 'europe-west4'\n",
    "    \n",
    "elif tier=='basic' and hardware=='tpu':\n",
    "    # TPU\n",
    "    region = 'us-central1'\n",
    "    \n",
    "else:\n",
    "    # Default\n",
    "    region = 'europe-west1'\n",
    "    \n",
    "verbosity = 'INFO'\n",
    "\n",
    "# define parameters for training of the model\n",
    "if type_production=='production':\n",
    "    # reading metadata\n",
    "    _, info = tensorflow_datasets.load(name='glue/imdb',\n",
    "                                       data_dir=data_dir,\n",
    "                                       with_info=True)\n",
    "    # define parameters\n",
    "    epochs = 2 \n",
    "    batch_size_train = 32\n",
    "    #batch_size_test = 32\n",
    "    batch_size_eval = 64  \n",
    "    \n",
    "    # Maxium length, becarefull BERT max length is 512!\n",
    "    max_length = 512\n",
    "\n",
    "    # extract parameters\n",
    "    size_train_dataset=info.splits['train'].num_examples\n",
    "    #size_test_dataset=info.splits['test'].num_examples\n",
    "    size_valid_dataset=info.splits['validation'].num_examples\n",
    "\n",
    "    # computer parameter\n",
    "    steps_per_epoch_train = math.ceil(size_train_dataset/batch_size_train)\n",
    "    #steps_per_epoch_test = math.ceil(size_test_dataset/batch_size_test)\n",
    "    steps_per_epoch_eval = math.ceil(size_valid_dataset/batch_size_eval)\n",
    "\n",
    "    #print('Dataset size:          {:6}/{:6}/{:6}'.format(size_train_dataset, size_test_dataset, size_valid_dataset))\n",
    "    #print('Batch size:            {:6}/{:6}/{:6}'.format(batch_size_train, batch_size_test, batch_size_eval))\n",
    "    #print('Step per epoch:        {:6}/{:6}/{:6}'.format(steps_per_epoch_train, steps_per_epoch_test, steps_per_epoch_eval))\n",
    "    #print('Total number of batch: {:6}/{:6}/{:6}'.format(steps_per_epoch_train*(epochs+1), steps_per_epoch_test*(epochs+1), steps_per_epoch_eval*1))\n",
    "    print('Number of epoch:        {:6}'.format(epochs))\n",
    "    print('Batch size:            {:6}/{:6}'.format(batch_size_train, batch_size_eval))\n",
    "    print('Step per epoch:        {:6}/{:6}'.format(steps_per_epoch_train, steps_per_epoch_eval))\n",
    "\n",
    "else:\n",
    "    epochs = 2\n",
    "    steps_per_epoch_train = 50\n",
    "    batch_size_train = 32 \n",
    "    steps_per_epoch_eval = 2\n",
    "    batch_size_eval = 64\n",
    "    \n",
    "input_eval_tfrecords = 'gs://'+os.environ['BUCKET_NAME']+'/tfrecord/imdb/bert-base-multilingual-uncased/valid'\n",
    "input_train_tfrecords = 'gs://'+os.environ['BUCKET_NAME']+'/tfrecord/imdb/bert-base-multilingual-uncased/train'\n",
    "output_dir = 'gs://'+os.environ['BUCKET_NAME']+'/training_model_gcp/'+job_name\n",
    "pretrained_model_dir = 'gs://'+os.environ['BUCKET_NAME']+'/pretrained_model/bert-base-multilingual-uncased'\n",
    "epsilon = 1e-08\n",
    "learning_rate= 3e-5\n",
    "s = 0.5\n",
    "decay_type = 'test'\n",
    "n_batch_decay = 2\n",
    "\n",
    "# building training_inputs\n",
    "parameters =  ['--epochs', str(epochs),\n",
    "               '--steps_per_epoch_train', str(steps_per_epoch_train),\n",
    "               '--batch_size_train', str(batch_size_train),\n",
    "               '--steps_per_epoch_eval', str(steps_per_epoch_eval),\n",
    "               '--batch_size_eval', str(batch_size_eval),\n",
    "               '--input_eval_tfrecords', input_eval_tfrecords ,\n",
    "               '--input_train_tfrecords', input_train_tfrecords,\n",
    "               '--output_dir', output_dir,\n",
    "               '--pretrained_model_dir', pretrained_model_dir,\n",
    "               '--verbosity_level', verbosity,\n",
    "               '--epsilon', str(epsilon),\n",
    "               '--learning_rate', str(learning_rate),\n",
    "               '--s', str(s),\n",
    "               '--decay_type', decay_type,\n",
    "               '--n_batch_decay', str(n_batch_decay)]\n",
    "if hardware=='tpu':\n",
    "    parameters.append('--use_tpu')\n",
    "    parameters.append('True')\n",
    "\n",
    "training_inputs = {\n",
    "    'packageUris': [package_gcs],\n",
    "    'pythonModule': module_name,\n",
    "    'args': parameters,\n",
    "    'region': region,\n",
    "    'runtimeVersion': '2.1',\n",
    "    'pythonVersion': '3.7',\n",
    "}\n",
    "\n",
    "if tier=='basic' and hardware=='cpu':\n",
    "    # CPU\n",
    "    training_inputs['scaleTier'] = 'BASIC'\n",
    "    \n",
    "elif tier=='basic' and hardware=='gpu':\n",
    "    # GPU\n",
    "    training_inputs['scaleTier'] = 'BASIC_GPU'\n",
    "    \n",
    "elif tier=='custom' and hardware=='gpu':\n",
    "    # Custom GPU\n",
    "    training_inputs['scaleTier'] = 'CUSTOM'\n",
    "    training_inputs['masterType'] = 'n1-standard-8'\n",
    "    accelerator_master = {'acceleratorConfig': {\n",
    "        'count': '1',\n",
    "        'type': 'NVIDIA_TESLA_V100'}\n",
    "    }\n",
    "    training_inputs['masterConfig'] = accelerator_master\n",
    "\n",
    "    \n",
    "elif tier=='basic' and hardware=='tpu':\n",
    "    # TPU\n",
    "    training_inputs['scaleTier'] = 'BASIC_TPU'\n",
    "\n",
    "else:\n",
    "    # Default\n",
    "    training_inputs['scaleTier'] = 'BASIC'\n",
    "\n",
    "# add hyperparameter tuning to the job config.\n",
    "if hp_tuning:\n",
    "    hyperparams = {\n",
    "        'algorithm': 'ALGORITHM_UNSPECIFIED',\n",
    "        'goal': 'MAXIMIZE',\n",
    "        'hyperparameterMetricTag': 'metric1',\n",
    "        'maxTrials': 3,\n",
    "        'maxParallelTrials': 2,\n",
    "        'maxFailedTrials': 1,\n",
    "        'enableTrialEarlyStopping': True,\n",
    "        'hyperparameterMetricTag': 'accuracy_train',\n",
    "        'params': []}\n",
    "\n",
    "    hyperparams['params'].append({\n",
    "        'parameterName':'learning_rate',\n",
    "        'type':'DOUBLE',\n",
    "        'minValue': 1.0e-8,\n",
    "        'maxValue': 1.0,\n",
    "        'scaleType': 'UNIT_LOG_SCALE'})\n",
    "    \n",
    "    hyperparams['params'].append({\n",
    "        'parameterName':'epsilon',\n",
    "        'type':'DOUBLE',\n",
    "        'minValue': 1.0e-9,\n",
    "        'maxValue': 1.0,\n",
    "        'scaleType': 'UNIT_LOG_SCALE'})\n",
    "\n",
    "    # Add hyperparameter specification to the training inputs dictionary.\n",
    "    training_inputs['hyperparameters'] = hyperparams\n",
    "    \n",
    "# building job_spec\n",
    "labels = {'accelerator': hardware,\n",
    "          'type': type_production,\n",
    "          'owner': owner}\n",
    "\n",
    "job_spec = {'jobId': job_name, \n",
    "            'labels': labels, \n",
    "            'trainingInput': training_inputs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'packageUris': ['gs://ai-platform-training-package-staging/tf_bert_classification_2020_05_28_083506/bert_model-0.1.tar.gz'],\n",
       " 'pythonModule': 'model.tf_bert_classification.task',\n",
       " 'args': ['--epochs',\n",
       "  '2',\n",
       "  '--steps_per_epoch_train',\n",
       "  '50',\n",
       "  '--batch_size_train',\n",
       "  '32',\n",
       "  '--steps_per_epoch_eval',\n",
       "  '2',\n",
       "  '--batch_size_eval',\n",
       "  '64',\n",
       "  '--input_eval_tfrecords',\n",
       "  'gs://multilingual_text_classification/tfrecord/imdb/bert-base-multilingual-uncased/valid',\n",
       "  '--input_train_tfrecords',\n",
       "  'gs://multilingual_text_classification/tfrecord/imdb/bert-base-multilingual-uncased/train',\n",
       "  '--output_dir',\n",
       "  'gs://multilingual_text_classification/training_model_gcp/tf_bert_classification_lr_3e5_1_600_2020_05_28_083507',\n",
       "  '--pretrained_model_dir',\n",
       "  'gs://multilingual_text_classification/pretrained_model/bert-base-multilingual-uncased',\n",
       "  '--verbosity_level',\n",
       "  'INFO',\n",
       "  '--epsilon',\n",
       "  '1e-08',\n",
       "  '--learning_rate',\n",
       "  '3e-05',\n",
       "  '--s',\n",
       "  '0.5',\n",
       "  '--decay_type',\n",
       "  'test',\n",
       "  '--n_batch_decay',\n",
       "  '2'],\n",
       " 'region': 'europe-west4',\n",
       " 'runtimeVersion': '2.1',\n",
       " 'pythonVersion': '3.7',\n",
       " 'scaleTier': 'CUSTOM',\n",
       " 'masterType': 'n1-standard-8',\n",
       " 'masterConfig': {'acceleratorConfig': {'count': '1',\n",
       "   'type': 'NVIDIA_TESLA_V100'}}}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job status for tf_bert_classification_lr_3e5_1_600_2020_05_28_083507:\n",
      "    state : QUEUED\n",
      "    createTime: 2020-05-28T08:35:16Z\n"
     ]
    }
   ],
   "source": [
    "# submit the training job\n",
    "request = ai_platform_training.projects().jobs().create(body=job_spec,\n",
    "                                                        parent=project_id)\n",
    "try:\n",
    "    response = request.execute()\n",
    "    print('Job status for {}:'.format(response['jobId']))\n",
    "    print('    state : {}'.format(response['state']))\n",
    "    print('    createTime: {}'.format(response['createTime']))\n",
    "\n",
    "except errors.HttpError as err:\n",
    "    # For this example, just send some text to the logs.\n",
    "    # You need to import logging for this to work.\n",
    "    logging.error('There was an error creating the training job.'\n",
    "                  ' Check the details:')\n",
    "    logging.error(err._get_reason())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job status for tf_bert_classification_lr_3e5_1_600_2020_05_28_083507:\n",
      "    state : PREPARING\n"
     ]
    }
   ],
   "source": [
    "# if you want to specify a specific job ID\n",
    "#job_name = 'tf_bert_classification_2020_05_16_193551'\n",
    "jobId = 'projects/{}/jobs/{}'.format(project_name, job_name)\n",
    "request = ai_platform_training.projects().jobs().get(name=jobId)\n",
    "response = None\n",
    "\n",
    "try:\n",
    "    response = request.execute()\n",
    "    print('Job status for {}:'.format(response['jobId']))\n",
    "    print('    state : {}'.format(response['state']))\n",
    "    if 'trainingOutput' in response.keys():\n",
    "        if 'trials' in response['trainingOutput'].keys():\n",
    "            for sub_job in response['trainingOutput']['trials']:\n",
    "                print('    trials : {}'.format(sub_job))\n",
    "    if 'consumedMLUnits' in response.keys():\n",
    "        print('    consumedMLUnits : {}'.format(response['trainingOutput']['consumedMLUnits']))\n",
    "    if 'errorMessage' in response.keys():\n",
    "        print('    errorMessage : {}'.format(response['errorMessage']))\n",
    "    \n",
    "except errors.HttpError as err:\n",
    "    logging.error('There was an error getting the logs.'\n",
    "                  ' Check the details:')\n",
    "    logging.error(err._get_reason())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# how to stream logs\n",
    "# --stream-logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# TensorBoard for job running on GCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Known TensorBoard instances:\n",
      "  - port 6080: logdir /home/vera_luechinger/tensorflow_model/saved_model/tensorboard (started 2:28:10 ago; pid 4119)\n",
      "  - port 8083: logdir /home/vera_luechinger/tensorflow_model/saved_model/tensorboard (started 2:21:31 ago; pid 4153)\n",
      "  - port 6006: logdir /home/vera_luechinger/tensorflow_model/saved_model/tensorboard (started 3:36:08 ago; pid 2100)\n"
     ]
    }
   ],
   "source": [
    "# View open TensorBoard instance\n",
    "notebook.list() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# View pid\n",
    "#!ps -ef|grep tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Killed Tensorboard process by using pid\n",
    "!kill -9 4119"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 2100), started 3:39:55 ago. (Use '!kill 2100' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-f175065a7c9a06b5\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-f175065a7c9a06b5\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "#%reload_ext tensorboard\n",
    "%tensorboard  --logdir {'/home/vera_luechinger/tensorflow_model/saved_model/tensorboard'} \\\n",
    "              --host 0.0.0.0 \\\n",
    "              --port 6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 2947), started 3:14:58 ago. (Use '!kill 2947' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-ab497822085c4a7\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-ab497822085c4a7\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#%load_ext tensorboard\n",
    "%reload_ext tensorboard\n",
    "%tensorboard  --logdir {output_dir+'/tensorboard'} \\\n",
    "              --host 0.0.0.0 \\\n",
    "              --port 6006 \\\n",
    "              #--debugger_port 6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-f607dbc3deca61fc\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-f607dbc3deca61fc\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6010;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "#%reload_ext tensorboard\n",
    "%tensorboard  --logdir {os.environ['OUTPUT_DIR']+'/hparams_tuning'} \\\n",
    "              #--host 0.0.0.0 \\\n",
    "              #--port 6006 \\\n",
    "              #--debugger_port 6006"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:env_multilingual_class]",
   "language": "python",
   "name": "conda-env-env_multilingual_class-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
